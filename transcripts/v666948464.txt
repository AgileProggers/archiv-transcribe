So Leute, da sind wir.
Es ist echt warm heute, soll ich das mal sagen.
Es ist 24,9 Grad hier bei mir gerade im Arbeitszimmer und ich hatte vorhin schon die Klimaanlage
laufen.
Die muss ich jetzt erstmal wieder anmachen.
Viel zu warm.
Gut, ich will auch gerade zweite mal Sport machen heute.
Peppofett.
Vielleicht bald nicht mehr oder vielleicht noch mehr.
Man weiß ja nicht, soll ich mal erstmal die Klimaanlage an kurz.
So, das reicht schon, wie gesagt es ist gerade 24,9 Grad hier drin.
Gut, ich habe jetzt hier Tür zugemacht, Rechner an, zweiter Rechner an, das heißt es wird
jetzt hier relativ schnell warm drin.
Aber wenn ich jetzt die Klimaanlage anmache, ich habe es auf 23 Grad gestellt, das ist
ein riesen Unterschied, ob 25 Grad oder 23 Grad.
Das ist wirklich, 23 Grad ist top angenehm, fast schon ein bisschen kühl, wenn die Klimaanlage
pustet und 25 Grad mit stehender Luft ist viel zu warm.
Ich weiß ja auch nicht, warum mir das jetzt gerade einfällt, aber das musste mal gesagt
werden.
Keckweight.
Warum habe ich eigentlich kein hochauflösendes Keckweight?
Man, warum habe ich kein Keckweight?
Keckweight.
Ich brauche ein hochauflösendes Keckweight, Keckweight, kein Keckweight, Images, Keckweight.
Moment, Color, Transparent, Keckweight, warum gibt es kein transparentes Keckweight?
Was ist denn das?
Was soll denn das hier?
Kein Keckweight.
Hoffentlich hat Teams mein Mikrofon hier wieder umgestellt.
Äh, nee, Moment, Recording, nee, nee hat es nicht, ich brauche ein ordentliches Keckweight
in der Auflösung.
Keckweight, Size, Medium.
Das ist ja mal absolut schlechte Kack-Quali, Keckweight.
Da ist das, da ist der hier schon besser.
Na gut, um euch zu erfreuen, Chat, habe ich einen neuen Sound-Effekt, Stripes 007, 12
Monat.
Aja ja, Exzellenz aufs Köpchen hier, geht gut los.
Ich habe, ich habe, ich habe zwei neue Sound-Effekte drinne und zwar, oh, einmal.
So und ganz wichtig, den brauchen wir auch noch, den kann man sicherlich immer mal gebrauchen.
So und das Problem ist nur, ich habe die Sachen gleich genannt.
Das hier ist, das hier ist eigentlich Edu, oder was auch immer, er da genau sagt, Edu,
nicht Bitconnect, Edu, Edu, ich muss mal kurz Updates anschmeißen, falls ich die noch letztes
Mal nicht habe durchlaufen lassen.
Exzellent Musik hier.
Exzellenz aufs Köpchen hier.
Das ist Mario Galaxy Musik, das ist, das ist auch, das war aus dem offiziellen Soundtrack
aber ich glaube, das ist eine der Stücke, die sie sich irgendwo abgeguckt haben.
Also ich glaube, das ist nicht original, mit ein bisschen Zeug drumherum.
So heute waren mal richtige Hacker-Mind-Sachen und zwar, ich weiß nicht mehr, wer es gewesen
ist, aber im letzten Stream hat mich irgendjemand auf die Idee gebracht, nämlich folgendes
zu machen.
Das da, so, wir werden das ein bisschen anders machen.
Neunter Monat, Tibidius, oh das Kind kommt von KS, wer ist denn schwanger?
Also ich meine, bei mir sieht es vielleicht so aus, aber das ist anders gelagert.
Die fehlt das Wombo-Kombo, ne, das glaube ich durfte, sag mal, achso, ne, oder, ah,
ich kann kein Sound hören auf meinem zweiten Rechner, weil das Audio-Interface wiederum
spackt.
Na ja, so, das ist der Mario Galaxy-Soundtrack, ups, ne, das ist meine Domain, das ist der
Mario Galaxy-Soundtrack, den ich irgendwo, wo habe ich ihn denn, da, also wir machen
heute Big Brain Stream, wie gesagt, mich hat hier jemand auf die Idee gebracht, dass wir
das hier machen.
Ich muss euch jetzt allerdings mal was fragen, Chat, und das ist nicht, das ist nicht so
einfach.
Und zwar, also was wir jetzt machen ist, wir gucken uns die Kombination an, aus einer
eigenen Domain, Let's Encrypt Zertifikaten, das steht ja schon im Titel, allerdings an
sich wäre das Sache von 5 Minuten, ähm, es ging ja darum, dass jemand gefragt hat, wie
man eine Reverse-Proxy aufsetzt, und das werden wir machen, wir werden irgendwelche Anwendungen,
wir nehmen erstmal so eine Hallo-Welt-Container, vielleicht hier so ein Git oder eine Next
Cloud, in einem Docker-Container laufen lassen, und davor eine Reverse-Proxy stellen, der
für uns Zertifikate und DNS, ne, ne, ne, ich versprache es hier nicht, DNS, äh, Zertifikate
über DNS-Challenge macht.
So, also soweit, soweit der Plan, und jetzt, Chat, jetzt kommt, äh, die, äh, schwierige
Frage.
Wie wollen wir das machen?
Also, ich kann das intern bei mir auf dem Raspberry Pi machen, das ist dann relativ
ähnlich zu dem, was man daheim auch machen würde, oder, ich habe überlegt, das wäre
vielleicht auch mal ganz gut, wir können das auf einer Digital-Ocean-VM machen, öffentlich
zugänglich.
Das heißt, ihr könnt dann sogar euch drauf connecten und gucken, ob alles funktioniert.
Natürlich muss ich da ein bisschen aufpassen, dass ich nicht irgendeinen Mist konfiguriere,
was aber auch nicht so schlimm ist, weil Digital-Ocean-VM kann ich mit einem Klick
wieder löschen.
Was gebrauchte Grafikkarte in der Reichweite von 100 bis 150 Euro, ja, nehm ich, wäre
auf dem Pi nicht besser, falls es jemand zuhause nachmachen möchte, naja, es ist ja eigentlich
kein großer Unterschied, also sprich, das, was ich mache, ist mehr oder weniger das gleiche
auf einem öffentlichen Server oder auf dem Raspberry Pi, nur, dass man sich das Ergebnis
mal angucken kann.
Wir können ja, wo habe ich eigentlich meinen Raspberry Pi, äh, ah, hier, da ist er, also
den Raspberry Pi hätte ich am Start, das könnte man machen, ja, also, wie ihr wollt,
wie ihr wollt, ja, also könnt ihr euch aussuchen, ob wir es intern auf den Raspberry Pi machen
sollen, oder ob ich das mal extern auf einer Digital-Ocean-VM machen soll, ähm, ich leg
meine Digital-Ocean-VM an, weil ich mal gucken will, ob ich überhaupt meinen SSH-Key hier
auf der VM hab.
Wenn ich nämlich meinen SSH-Key gar nicht auf der VM hab, dann können wir uns das Ganze
eh sparen.
Externis.
Okay, da machen wir, da machen wir Kompromiss, easy killer, neun Monate, exzellent, dankeschön,
five head, big brain, wo habe ich denn hier, wo ist mein big brain?
So, ähm, das wäre auch mal was für den Stream, ist das, soll auch, oh, das ist eine gute
Idee, Sebaro, das finde ich gut, das ist, das ist sehr nice, das, ähm, schreibe ich
mal auf, da können wir echt mal reingucken, das ist bestimmt ganz witzig, also, was wir
jetzt mal machen, da legen wir das Ding extern an, wir können ja, wir können ja so ein Kompromiss
machen, es, wir installieren das Ganze extern erstmal, allerdings die Sachen, wo es dann,
wo man auch wirklich was mit machen kann, sei es jetzt irgendwie eine Nextcloud oder
sonst was, das mache ich dann vielleicht intern, weil, das gebe ich euch eh extern kein Zugriff
drauf.
Also insofern bringt es das nichts, dann machen wir das Basic Setup, das Basic Setup machen
wir auf der Digital-Ocean-VM, da könnt ihr nämlich Hello World sehen, dass es funktioniert
und, ähm, dann ist es auch besser, so ein bisschen die Sachen drumherum anzugucken und
die anderen Sachen machen wir dann vielleicht auf dem Raspberry Pi später, mal gucken,
wie wir von der Zeit her hinkommen, ja, und wenn es jetzt 18.30, 22 Uhr ist wieder Schluss,
aber dann haben wir noch ein bisschen Zeit bis dahin, also ich lege erst, ich lege erst
mal eine Digital-Ocean-VM an, ich mag aus irgendwelchen Gründen Digital-Ocean, ich
weiß, dass die Hetzler-Cloud viel billiger ist, aber ich habe mich irgendwie auf Digital-Ocean
eingeschossen, also, das ist die einfachste Variante, sich, ähm, irgendwelche Linux-VMs
zu erstellen, online, die man einfach wieder löschen kann, die sind sau schnell wieder
da und die kann man sau schnell wieder löschen, überhaupt kein Problem, ja, da geht man einfach
auf Droplets, Create und dann sucht man sich eins aus, was man haben will, also sagen wir
hier, wir wollen Ubuntu 20.04, Standard übrigens, das hier ist Gbait, das ist die größte Gbait-Anzeige
überhaupt, ihr müsst hier hin, 5 Euro im Monat oder 0,7 Cent die Stunde, also Stream,
das kostet euch, so wie es aussieht, heute einige Prime-Subs mit 0,7 Cent die Stunde,
ja, und trotzdem reicht es für alle Testzwecke, ich meine, man hat einen Gigabyte RAM, man
hat eine CPU, man hat 25 Gigabyte SSD und genug Transfervolumen, wenn du das einfach
findest, musst du dir unbedingt einmal Scaleway anschauen, da war ich sogar, glaub mal drauf
schon auf Scaleway, da war ich glaube ich schon mal drauf, aber die Preise waren noch
gar nicht so groß oder so unterschiedlich, ich hatte es mir auf jeden Fall mal angeschaut,
da sind die mit diesem lila Logo, ne, ja, da sind die mit diesem lila Logo, ja, also
die Hetzner, Hetzner Cloud ist viel günstiger, hallo Wasserfreak, Hetzner Cloud ist viel
günstiger, guck, da sind wir bei, naja, 0,02 Cent, aber kostet halt nur die Hälfte, ungefähr
im Monat, bis weniger als die Hälfte, und man kriegt sogar mehr RAM, also an sich ist
gar nicht so verkehrt, ist das gleich wie bei NetCup, vielleicht sind die ja sogar im
gleichen RZ, man weiß ja nicht, ne, kann ja sein, oh, das ist eine schöne Statistik,
hier guckt mal, bestprices, Scaleway ist angeblich bestprices, na gut, wundert mich jetzt nicht,
wenn das von Scaleway.com kommt, dass sie hier sich in dem Vergleich als bestprices
hinstellen, gut, Azure ist teuer, also Azure, AWS, wo ist Google, hier, Google, ne, Moment,
da, Google, also Google ist bei vielen Sachen ziemlich teuer, wenn man das freikontingent
überschreitet, aber AWS und Azure nimmt sich meistens auch relativ teuer, und dafür kann
man halt noch viel mehr Sachen machen, egal, wir legen uns jetzt einfach mal hier eine VM
an, ich weiß nicht, ob ich euch das schon mal im Stream gezeigt hab, das ist wirklich
total einfach, solltet ihr mal wirklich einen Linux Server auf die Schnelle brauchen, geht
auf Digital Ocean oder auf Scaleway oder auf Hetzner Cloud oder sonst was, die sind alle
mehr oder weniger ähnlich, wählt das Betriebssystem aus, was ihr haben wollt, geht auf die kleinste
VM, die es gibt, und sucht euch ein Datacenter aus, wählt euren SSH Key aus, ihr könnt es
auch mit einem Passwort machen, aber SSH Key würde ich euch empfehlen, dann ist das von,
dann ist das standardmäßig secure eingerichtet, und ja, Sebaro mach ich, so, und dann klickt
man auch anlegen, und das war's, mehr muss man nicht machen. Was hast du bereits gemacht?
Keine Ahnung, ich bin letztes Zeit, ich bin seit einer Viertelstunde online, noch gar
nix, ich leg grad ne Digital Ocean VM an. So, dann guckt man dem ganzen zu, wie der,
wie die VM provisioned wird, und wenn das fertig ist, kriegt man ne IP und kann sich
drauf einloggen, also so einfach kriegt man ansonsten nur lokal irgendeine VM, also einfacher
kann es eigentlich nicht mehr gehen. So, und was man jetzt als nächstes machen muss,
ist folgendes, also was wir machen, ich, ich mal das nochmal auf, ich hab's ja gestern
schon mal aufgemacht, ich mal das nochmal kurz auf, was wir machen, also, machen, Drive,
Device, Create New, Blank, also, wir haben hier nen Ubuntu Server, äh, kann man die
Schrift nach oben machen, Top, ok, also, kann man auch Top-In machen, Top-Right, Left, ne,
also wir haben hier nen Ubuntu Server, da kommt rein, da kommen mehrere Container rein,
es ist jetzt erstmal egal welche, wir schreiben einfach mal Container hin, Service 1, Service
2, Service 3, oder irgendwie sowas, so, Service 1, so, Service 2, Service 3, das kann zum
Beispiel, der Soundtrack kann sich nicht entscheiden, ob er zu laut oder zu leise sein soll, ähm,
das kann zum Beispiel, dann schreiben wir mal was hin, Nextcloud zum Beispiel rein,
dann haben wir noch nen Git-Server, äh, sowas, sowas in der Richtung, und dann noch irgendwie
irgendwas anderes, keine Ahnung, irgendeinen Web-Server oder so, es ist auch vollkommen
wurscht, so, davor machen wir nen Reverse-Proxy-Loud-Balancer-Hybrid-Ding, also, so, das ist in dem Fall ist das,
ich kann das nicht richtig schreiben, ich glaub, so schreibt man das, drei, was, was
ein Wort, wer hat sich das ausgedacht, das ist total, äh, ich hab was im Auge, so, dann
machen wir den hier davor, als Reverse-Proxy, das klingt wirklich was wie von Okia, ne,
von Nginx, ähm, und das ganze, hab ich ja noch, hab ich ja noch vergessen, das da sind
jeweils Docker-Container, also sprich, Doxor, ähm, Text, Position, Top, das da sind eigentlich
Docker-Containers, äh, Moment, ähm, Range, To Back, äh, To Back, exellent, Big Brain-Zeichen-Programm
hier, so, das ist das, was wir bauen, also sprich, das ist die logische Aufteil, was
wir auf unserem Ubuntu Server machen, und, oh, man kann das ganze speichern, das wusste
ich gar nicht, dass das funktioniert, so, dann haben wir hier außen, das hab ich sowas
ähnlich, das hab ich ja gestern schonmal gemalt, hier außen haben wir Let's Encrypt
für SSL-Zertifikate, so, oh, ok, FOD, komischer Pfeiler, weg, das sind Zertifizierungsstelle,
die stellt uns SSL-Zertifikate raus, und unser Reverse-Proxy macht Big Brain Moves, und ruft
sich immer neue Zertifikate ab, und das Schöne an dieser Kombi ist, dass Traffic checkt,
dass alles angelegt ist, also sprich, welche Container hier existieren, und er macht intern
das Handling, sprich, das, äh, das Proxying, oder eventuell auch Loadbalancen, je nachdem,
auf die Container automatisch, also sprich, man muss sich nicht hier drum kümmern, man
muss auch nichts anlegen, außer einmal diesen Server im DNS einrichten, das ist alles,
mehr muss man nicht machen.
So, und das heißt, davor hat man halt irgendwie einen ordentlichen Router, ordentlichen Router,
wobei, die Cisco-Fans, bei denen ist ein Router sowas hier, ein Router, da haben wir hier
Cloud, ganz wichtig, brauchen wir auch noch hier, Cloud, das ist das Internet, Big Brain,
oder Wolke, das ist euer Provider, und das seid ihr, oder irgendjemand, und das Schöne
ist, dass man von hier, nach hier, also von euch daheim, zu eurem Server, ist jetzt erstmal
egal, ob der in der Cloud irgendwo steht oder bei euch daheim, wenn er bei euch daheim steht,
fällt halt die Internetgeschichte weg.
Man muss nur einmal, oh, was ist denn das hier, was macht die Wolke hier in der Mitte,
man muss die Sache nur einmalig konfigurieren, richtig, also das Handling von Zertifikaten
und diesen Weg hier, das muss man nur einmal richtig konfigurieren, danach lassen sich
relativ easy, ohne größere Config-Aufwände, oder ohne Big Brain-Geschichten, weitere Services
hier dahinter betreiben, ohne dass das großartig unsicherer wird, und ohne dass man großartig
was machen muss.
Warum nicht Serverless, das passt, gute Frage, das ist nämlich auch gut in Kombination mit
das, was dann draufkommt, ich kapiere immer noch nicht, was Serverless ist, was sollte
jetzt ohne Server funktionieren, gar nicht, Serverless ist der größte Jebait überhaupt,
Serverless hat mit dem Namen Serverless überhaupt nichts zu tun, das einzige, was Serverless
meint ist, dass die Server nicht bei dir stehen, sondern dass die Server bei jemand anderem
stehen.
Das alles, also Serverless ist exakt das Gegenteil von Serverless, weil ohne Server geht's halt
nicht.
Es ist, naja, Synonym für Cloud, kann man so nicht sagen, Synonym bedeutet, als heißt
mehr oder weniger das gleiche, Cloud ist ja so ein wager Begriff für Rechner, die irgend
wo stehen.
So und Serverless ist quasi eher, jemand bietet mir einen Service an, den ich verwende, sodass
ich keine Server mehr brauche, zum Beispiel, wenn ich irgendwas berechnen will, und dazu
brauche ich drei verschiedene Services, und die Services miete ich mir in der Cloud und
verbinde die in der Cloud zusammen, und ich liefere dann vielleicht bloß noch einen Frontend
aus, dann ist das insofern Serverless, weil ich halt keine Server mehr betreibe.
Serverless letztendlich gibt's eh nicht, im eigentlichen Sinne, weil irgendwo muss
die Webseite ausgeliefert werden, von irgendeinem Webseiter wird eine Webseite ausgeliefert.
Also komplett Serverless ist Blödsinn, in der Regel ist damit nur gemeint, der Scheiß
steht halt einfach nicht bei mir.
Genau, Microservices kommt auch noch dazu, in der Regel spricht man bei diesen Diensten,
die man entweder sich mietet, oder die man eventuell sogar selbst betreibt in der Cloud,
dann von Microservices, weil das ist halt kein großartiges Ding, sondern funktionell relativ
beschränkt auf eine Sache, was weiß ich, das eine macht nur Authentifizierung, da habe
ich irgendeinen Key-Cloak-Service laufen, das macht nur Authentifizierung, dann habe
ich vielleicht irgendwie die Azure Cosmos DB für ein bisschen Datenbankgedöns und sowas,
und das verbinde ich dann zusammen in der Cloud, dann ist das quasi Serverless Microservices
in der Cloud, die ich verwende.
Und dann kann man sich als Stonks-Mann einen darauf abrubbeln, wie hip man ist.
Was machen wir heute?
Das hier machen wir heute, ich habe es gerade aufgemalt, wo habe ich es, da, wir bauen
ein Reverse-Proxy mit Traffic für unsere eigene Domain, ich habe mir extra eine Domain
gekauft, damit ich hier im Stream ein bisschen Zeugs basteln kann, nämlich proggers.exe
x, y, z, und wir werden folgendes machen, wir nehmen die Domain, konfigurieren bei Digital
Ocean, ich habe das hier, ich habe mich schon überall eingeloggt im anonymen Tab, also
wir konfigurieren auf Cloudflare, also ich muss alles anfangen, wir machen uns zum Einstieg
auf Digital Ocean eine VM, das heißt, da ist er am Start, zwei Monate, exzellent, Subscription,
also wir machen uns auf Digital Ocean, wir machen uns auf Digital Ocean eine VM, jetzt
erstmal zum Ausprobieren, die Sachen, wo Leute was mit anstellen können, die machen wir
dann auf dem Raspberry Pi, aber wir machen das erstmal öffentlich diesmal, also sprich,
dass ihr auch prinzipiell seht, dass es funktioniert, ihr könnt euch dann auf die IP später connecten
oder eben auf die Domain, was ja eigentlich der Sinn ist, und euch angucken, dass dann
da Hallo Welt steht, oder ne, da steht nicht Hallo Welt, da steht dann Willkommen im Who-Is-Container
oder im Who-Am-I-Container oder sowas, irgendein Exempel-Container machen wir dann, also wir
legen uns eine VM bei Digital Ocean an, mit der wir heute den ganzen Kram machen, zumindest
bis zum gewissen Teil, dann gehen wir als nächstes zu Cloudflare, legen dort meine,
übrigens die E-Mail-Adresse ist nicht leaked, das ist meine offizielle Business-Kontakt-E-Mail-Adresse,
die überall steht, sowohl auf Twitch als auch auf YouTube, falls mir da irgendjemand
ankommt, Max, leaked, leaked, leaked, ich hab's genau gesehen, leaked, alter, leaked, so,
dann legen wir uns unsere Domain bei Cloudflare an, Cloudflare sorgt in dem Fall dafür, dass
die Leute die Domain auflösen können, warum auch eine Max-FPS-TV-Adresse nehmen, hätten
wir auch machen können, Seba, richtig, ja, aber ich hab den Cloudflare-Account schon
eine Weile, aber vielleicht nehme ich auch eine Max-FPS-TV-Adresse, genau, dann gehen
wir in Cloudflare, legen unsere Domain an, also unsere Domain ist proggers.xyz, da ist
gerade noch gar nichts dabei und man sieht auch, DNS-Auflösung geht nicht, so, damit
Cloudflare funktioniert, müssen wir zu unserem Host da gehen und ich glaube, das ist ganz
gut, wenn man mal die einzelnen Schritte gesehen hat, die man da unternehmen muss, dass das
funktioniert, da müssen wir zu unserem Domain-Registrar gehen und dort die DNS-Serve ändern, so und
das werden wir jetzt alles machen, wenn wir das gemacht haben, dann gehen wir auf unsere
Digital-Ocean-VM, installieren Docker, Docker-Compose, Traffic und starten den Hello-World-Container
oder so Who-Am-I-Container ist das und den könnt ihr dann im Stream ausprobieren, ob
das funktioniert. Warum Cloudflare? Weil Cloudflare kostenlos ist für kleine Sachen und Cloudflare
eine gute API-Unterstützung hat und auch gute Plugins, die überall funktionieren. Ich hätte
eine Idee für ein Abstimmen, bevor es losgeht, oje Sebaro, was denn? Was willst du für eine
Abstimmung Sebaro? Wer ist der cutest Mod im ganzen Land? Wird dieser Stream später noch
als Watt verfügbar sein oder nicht, ja? Achso, wird was geleakt, ja das weiß ich doch jetzt
noch nicht. Woher soll ich das denn jetzt schon wissen, ob was geleakt wird? Ich bin
ja kein Hellseher. Ja, E-Mail ist nicht geleakt, E-Mail ist öffentlich. So, also, auf geht's.
Gut, fangen wir mal an, also Sebaro. Wir können es auch im nächsten Stream machen. Okay, also
jemand hat gefragt, was die Domain kostet. Die kostet, ich muss aufpassen, weil hier kann
ich wirklich was liegen, da muss ich aufpassen. Das ist nämlich dort, wo ich meine ganzen
Domains, also meine ganzen, ganzen Domains, meine zwei Domains registriert habe. Das ist
die, die ich für meine Heimautomatisierung verwende, daheim, da ist nichts öffentlich
von. Und das hier ist der Kram, den ich verwende. Die Domain habe ich mir extra gekauft, nur,
damit ich im Stream Sachen zeigen kann. Chat. So, und ich weiß leider nicht genau, was es
kostet, wir gucken mal. Ich muss aber aufpassen, dass ich keine E-Mail Adresse und Namen leake
und sowas. Okay, für neun Dollar im Jahr könnte ich sie renewen. Also, Prime Subs, bam, bam,
bam, neun Euro im Jahr müssen reinkommen, neun Dollar, neun Dollar achtzehn im Jahr.
Any primers. Und, ähm, mit der Domain können wir ein bisschen rumsaunen, im Endeffekt,
danach schmeiße ich das eh alles wieder raus. So, also, dann würde ich sagen, fangen wir
mal an. MaxMarketing, exellent. PepofetMarketing. So, ähm, so, damit wir das Ganze hier hinkriegen,
was ich da aufgemalt hab, müssen wir jetzt erstmal schauen, was ist denn das Ziel? Also,
sprich, was wollen wir? Wir wollen, dass, jetzt müssen wir ein bisschen DNS-Zeug machen,
wir wollen, dass Progasp, also, unsere Domain, ist Progasp XYZ. Hat das einen bestimmten
Grund, wieso du deine Domains da hast? Ja, weil es die billigsten waren. Die mit Abstand
billigsten. Und, weil die sich absolut nicht für interessieren, ob man sich mit Fake-Daten
registriert. Ich heiße irgendwie, ähm, äh, Peter K. Wupplor, äh, wohne, wohne in Frankfurt
am Hauptbahnhof und in der Unterführung oder so. Am oder im Hauptbahnhof. Ich weiß nicht,
was ich da eingetragen hab. Hast du Angst, dass du den Namen liegst? Naja, ähm, bis
vor nicht allzu langer Zeit konnte jeder eine WhoIs-Anfrage machen und man hat das
rausgekriegt. Mittlerweile rücken die das ja gar nicht mehr raus. Deswegen Fake, Fake-Daten.
So, also das Ziel ist, die Domain, die wir haben. Ich glaub übrigens, dass der jung
Snorlax, der gerade im Chat gekommen ist, das war, der sogar gefragt hat, wie man das
macht. Ich bin mir aber nicht mehr ganz sicher. Irgendeiner hat gestern im Stream gefragt,
wie man das macht. Ich glaub, das war er. Frage liegt. War Matze2090, da kann ich mich
jetzt nicht mehr dran erinnern. Aber es ist ja so, es ist ja so im Trend auf Twitch,
dass man immer sagt, I did this. Und da muss Vertöner und Smiley dahinter machen. Yep,
yep, gibt's hier nicht als E-Mode. Die Geschichte mit Reverseproxy einrichten. Wer war denn
das? Ist ja auch egal, wir machen's trotzdem. Also, so, damit wir jetzt ein bisschen, als
hab ich lange geschwätzt, dass man jetzt ein bisschen Vorstellungen hat, was man bei
der ganzen Geschichte machen muss. Also, Ziel ist ja, sowohl wenn ihr das intern bei euch
habt, daheim, für interne Container, Services, was auch immer, oder ob ihr das extern macht,
euer Ziel ist ja, dass wenn ihr auf eure Domain geht, dass ihr irgendwo rauskommt. So, aktuell
passiert bei progas.xyz schon mal gar nichts. Und das liegt daran, weil bei meinem Domain-Anbieter
nichts hinterlegt ist. Da sind keine DNS-Einträge. So, allerdings möchte ich den DNS von meinem
Domain-Registrar nicht verwenden. Und zwar aus folgendem Grund, weil die keine API für
DNS-Änderungen haben. Und ich hab ja schon mal die Story erzählt, dass ich's geschafft
habe, dass die mich zweimal gesperrt haben. Also, da hab ich schon erzählt, oder? Dass
mich mein Domain-Registrar zweimal gesperrt hat. Also, ja, hab ich. Nur mal ganz kurz
für alle, die sich mitgekriegt haben, ich hab versucht, die DNS-Einträge automatisch
zu ändern. So wie man das hier über die Cloudflare API machen kann. So, und über die Cloudflare
API ist es total einfach, sowas zu machen. Bei meinem Domain-Registrar, die haben keine
API für DNS-Änderungen. Und für Zertifikate, DNS-Challenge, brauchst du gewisse DNS-Einträge,
das letzte Encrypt der Zertifikate gibt. Deswegen hab ich mir gedacht, ich mach jetzt einfach
Next Level Big Brain Move und ich hab ein Skript gebastelt, was im Hintergrund in Chrome
startet, sich bei meinem Domain-Registrar einloggt und im Web-Interface DNS-Änderungen
quasi eintippt, auf Enter drückt und das speichert. Also ich hab quasi Webseiten, User-Interaktionen
gefaked über den unsichtbaren Chrome. Das Problem war nur, dass ich es ein bisschen
verkackt habe und hab das Skript quasi gebotet, ja, wenn du es so willst, im Prinzip richtig
Hacker-Mans-Geschichten. Und das Problem dabei war nur, ich hab es dann irgendwann verkackt
und hab das Skript ein bisschen fail programmiert, ich hab an einer Stelle wahrscheinlich einen
Exit oder einen Break oder sonst was vergessen und dann hat sich das halt versucht, 500 mal
anzumelden. Und dann haben die meine IP blacklisted. Weil die sich gedacht haben, okay, das ist
definitiv kein normaler Traffic. Monarch-S. Und dann haben die meine IP geblacklisted.
Da hab ich dahingeschrieben und hab gesagt, oh nee, ich hab mich vertan, ganz schlimm.
Und hab die bei der Gelegenheit auch gefragt, ob die einen DNS-AP haben und die haben halt
geantwortet, nee, sie haben keine DNS-AP, aber sie mögen das auch nicht, wenn man quasi
die Webseite crawlt, das finden sie nicht so toll. Ja, ja, kommt nicht wieder fair, kommt
nicht wieder, kommt nicht wieder vor. Hi Noob, ein bisschen Jammel werden wir wahrscheinlich
machen müssen denke ich, ja. Tommel mache ich nicht, Jammel. Können auch Tommel machen
meinetwegen. Und da hab ich eigentlich gesagt, ja, kommt nicht wieder vor, mach ich nicht
und dann haben die mich freigeschaltet. So und dann hab ich das Skript genommen und
hab mir gedacht, scheiß drauf, du machst es jetzt trotzdem. Beziehungsweise ich wollte
das Skript dann auch zweckentfremden für eine andere Seite. Und das Problem war, dass
ich das umgebastelt hab, aber an einer Stelle noch mein Domain-Registrar drinne stehen hatte.
Da hab ich's ausgeführt und dann wurd ich nochmal gebannt. Und da hab ich ihnen das
nochmal erklärt, so nach dem Motto, ja, ich hab aus Versehen mein Skript nicht richtig
angepasst, kommt nicht wieder vor, da haben sie mich halt wieder freigeschaltet. Ja also
von wegen, ne, also ich programmier auch öfters totalen Crap zusammen. So und zumindest
hab ich mir dann gesagt, ok, mein Domain-Registrar bietet keine AP an, um DNS-Änderungen zu
machen und ich lauf Gefahr, dass die mich permanent bannen, wenn ich so weitermache.
Also was mach ich? Ich verwende einfach nicht den DNS von meinem Domain-Registrar, sondern
ich verwende das, was die meisten anderen in dem Fall auch verwenden, Cloudflare. Und
das ist total einfach, das zeig ich euch jetzt mal. Also von der Logik her geht das ja so.
Wenn ihr eine Namensauflösung für ein Domain macht, so dann guckt, dann guckt, ganz grob
und einfach gesagt, dann geht euer Rechner an den DNS-Server, der bei ihm hinterlegt
ist. Die meisten Leute haben den DNS-Server zugewiesen bekommen mit ihrer DHCP-Adresse,
die meisten Leute haben ja keine IP und DNS und Gateway-Geschichten selbst mal vergeben,
die kriegen per DHCP, kriegen die eine IP, kriegen eine Gateway vom Router und kriegen
einen DNS. Meistens wird dann der interne DNS vom Router verwendet und der selbst kriegt
bei der Einwahl einen DNS vom Provider. Deswegen, Telekom-Kunden kennen das vielleicht, wenn
ihr euch vertippt bei einer URL, die es nicht gibt, dann kriegt man bei der Telekom manchmal
Werbung angezeigt. Und wie machen die das? Genau über die DNS-Anfragen, die beim Google
DNS kommen. Wenn beim Telekom DNS eine Anfrage ankommt mit einem Domain, die es nicht gibt,
dann redirecten die das auf den Server von ihnen und da ist halt zufälligerweise eine
Suchmaschine mit Werbung. Ich halte das für fragwürdige Praxis, was die Telekom da treibt,
aber ja, ich weiß, man kann es deaktivieren, aber es macht die Telekom. Dann sieht man,
normaler Weg ist von eurem Rechner zu eurem Router, von eurem Router zu eurem Provider-DNS.
Euer Provider-DNS hat so ziemlich alles, was es so gibt, größere Sachen weltweit gecached
und wenn euer Provider-DNS das nicht gecached hat, dann geht er zur Top-Level-Domain und
von dort wird dann geguckt, okay, wer ist denn für Progas zuständig, also wird erstmal
geguckt, wer ist für XYZ zuständig, dann wird geguckt, wer ist für Progas zuständig
und so wird sich quasi an den Domain-Namen abgearbeitet, bis man irgendwann dazu kommt,
dass Progas XYZ bei PorkBan registriert ist und PorkBan eben die Standard-DNS-Server,
die sie hier verwendet. So, so funktioniert das bei einem Name Lookup. Das kann man sich
auch einfach angucken, wenn man jetzt hier mal auf Linux geht und sagt Dick Progas, ne,
XYZ, es kann auch sein, dass es überhaupt nicht funktioniert, wie? OK, es, yep Dick,
warum hab ich keinen Dick installiert, was man DNS-Utils oder sowas, was muss man dafür
installieren? Beides fehlt man schon, NS-Lookup fehlt auch, Bind-Tools, Bind-Utils, Bind-Utils,
Bind-Tools, Bind-Tools, ist exzellent. So, das kann man auch überprüfen, Progas.xyz
gibt es nicht. Wir fragen den Google-DNS, das ist 8.8.8.1 und der Google-DNS sagt, aha,
guck mal da, keine Ahnung was es ist, allerdings, ich weiß, dass diese DNS-Server dafür zuständig
sind. So, wir können jetzt noch Cloudflare fragen, Cloudflare könnte sein, dass sie
das gecasht haben, weil ich hab das vorher mal kurz ausprobiert, nein, haben es auch
nicht gecasht. So, und was ich jetzt machen muss, dass das funktioniert, also sprich,
dass Cloudflare für mein DNS zuständig ist und nicht mehr mein Domain-Registrar, muss
ich hier die autoritiven, die Nameserver ändern, die für meine Domain zuständig
sind. Dort muss ich jetzt Domains, also das sind die Server, die letztendlich auch in
der Kette gefragt werden, wer für was zuständig ist und die muss ich umbiegen auf Cloudflare.
Das funktioniert folgendermaßen, das ist in Cloudflare ziemlich gut gemacht, man sagt
einfach, hallo Cloudflare, ich möchte bei euch eine neue Domain anlegen, also nicht
eine neue Domain registrieren, sondern sagen, Cloudflare, kümmere dich mal um folgende
Domain. So, äh, Moment, nicht Support, was mache ich denn bei Support? So, genau, you
don't have any websites, add website, sag mal, progress.xyz, das geht dementsprechend ja
auch nur, wenn mir die Domain gehört, also ich könnte da reinschreiben, google.de, aber
ich bin nicht in der Lage, die DNS-Server, die für Google, also in dem Fall hier für
Google.de zuständig sind, umzubiegen auf Cloudflare. Dazu müsste ich bei Google sein. Ich könnte
Cloudflare zwar sagen, ich möchte google.de anlegen, aber nachdem ich die Domainserver
nicht umbiegen kann, wird das nicht funktionieren. So, also legen wir mal meine Domain an, progress.xyz,
add site, so, dann wird Cloudflare jetzt ein bisschen rumrödeln, drei Stunden später,
dann muss man den free plan selecten, weil sonst kostet Geld, und das wollen wir nicht,
was auch übrigens reicht, Cloudflare ist komplett kostenlos in der Basic-Variante, wenn man
einfach nur DNS machen will, und auch das Basic-Proxying kostet glaube ich nichts, erst
wenn man eine gewisse Anzahl von Traffic-Domains hat und sonst was, also man kann Cloudflare
ohne Probleme kostenlos verwenden, und zum Glück ist Cloudflare so nett und erlaubt
das verwenden des Dienstes ohne dass man ein Konto hinterlegen muss, also sprich bei AWS
und bei Azure ist es so, dass man immer, auch wenn man im Free-Kontingent bleibt, bei Azure
weiß ich gar nicht wie hoch das Free-Kontingent ist, aber bei Google beispielsweise ist es
glaube ich 300 Dollar im Monat, und man muss trotzdem eine Payment-Option hinterlegen,
obwohl man im Free-Kontingent ist, das ist bei Cloudflare nicht so, ich kann einfach
sagen, ok, oh, habe ich jetzt Free angeklickt, ja sonst müsste ich ja was bezahlen, so,
dann guckt Cloudflare jetzt nach, ob es da schon DNS-Einträge für gibt, und die werden
festgestellt, naja, da gibt es nix für, es gibt aber halt, ja gibt es nix für, Progress
XYZ, gibt es nix, wir legen auch erstmal nix an, wir wollen ja erstmal nur die Seite
adden, DNS-Records können wir später adden, so, und jetzt kommt das, was ich machen muss,
der sagt mir, ok, who is, sagt, mein Domain-Registrar ist dafür zuständig, ich muss jetzt bei meinem
Domain-Registrar hinterlegen, dass ich nicht mehr die hier verwenden will als DNS-Server,
sondern die hier, nämlich den Lars und Nia von, das sind halt die Nameserver-Namen von
Cloudflare, so, probieren wir uns das mal, Lars und was hier, Nia, nehmen wir mal Copy
Pasta und machen das dort rein, so, und das dauert jetzt eine halbe Stunde, ungefähr,
so, und jetzt habe ich bei meinem Domain-Registrar umgebogen, dass ich nicht mehr seine, dass
nicht mehr seine Server für zuständig sind, sondern, also für meine Domain, sondern die
Nameserver von Cloudflare, das dauert jetzt noch ein bisschen bis das ganze propagiert
ist, also sprich, wenn ich hier abfrage, werdet ihr sehen, ok, es ist immer noch, es ist immer
noch Porkban, das dauert so 10 Minuten, Viertelstunde, halbe Stunde oder sowas, dann ist das propagiert,
das sieht man dann auch hier in Cloudflare, wenn das alles funktioniert hat, dementsprechend
warten wir jetzt mal ab, ist eigentlich ziemlich easy, ich gucke hier alle paar Minuten mal
nach, bis das sich geändert hat und in der Zwischenzeit, bis die DNS-Geschichten aktiv
sind, können wir anfangen mit unserer VM, so, wir haben uns nämlich bei Digital Ocean,
eine Linux Ubuntu 20.04 angelegt, ja, das könnte man tatsächlich machen, das ist eine
gute Idee, können wir hier zugucken, wobei ich gar nicht weiß, ob das so eine gute Idee
ist, IP leaked, MonkaS, schau mal da, ich weiß gar nicht, ob das so eine gute Idee ist,
weil dann reflechst sich ja auch jedes Mal mein DNS-Cache, vielleicht lass ich mal alles
timeouten, wobei, nee, wenn ich direkt gegen 8888 gehe, hat ja mein DNS-Cache nichts damit
zu tun, da können wir uns tatsächlich, komm, bevor mich Google noch irgendwie blacklistet,
weil ich zu viele DNS-Anfragen spam, wir warten einfach mal ab, wenn wir können n sagen,
sonst, wir gucken einfach mal nachher weiter, wir machen jetzt hier, wir machen jetzt erstmal
weiter mit der Linux-Kiste, so, wir haben uns bei Digital Ocean, die billigste Linux-VM
ever angelegt, 0,7 Cent die Stunde, also wahnsinnige High-Performance-Kiste, die man bekommt für
0,7 Cent die Stunde und da fangen wir jetzt schon mal an, drauf Zeugs zu installieren,
was wir später für brauchen, wir können jetzt ja mit Cloudflare und Domains nicht
großartig weitermachen, weil wir noch drauf warten, bis die DNS-Geschichte durch ist, bis
die Änderungen durch sind, Tainser verschenkt 3 Subscriptions, gehts wieder los Leute, exzellent,
Dankeschön, wer kriegt denn was, wer kriegt denn was, Rionikfire kriegt eins, Yannik00000,
Phantimbo, exzellente Subscriptions hier, da platzt der Kopf gleich wieder, Stonks, also
was von, das ist die IP von unserer Linux-Kiste, wir können da später auch per Progas XYZ
drauf, allerdings aktuell noch nicht, weil die Namensauflösung nicht funktioniert, yes,
exzellent, so, okay mein Key ist im Invalid-Format, aber Connecten geht trotzdem, so das wichtigste
was man erstmal machen muss, man muss erstmal den Server umbenennen, ohne gehts nicht,
also als erstes ist, wir gehen mal nach etc-hostname und der Server heißt ab jetzt Qt-Chat, das
ist schonmal das allerwichtigste, so was man auch nicht vergessen darf, wenn man den Server-Namen
ändert, wenn man den Server-Namen ändert, dann muss man auch hier das ganze anpassen,
Qt-Chat, sonst packt Ubuntu rum, muss den Cooldown rausnehmen, Hä, Sebaro, was hast
du gemacht, hast du irgendein Nightbot-Kommando angelegt, ja ich sehs, weißt du was FRA 1,
FRA bedeutet, dass die Kisten in Frankfurt stehen, das ist irgendeine interne Bezeichnung
von Digital Ocean, aber das ist Standort Frankfurt, so und jetzt machen wir was, was man bei Linux
machen muss, das muss man nicht unbedingt machen, also, man kann glaub ich auch hostname-f machen
oder sowas, aber wir rebooten mal, dann übernimmt der alles und fährts Netzwerk neu hoch und
gut ist, wir gucken mal was unser Dick macht, unser Dick geht immer noch auf die Digital
Ocean, äh auf die, auf die PogPan und nicht auf Cloudflare-DNS, hat man bei Digital Ocean
auch IPv6, ja, hab ich noch nie ausprobiert, aber ziemlich sicher, muss ich hier vielleicht
erst noch OK klicken, dass das funktioniert, dann Check Name-Servers, oh Setup Later, ja
Progress is not, Progress is not yet active, ok, dann hat es noch nicht funktioniert, da
müssen wir wie gesagt, das dauert ne halbe, das dauert bis zu ne halbe Stunde bis das
propagiert ist, dass die Name-Servers sich geändert haben, aber wir sehens ja hier bei
meinem so Main-Registrar, ähm, können wir das Ganze mal refreshen, ich hab's ja geändert,
also sprich das passt, Progress XYZ zeigt jetzt auf Last NS Cloudflare, Nier NS Cloudflare,
schreiben wir ja hier, dass man das machen soll, dann warten wir mal ab, bis das Ganze
hier funktioniert, wir können mal gucken, ob Cloudflare selbst es schon gecheckt hat,
ne, Cloudflare selbst ist auch nicht gecheckt, wahrscheinlich hat es mein Domain-Provider
auch noch gar nicht gecheckt, ok, also weiter im Text, wir haben jetzt den Server gerade
neu gestartet, hier haben wir meinen PSSH wieder drauf, und das erste was wir erstmal
machen ist ein Update, das was wir machen ist ein Update gefolgt von einem Upgrade,
das macht man bei allen Servern, wenn man sie frisch installiert hat, dass man auf dem
aktuellen Stand ist, und gerade bei Servern die public im Internet erreichbar sind, weil
ansonsten ist das ziemlich fail, installierst du dann alles schön mit Kubernetes, ne, wir
machen das für einen Heimgebrauch, äh, passender, wir nehmen, ich will nicht sagen oldschool,
weil oldschool ist es nicht, wir nehmen die klassische Variante aus Docker und Docker
Compose, das ist nämlich deutlich praktikabler für Leute daheim als irgendwelche Kubernetes-Geschichten,
unten ist ein Recheck-Button, ja das bringt aber nichts zu rechecken solang es mein Domain-Registrar
noch nicht umgeschrieben hat, das wie gesagt, das kann durchaus mal eine halbe Stunde dauern,
aber nicht viel länger, so, jetzt lassen wir den erstmal updaten, die Ubuntu-Kiste,
wie funktionieren Hausnamen im Netzwerk, kennt der Router immer alle Hausnamen, ne, also
dein Router, wenn der ein DNS drauf hat, dann, äh, hat er einen DNS-Cache für, was, was
ist die Fault, acht Minuten oder so bei DNS, fünf Minuten, ähm, ok, also, der möchte
nicht updaten, weil meine SSHD-Config sich geändert hat, warum, showdiff, äh, permit
rootlogging, yes, permit rootlogging without password, ja, das will ich auf jeden Fall
haben, nicht, dass da noch einer mein, rootpassword, äh, hacksword, ja, rootlogging ohne Passwort,
vollkommen ok, das rootpassword zu hacksel mit ein bisschen schwierig, ich glaub das ist
standardmäßig irgendwie 28-stellig oder so, was macht Digital Ocean, immer noch nicht,
du, du, du, du, du, I'm in, ist klar Leute, glaubt euch nicht, denied, ne, Passwort aus
ist nicht deaktiviert gewesen, jetzt ist Passwort aus deaktiviert, bis eben war es noch aktiviert,
zumindest laut config, weil er hat eben gesagt beim Update, er möchte permit rootlogging,
yes zu permit rootlogging without password, hast du schon mal Artix Linux ausprobiert,
ne, oder Antix, meinst du Antix, Debian ohne Systemd, oh, jetzt fangen die wieder mit sowas
an, ich dachte, das haben wir hinter uns, ich dachte, Artix, nein, auf Artstellung basiert,
mit OpenRC, das sind die Systemd Hater, ja, ich weiß nicht, ich hab mich da mittlerweile
eigentlich gesagt dran gewöhnt, ich find auch vieles ein bisschen zu magic unter Systemd,
oh, ich hab jetzt da keine großartigen Schmerzen mit, so, wir haben ein Update gemacht, wir
müssen noch einmal neu starten, dass die Updates geladen werden, und dann können wir anfangen,
dann müssen wir docker compose, docker, und konfigurieren vielleicht schon ein bisschen
was, was macht Systemd, also die einfachste Erklärung ist dein System starten, allerdings
macht Systemd noch gerade mehr als dein System starten, also früher war das so, du hast
unter Linux jede Menge Shell-Skripte gehabt, die wurden nach und nach abgearbeitet und haben
halt alles gestartet, was man gebraucht hat, dass das System lauffähig ist, da war da so
was drinne wie in den Multi-User-Mode switchen und Netzwerk hochfahren und Login-Geschichten
starten und sowas, war da halt in einem Startup-Skript drinne, und das war relativ viel, also wenn
du ein Linux-System gebootet hast, mit dem alten Init, war das relativ viel Skripte und
das hat auch eine Weile gedauert, Systemd hat gesagt, ok, wir machen was ähnliches,
nur, dass wir noch Abhängigkeiten definieren können und keine klassischen Shell-Skripte
untereinander mehr verlinken, und dementsprechend kann Systemd dein System quasi parallelisiert
starten, und ist eigentlich auch das, wofür Systemd grundsätzlich da ist, dein System
starten, die Sache ist bloß die, dass Systemd mittlerweile noch viel mehr Aufgaben übernommen
wird, von Hardware-Erkennung teilweise bis DHCP fürs Netzwerk, Bootmanager für Systemd
gibt's auch noch, also Systemd breitet sich aus überall hin, das ist auch so das, wo
die Leute, die hauptsächliche Kritik immer an Systemd ist, dass Systemd das zu viel machen
würde, wobei Systemd selbst recht modular ist, also man muss den ganzen Kram nicht verwenden.
So, jetzt haben wir unsere Ledungskiste am Start, und wir gucken mal kurz, was Cloudflare
macht, ob's Cloudflare schon hinkriegt, immer noch nicht, ah, guck mal, es propagatet, langsam
aber sicher, je nachdem auf welchem DNS-Server du rauskommst, ist es schon das alte und ist
es mal das neue, guck's, also bei der Google DNS 8888, das ist ja irgendein Loadbalancer,
wo man rauskommt, wo unter der Haube unterschiedliche DNS-Server sind, die haben ja nicht einen
DNS-Server da stehen, für alle Anfragen, die das Ding kriegt, also, das müssen wir
noch 2-3 Minuten warten, dann haben's alle Server drinne und alle Server kapiert, dass
wir jetzt Cloudflare für unsere Domain verwenden wollen.
Gut, also wir installieren jetzt mal, damit wir das hier machen können, wie gesagt, wir
sind jetzt auf dieser Kiste hier in der Zeichnung, da, auf dem Ubuntu-Server, wir installieren
jetzt Docker drauf, damit wir unsere Container starten können und Docker Compose, dass wir
Docker reproduzierbar konfigurieren können, das ist ne Sache, wenn man das im Heimbereich
macht, ist das nice to have, ich zeig da euch gleich mal auch mal, was die Vorteile davon
sind, aber man lernt dafür einiges, was man auch auf der Arbeit verwenden kann, weil,
es mag jetzt banal aussehen, man hat ein Konfig-File und dann sagt man Start und Docker Compose
macht alles, was in diesem Konfig-File steht, allerdings, wir wären nicht in der IT-Welt,
wenn's dafür nicht einen super krassen Buzzword-Namen gäbe und das Ganze läuft unter Infrastructure
as Code, klingt natürlich toll, ja, das natürlich dann noch gepaart mit Serverless Microservices
in der Cloud, dann platzt der Kopf, mehr Buzzwords, also installieren wir erstmal Docker Compose,
ihr werdet auch gleich sehen, was was macht, ich installiere jetzt erstmal, dass man sieht
und Blockchain natürlich noch, richtig, Idee für den nächsten Stream Twitch-Statistiken
analysieren. Ja, weil's mir besser gefällt. Ja, kann man, kann man, also es funktioniert
grundsätzlich anders, aber es ist sowas ähnliches wie Ansible für Docker-Container, das betrifft,
beschreibt's eigentlich ganz gut. Mir gefällt Ubuntu als Serversystem schlicht und ergreifend
besser als die anderen. Auf der Arbeit verwenden wir nur Red Hat, also als CentOS in dem Fall
und dementsprechend, ich verwende privat halt dann für alles, was ich so hab, Ubuntu Server.
Jungen Sieben Snorlax abonniert Stufe 1 zum ersten Mal Subscriber, hei hei hei. Nein,
Moment, ist doch gar kein Prime, ist ja, ist ja ein richtiger, echter. Exzellent, exzellent,
wahrlich exzellent. So, das war jetzt genug Huldigung für den ersten Sub. Du hast gesagt,
dass du Subs, siehste, da warst du das doch gestern, der das gesagt hat. Hab ich doch
richtig in Erinnerung gehabt, war ich doch nicht so low-brain. Hat deine Anfrage bezüglich
Programmierprojekte auf der Arbeit Erfolg gehabt? Gut, dass du mich dran erinnerst,
ich hab das schon wieder voll vergessen und mein Chef hat das auch wieder voll vergessen.
Weil wir hatten schon unsere nächste Rücksprache und wir haben beide nichts mehr dazu gesagt.
Gut, der Twitch Chat, Twitch Chat ist halt Big Brain, der erinnert mich an solche Sachen.
Klassiker, ja. So, also, ähm, wir haben Docker Compose installiert, jetzt können wir anfangen
das Ganze zu benutzen. Also unser Ziel ist ja, dass wir jetzt auf diesem Ubuntu Server
einen Docker Container, also Docker zum Laufen bekommen und darin einmal Traffic starten
als Load Balancer bzw. Reverse Proxy und so einen Hallo Welt Container oder sowas. So,
und das ist tatsächlich ziemlich simpel, allerdings, vorher müssen wir noch ein paar Kleinigkeiten
erledigen, dass das Ganze, dass das Ganze gut funktioniert. Wir fügen erstmal den User
hinzu, weil man Container und das ganze Zeug als Root machen ist jetzt nicht unbedingt
so, wie sagt man so schön, best practice. Ähm, deswegen machen wir jetzt erstmal add
user, Max, new password 123456, click w. Wobei sollte ich das lieber, sollte ich das machen?
Moment, ich muss mal kurz was checken. Ist Password Login aktiviert? Nicht dass jetzt
gleich sich wirklich einer einloggt, Alter. Max, Perperition Denied Public Key. Ok, dann
ist alles gut, dann kann ich das machen. Oh, jetzt hab ich's verkackt, jetzt hab ich abgebrochen.
Äh, su, Max, ok. Wir machen jetzt allerdings noch eine Sache, wir disablen den User auch
gleich wieder und sagen PassWD minus L ist es glaube ich, Max und das disabelt den interaktiven
Login und das Anmelden mit dem User. Allerdings als Root können wir immer noch dieser User
werden und es ist ja best practice, dass man nicht Docker und Zeugs als Rootlauf lässt.
Warum nicht Nginx? Hat den einfachen Grund, weil Traffic eine super Docker Integration
hat. Das kann sich automatisch auslesen, was für Docker Container laufen, gucken mit welchen
Domains die konfiguriert werden sollen, automatisch Zertifikate dafür holen und dann intern noch
das Proxen auf die Container automatisch machen. Kann man da alles mit Nginx machen? Gut, Docker
PS, guck mal mal, geht nicht, weil ich muss meinen User noch in die Docker Gruppe hinzufügen.
Ah, minus G, Docker Max, passt das? Docker PS, exellent. So, wir sind auf dem Ubuntu
Server drauf, Docker läuft und wir können jetzt ein paar Sachen anlegen. Wir machen
uns mal ein Ordner, nennen wir mal Compose, Compose und da erstellen wir jetzt einen Docker
Compose Jammel oder Jimmel oder so, je nachdem, wie man es will. So, und in diese Konfig-Datei
schreiben wir jetzt rein, was wir für Services verwenden wollen und wie die konfiguriert
werden sollen. Der große Vorteil davon ist, also, man wird es gleich im Detail sehen,
wie das funktioniert. Der große Vorteil davon ist, man hat jegliche Konfig, was Container
und Load Balancing und Zertifikat angeht, in einem Konfig-File. Das kann man versionieren
in Git und wenn man einen neuen Server installiert, clone man sich einfach sein Git-Repo, sagt
Docker Compose ab und es ist wieder alles wie vorher. Soweit die Theorie. Es gibt ein paar
Falschschritte bei, nicht so einfach, wie es sich jetzt anhört, aber das ist prinzipiell
der riesen Vorteil davon, dass man alles schön in einem Konfig-File hat und nicht, dass man
anfangen muss, die Sachen von Anfang an zu konfigurieren. Das nächste ist, was wir hier
bauen werden, das mit dem Reverse-Proxy, ist der Vorteil, dass man nach außen hin nur einen
Einstiegspunkt hat. Infrastructure als Code sein Vater. Ja, das trifft es eigentlich
ganz gut. Ist ja so das Hype-Wort aktuell, aber das ist schon recht Oldschool-Variante.
Gibt es schon lange, aber im Heimbereich finde ich, ist immer noch das Beste, was man machen
kann. Jaml-File, Docker Compose und gut ist. Da muss man gar nicht mit irgendwelchen überladenen
Dingern anfangen, die eher dafür sorgen, dass man sich Sachen kaputt macht und nicht wieder
repariert bekommt daheim. So und das Schöne ist, wenn man das mit einem Reverse-Proxy
vor den einzelnen Servicers macht. By the way, da fehlen nämlich noch ein paar Pfeile
zwischen dem hier und dem. Kann ich denn von hier? Er ist übrigens umgedreht. What the
fuck macht das? Kann ich nicht von hier, ich will von hier einen Pfeil machen. Das ist
Low-Brain-Software. Also so ist es ja eigentlich. Das heißt, ich hab von außen nur einen Einstiegspunkt.
Das führt dazu, dass man einen sicheren Einstiegspunkt hat, wo man weiß, dass der auch für sowas
ausgelegt ist. Also sprich, da muss man sich keinen, also setz mal einen gehärteten Einstiegspunkt,
also sprich, die Leute connecten sich nicht da drauf, da drauf, da drauf, die Leute connecten
sich da drauf und werden hierhin weitergeproxied. Das heißt, die müssen erstmal hier durch
und wenn man hier beispielsweise eine Basic-Authentifizierung mit Passwort konfiguriert hat, kommen die
Leute auch erst da raus, wenn sie hier das richtige Passwort eingegeben haben. Also sprich,
man kann dahinter auch Dienste betreiben, die keinerlei Authentifizierung haben und
ihnen damit relativ einfach eine Authentifizierung verpassen und von außen ist nichts erreichbar
dieser Sachen, nur hier über den Reverse-Proxy. Was, wenn ich Traffic lokal mache mit dem
Proxy, ist die Domain nur lokal rootbar oder auch im Internet, also Domains sind prinzipiell
nicht rootbar, IP-Adressen sind rootbar und Domains lösen zu IP-Adressen auf und wenn
die IP-Adresse rootbar ist, dann funktioniert's. Kann Traffic auch loadbalancing? Ja, aber
habe ich noch nie gemacht. Ein weiterer Vorteil ist, dass die Konfiguration weiterer Services,
also mal angenommen, ich will hier dann noch einen Fileserver, okay Fileserver ist ein
doofes Beispiel dafür, ich will hier irgendwie noch einen zweiten, noch einen dritten Webserver
haben, ich will hier noch irgendwelche Dashboards haben, ich will hier noch einen Grafana haben,
ein Prometheus, was auch immer, solche Service-Container dahinter sind extrem easy erstellt und ich
muss mir keine Gedanken machen, dass ich irgendwie mein System zerschieße oder angreifbar mache,
weil ich hier an meinem Reverse-Proxy-Config gar nichts großartig ändere, ich starte einfach
einen neuen Backend-Container und der wird dann geproxied und gut ist. Und ein weiterer
riesiger Vorteil davon ist auch, man kann die Dinge hier relativ einfach updaten, es gibt
sogar einen fertigen, es gibt sogar ein fertiges, fertigen Docker-Container, der andere Container
updatet, nach Regeln, die man vorgibt. Anno schreibt, endlich Feierabend, heute Prot-Deployment
war bei uns, äh warte mal, was ist heute Mittwoch, war bei uns gestern, ähm, bei dem so ziemlich
alles schief ging, Q hat gefehlt, wodurch wir dann einen ungewollten Festplatten-Benchmark
hatten, 16 GB Log-File in 4 Minuten, ach ja, einfach mal ein paar SSDs kaufen, ne, aber
am Ende ist doch hoffentlich alles gut gegangen, oder? Ich sag mal, kann das sein, dass die
Playlist vorbei ist? Was ist hier los, gleich nochmal, excellent Playlist, ähm, genau und
Auto-Update ist auch ein Vorteil davon. So und damit ihr jetzt mal eine bessere Vorstellung
bekommt davon, was man, wie das Ganze funktioniert. Ich muss dazu sagen, ich guck ein bisschen
ab, ich schreib jetzt diese Config-Datei nicht blind oder so, ähm, weil ganz aus dem Kopf
krieg ich's auch nicht, ich guck ein bisschen ab. Ähm, kann alles easy in einem Docker-Container,
also Wasserfreak fragt, kann alles easy in einem Docker-Container installiert werden,
insbesondere TS-Server, Minecraft-Server? Zum größten Teil kann alles, also das meiste
kann in einem Docker-Container installiert werden. Es gibt ein paar Ausnahmen, es gibt
ein paar Ausnahmen. Zum Beispiel, wenn du spezielle Kernel-Modulo brauchst, dann geht
das im Docker-Container nicht. Weil Docker-Container können, also Docker-Container sind ja, das,
Container ist eben ein total doofes Wort. Container suggeriert ja irgendwie, als wäre
das ein eigenes System oder so, ist das ja gar nicht richtig. Also es ist ein ganz normaler
Prozess im Host-Kernel, wie alles andere auch, nur dass noch ein paar Namespaces und
Seagroups drumherum sind, also Container in dem Sinn ist das ja eigentlich gar nicht,
wir nennen es halt nur so. So, und nachdem das ein ganz normaler Prozess ist, der auf
dem Host-Kernel läuft, kannst du auch keine Software im Docker-Container verwenden, das
irgendwelche Kernel-Module laden will oder so, das funktioniert nicht.
Lass dir den Code vom Chat ansagen. Wenn ich mir vom Chat sagen lasse, was ich programmieren
soll, dann wird das eher Monarch-S. So, und das was du vorhast, TeamSpeak und Minecraft
geht ohne Probleme im Docker. Du hast sogar ein paar Vorteile dadurch, du kannst das Ding
Memory, relativ gut Memory und CPU beschränken. Also es geht eigentlich alles, es geht eigentlich
alles in einem Docker-Container, was jetzt nicht Kernel-Module braucht. Es gibt bestimmt
die ein oder anderen Ausnahmen, die mir jetzt gerade nicht wirklich viele einfallen. Kernel-Module
ist das, was mir als erstes einfällt, wo es nicht im Docker-Container geht. Ich mein
klar, man könnte im Host-Kernel das Modul laden und dann wird es wahrscheinlich auch
im Docker-Container gehen, aber vielleicht will man das Ganze ja nicht.
Zumindest wenn das Programm irgendwie versucht oder irgendwie ein Kernel-Modul braucht, was
nicht geladen ist, dann geht das nicht im Docker-Container. Also du kannst beispielsweise schlechten
Virtual-Box in Docker verwenden. Soll ich sagen. Aber ansonsten geht nahezu alles in
Docker. Im Umkehrschluss, was aus irgendwelchen Gründen mit dem Host-Kernel nicht läuft, läuft
allerdings auch im Docker-Container nicht. So, also jetzt so, dass ihr eine bisschen
bessere Vorstellung kriegt davon, was hier eigentlich läuft. So, wir haben Docker-Compose
installiert. Als Abhängigkeit wurde Docker installiert, allerdings Docker selbst werden
wir gar nicht verwenden. Ich habe ja gesagt, wir wollen eine Config-Datei erstellen, die
dann mit Docker-Compose am Ende die Container so aufbaut, wie wir das haben wollen. Und
was wir verwenden werden, ist das Kommando Docker-Compose. Und das kennt eigentlich nur
zwei Sachen. Docker-Compose ab, dann wird alles, was in der Docker-Compose-Yaml-Datei
drinne steht, angelegt und Docker-Compose down, dann wird alles, was in Docker-Compose
definiert ist, gestoppt. Es gibt noch Sachen wie Force stoppen und auch Images löschen
oder so. Aber das sind so die standardmäßigen Sachen. Also, man hat eine Docker-Compose-Datei,
da steht alles drin, was man konfigurieren will. Man geht in den Ordner rein, sagt Docker-Compose
ab. Und dann, ne, die Datei ist jetzt leer, deswegen geht's nicht. Dann startet er alles
und mit down macht er alles weg. So, dann machen wir jetzt mal testweise ein Container rein.
Und das erste, was man machen muss in so einem Docker-Compose-File, kurz überlegen, habe
ich alles gemacht, was ich machen wollte? Ich glaub schon. Genau, also wir legen jetzt
mal einen, den minimalsten Container an in Docker, den es so gibt. Das erste, was man
in einer Docker-Compose-Datei machen muss, oder macht Max das für sich? Ne, nachdem
ich das auf dem Digital-Ocean-Server mache, mache ich das nicht für mich. Das habe ich
bei mir schon laufen. Das erste, was man machen muss in einer Docker-Compose-Yaml ist eine
Versionsnummer angeben. Zum Beispiel 3.3. Das muss man bei den meisten Config-Dateien
nicht. Ich finde, die machen das mit Docker-Compose aber relativ clever. Wenn die neue Version
rausbringen, die neue Parameter unterstützen oder ändern, dann machen sie das nicht einfach,
updaten sie das nicht einfach, sondern sie sagen, okay, das braucht eine neue Version.
Was verkürzt heißt, dass eine Docker-Compose-Datei immer funktioniert, egal mit welcher Docker-Compose-Version
man sie verwendet. Hauptsache sie ist neuer als die, mit der ich es ursprünglich angelegt
habe. Das heißt, ich gebe jetzt hier an Version 3.3 und selbst wenn wir mal Docker-Compose
in 10 Jahren haben, dann wird die Config-Datei immer ausgeführt mit dem Config-Befehlssatz,
der zu Version 3.3 aktuell war. Das heißt, bei einem Docker-Compose-Update kann es nie
sein, dass meine Config nicht mehr funktioniert. Und das ist natürlich ne wichtige Geschichte.
Ich möchte vielleicht mal neue Parameter verwenden, dann mach ich die Version ein bisschen höher
und verwende eine neue Docker-Compose-Version, dann kann ich die verwenden, aber ich kann
mir immer sicher sein, dass der Kram, wenn die Docker-Compose-Version, die ich verwende
mindestens so alt ist, wie die Version, die ich benutzt habe, um das zu erstellen, immer
funktioniert. Das ist ganz wichtig bei sowas, weil ich hab ja keinen Bock. Stellt euch mal
vor, ich hab jetzt hier meinen Server laufen, mit Docker-Compose von Ubuntu 16.04 oder 14.04.
So, ich update den Server auf Ubuntu 20.04, hab jetzt Docker-Compose, was 4 Jahre neuer
ist, und es unterstützt die Hälfte nicht mehr, und ich kann meine ganze Containerumgebung
nicht benutzen. Das wäre natürlich kacke. So, und durch diese Versionsgeschichte ist
ganz einfach, die aktuellste Docker-Compose-Version benutzt weiter den uralt-config-Satz und gut
ist. Und es funktioniert auf jeden Fall. So, also was wir jetzt machen mussten, wie gesagt,
als erst mal ne Version angeben. Das wollte ich jetzt bloß mal zur Version erklären.
Und dann ist ein Docker-Container anzulegen ziemlich einfach. Man sagt einfach Services,
und unter Services kann man alles, kann man die unterschiedlichen Container definieren,
die man haben will. Zum Üben, wenn man einfach nur nen Test-Docker-Container braucht, ist
der hier immer ziemlich gut. Das ist quasi nen Hello-World, nen Hello-World-Docker-Container,
wenn man es so will. Der macht nichts anderes, wie wenn man draufgeht zu sagen, hallo, ich
bin ein Docker-Container. So, und in dieser Docker-Compose-Datei kann man verschiedenste
Sachen anlegen. Das Einfachste ist nen Service, und nen Service ist unterm Strich nen Docker-Container.
So, das heißt wir wollen jetzt einen Who-Am-I-Docker-Container anlegen. Warum ist die Standard-Einrückung
bei Wim eigentlich Tabs? Wer hat sich das ausgedacht? Das ist total aberlich. So, da
muss man sagen, welches Image verwendet werden soll. Das hatten wir hier grad schon. Dieses
Image wollen wir verwenden, als Who-Am-I-Container. Dann wollen wir sagen, muss man nicht machen,
mache ich aber immer ganz gerne. Container-Name, das Ding soll Who-Am-I heißen. Und das war's,
erst mal, erst mal war's das. Und wenn man jetzt, also das ist das Simpelste, was man
machen kann, man wird nicht viel von haben, aber ich zeig's euch mal, dass es funktioniert.
Also sprich, ich hab jetzt in Docker-Compose gesagt, ok, ich möchte Docker-Compose Version
3.3 verwenden und ich möchte einen Service anlegen, der sich Who-Am-I nennt und dieses
Container-Image verwendet. So, an Visual Studio Codeserver, oh, das ist eine gute Idee, das
probieren wir gleich mal aus, später. Codeserver, ja, gute Idee. So, und wenn ich jetzt Docker-Compose
abmache, dann startet der, diesen Who-Am-I-Container. So, und man sieht, Docker-Compose ist gestartet,
hat den Container gestartet und hat die Umgebung so konfiguriert, wie ich das haben will. Mach
mal minus D, dann kann ich weiter was tippen. Also, wenn ich Docker-Compose ps mache, sehe
ich, ok, es läuft halt ein Container, Docker-PS läuft auch ein Container, hat funktioniert.
Also sprich, ich hab meine Config-Datei, wo drin steht, wie die Umgebung aussehen soll,
meinten, wie mein Environment aussehen soll und Docker-Compose konfiguriert das quasi
so, wie ich sie in meiner Config-Datei beschrieben habe. Deswegen nennt man diesen Ansatz auch
Infrastructure as Code. Also sprich, man definiert in der Config-Datei, wie seine Infrastruktur,
wie seine Umgebung, wie sein Environment aussehen soll und dann hat man irgendein Config-Management-Programm,
was das umsetzt. Das ist ein anderer Ansatz zu früher, wo man quasi in den Linux-Server
installiert hat, dann sich PSSH drauf eingeloggt hat, sich Programme installiert hat, sondern
jetzt definiert man einfach nur, wie soll die Umgebung aussehen und sagt dann Docker-Compose,
ach, war nicht bei Ubuntu auch die Netzwerk-Config in Jaml. Ja, mittlerweile schon. Da gab es
verschiedene Zwischenschritte, es gibt sowas auch für nackische Linux-Server, sowas wie
Puppet oder Ansible gibt es noch, Chef gibt es auch noch, Saltstack und was es nicht alles
noch gibt. Ist aber jetzt in dem Fall wurscht, wir benutzen Docker und das können wir auch
mit dem Docker-Config-Tool nehmen. Das ist so die grundsätzliche Funktionsweise von Docker-Compose.
Also man hat eine Config-Datei, in der man sagt, wie soll das Ganze aussehen und mit
Docker-Compose startet und stoppt man dann die Umgebung. So, soweit von der TUI hier.
Natürlich bringt uns das jetzt nicht sonderlich viel, wenn wir dann Hallo-Welt-Container haben,
ich kann euch übrigens mal zeigen, dass der Hallo, oh, bye. Ne, gucken wir uns später
an, ob der Hallo-Welt-Container wirklich funktioniert. So, und jetzt ist ja unser Ziel nicht, dass
wir einen Hallo-Welt-Container gestartet haben. Machen wir mal hier, schreiben wir den mal
hin. Den haben wir gerade gestartet, den Container. Allerdings, ihr werdet sehen, wenn ich den
jetzt starte, ihr kommt da nicht drauf. Warte mal, "-d", ihr kommt da nicht drauf. Also sprich,
hier meine IP von dem Server. What the fuck, wo ist mein Server-IP? Da. Also da könnt
ihr ja mal mit dem Browser hingehen und das aufmachen. Wir feststellen, ne, geht nicht.
Und selbst wenn man einen Nmap macht, ich komm wieder, die Hexer geschickt, wie? Kein
Nmap am Start. Nmap installieren. Nmap ist ein Portscanner, der guckt, was auf dem Server
alles läuft. Selbst wenn ich jetzt mal einen Portscan mache auf die IP. Chat, big brain,
was schmeißt der Portscan aus für ein Port oder für Ports? Hat jemand eine Idee? Ja,
22, korrekt. Das Einzige, was auf dem Server laufen sollte, ist, offen sein sollte, ist
Port 22. Port 22 ist SSH, das ist, worüber ich mich auf den Server verbunden hab. Und
ihr seht, kein Port 80, obwohl Docker Compose sagt, es läuft auf Port 80. Das liegt daran,
es läuft nicht auf Port 80 auf irgendwie meinem externen Interface, sondern auf einem internen
Docker Interface. So, und das ist das, wozu ich jetzt meinen Reverse-Proxy brauche, sprich,
diese Service-Container, die sind nicht von außen zugänglich, die laufen auf einem internen
Interface und der Reverse-Proxy, der ist von außen zugänglich und der Proxy, die jetzt
anfragen, die von außen kommen, auf die jeweiligen Container dahinter. So, und wir legen jetzt
mal, wir starten jetzt mal ein Reverse-Proxy und dann könnt ihr in eurem Browser auf
die Seite gehen und das Ganze aufmachen und gucken, ob das funktioniert. So, und das Ganze
machen wir mit Traffic. Wir machen das ohne HTTP, erst ohne SSL, einfach ganz stinknormales
HTTP. Also dann sagen wir jetzt erstmal, wir wollen noch einen, wie gesagt, ein bisschen
abgucken muss ich. Wie gesagt, wir wollen noch einen Traffic-Container haben. Wim-Eindrückung
standardmäßig, MonkaS. DNS-Records einrichten, mal mal gleich. Wir gucken uns das erst mit
der IP an, dass es funktioniert und dann richten wir DNS-Records ein. DNS-Records, wo war
man denn hier bei DNS-Records? Hat's Cloudflare jetzt eigentlich gecheckt? Great News, Cloudflare
is protecting your site. Sehr gut, dann hat's funktioniert. Poggers. Genau, also wir legen
den Traffic-Container an, das ist das, was denn die Reverse-Proxy-Geschichte im Ende
macht. So, und damit das Ganze funktioniert, muss ich ihm erstmal das Image sagen, was
er verwenden soll. Image ist, da kann man hier auf Docker Hub gucken, was man da für
Versionsnummern verwenden möchte. So, wenn wir jetzt mal auf Docker Hub gucken, was es
für Tags gibt, dann sieht man hier, Latest ist immer das Aktuellste. Was ich empfehlen
würde, ist nicht unbedingt Latest zu verwenden bei sowas Wichtigem wie eurem Loadbalancer
beziehungsweise Reverse-Proxy, sondern vielleicht die letzte Major-Version. Sowas hier, V2.2
oder hier 2.2. So, und wenn ihr diese Version nehmt als Tag, also sprich, welches Image
ihr verwenden möchtet, dann ist es meistens so, dass Version 2.2 auch 2.2.1 einschließt
und erst 2.3 oder 3.0 nicht mehr, je nachdem, wie das gemacht ist. Und Latest mit Auto-Update
kann man machen, würde ich aber bei meinem Eingang zu meiner Infrastruktur nicht unbedingt
machen, weil wenn ihr das mal updatet und euer Konfig da nicht mal funktioniert oder
nicht mal startet oder kaputt ist, dann geht alles dahinter auch nicht mehr. Also, die
letzte Major-Version ist schon nicht verkehrt. Also, Traffic, nehmen wir mal 2.2. Den Container
wollen wir anlegen, machen wir hier ein Leerzeichen dazwischen. Dann sagen wir mal, wir wollen
dem Ding noch einen Namen geben, Container Name. Wir können übrigens, ich zeig euch
mal Big Brain Vim Magic. Habt ihr das gesehen? So, Monka ist Monka Vim, Alter. So, das Ding
Container nennen wir Traffic. Und jetzt kommt ein bisschen Magic. Das kann man übrigens
Docker Traffic Docs, kann man sich bei denen auf der Seite auch angucken. Wer genau wissen
will, was die einzelnen Sachen machen und dem meine Erklärung nicht reichen, der kann
sich auch Compose, der kann sich auch die Docs auf der offiziellen Seite angucken. Also,
wir müssen jetzt, also was der jetzt machen würde, wenn ich jetzt sage, Docker Compose
leg los, dann legt er mir einen Container an mit Traffic drauf und einen Container an
mit Who Am I. Allerdings, ohne Config für mein Reverse Proxy, Ateez, da hast du recht,
die V1 Docs und auch die Config für V1 fand ich persönlich viel schöner als für V2.
V2 musst du so krass rum suchen, bis du irgendwas findest. Allein, wie kompliziert das ist,
um Redirect zu machen von HTTP auf HTTPS, da kriegste Anfälle. Das steht noch nicht
bei den offiziellen Docs drinne. Das ist so ein typischer Fall von, sie haben relativ
viele Docs, aber das, was du wissen willst, steht nicht drinne. Ja, also da kann ich auch,
die darf ich nicht zu sehr loben für ihre Docs. Aber ich bin ja froh, dass ich nicht
der einzige bin, der das so sieht. Also wäre Nginx einfacher, wenn man keinen Docker machen
will. Ja. Allerdings, wenn man keinen Docker machen will, würde ich wahrscheinlich Caddy
nennen, weil Caddy ist wirklich idiotensicher. Caddy ist absolut Low-Brain-Reverse-Proxy,
den jeder verwenden kann. Aber persönlich würde ich wahrscheinlich auch Nginx verwenden,
wenn es wirklich drauf ankommt. Auf unserem Server, wo ich habe ja schon ein paar mal
erzählt, dass ich ja gerade so ein Projekt laufen habe mit einem Arbeitskollege, wo
wir so eine Routenplanning-Software programmieren bzw. testen für Handwerker, da läuft auch
ein Caddy davor. Caddy pro User, eine Domain und dann balancet auf eine eigene Instanz
von der Anwendung dahinter. So, also, jetzt müssen wir den Traffic-Container, wie schreibt
man das? Caddy. So schreibt man Caddy. So wie der, ja, aber Proxy. Der da. Caddyserver.com.
So, also, was wir jetzt machen ist, wir müssen unseren Reverse-Proxy konfigurieren. Und was
ich ja schon gesagt habe, der große Vorteil von Traffic ist, der kapiert Docker-Config.
Man kann ihm jetzt sagen, Commands ist das, was beim Starten dem Container als Parameter
mitgegeben wird. Also sprich, das Kommando, was in dem Container gestartet wird, was das
für Argumente mitkriegt. So, und jetzt können wir den Traffic-Container konfigurieren. Als
erstes sagt man Folgendes, das Copy-Paste ich mir jetzt von der offiziellen Webseite. Nein,
das sagen wir übrigens nicht. Als erste sagt man, als Provider, also sprich als Info-Quelle,
als Source, wo er sich quasi Informationen herholen kann, wollen wir unter anderem Docker verwenden.
Also sprich, damit sagen wir eben, du kannst, guck mal bei Docker nach, was da für Container
laufen, ob du die nicht irgendwie balancen kannst. Also der kennt die dann schon. So,
das ist das erste Parameter, was wir ihm übergeben müssen. Dann ein Parameter, den ich immer
verwende, ist der hier, den Copy-Paste ich mir jetzt mal, Exposed by Default False. Das
bedeutet, dass, wenn man das hier weglässt, wird der jeden Container, den man hier unter
Services stehen hat, also jeden Container, den man hier einträgt, automatisch Proxien
beziehungsweise balancen. Und das will ich nicht, ich will bei jedem Container von Hand
sagen, ja, den möchte ich Exposen nach außen. Das heißt, ich muss dann bei diesem Container
unten auch konfigurieren, dass ich das machen möchte. So, dann muss ich ihm als nächstes
sagen, wir brauchen Ports. So, und dann nehmen wir mal standardmäßig die Ports hier, die
Copy-Paste ich mir jetzt rein. Set Paste, das da. Also sprich, Einstiegspunkte Port 80
und Port 443. Warum? Weil Port 80 HTTP und SSL halt 443 ist. Äh, Extreme Nerd, fragt
kann man damit auch zwei verschiedene Domains auf einen Host wenden? Ja, das ist ja grad
der Sinn und Zweck, warum man sowas macht. Ich werd's euch gleich zeigen, wie schön
einfach und unglaublich praktisch das ist im Betrieb. Übrigens, ich glaube, ich hab
das hier verkehrt eingerückt. Wow, Wim, was machst du da? Please. Alter, geh fort, Wim,
please. Mach keinen Scheiß, Alter. Ah. Okay, haben's gefixt. Äh, okay, also, wir haben
ihm jetzt gesagt, wir wollen als Einstiegspunkt Port 80 und Port 443 haben. Als nächstes
müssen wir ihm die Ports sagen, die Docker weiterleiten soll. So, und als Ports ist in
dem Fall relativ klar, wir wollen Port 80 von außen auf Port 80 von Traffic weiterleiten,
weil also, Traffic startet mit Port 80 und Port 443. Was wir in der Ports-Konfig sagen
ist, was ist von außen erreichbar? Äh, Vhost. Ein bisschen wie Vhosts, ja, ein bisschen.
Zumindest ein Teil von Vhosts, so. Und wir wollen Port 443 von außen auf Traffic Port
443 weiterleiten. Das machen wir mal. Ähm, machen wir sonst noch irgendwas? Ah ja, eine
Sache muss man noch sagen, wir müssen dem Traffic-Container Zugriff geben auf unsere
Docker-Instanz. Das macht man normalerweise nicht, weil was man damit macht ist, man gibt
die, quasi, man gibt einem Container die Kontrolle über den Container-Manager, was
ja irgendwie sich ein bisschen wirr anhört, aber in dem Fall ist es sinnvoll, weil der
soll ja abfragen können von Docker, was für Container alles laufen. Das muss man aber
sich Gedanken zu machen, das sollte man nicht standardmäßig irgendwie einfügen, ja. So,
jetzt geben wir Traffic Zugriff auf unsere Docker-Instanz. Read-Only. Wohlgemerkt, also
er kann da nichts ändern, er kann aber auslesen, was man vielleicht auch unbedingt will. Und
als letztes müssen wir jetzt noch dem Who-Am-I-Container sagen, dass Traffic ihn verwenden soll. Und
das funktioniert folgendermaßen, wir gehen bei Who-Am-I in und sagen Label, äh, Labels
und als erstes mal sagen wir eben, ich kopiere mir das jetzt einfach mal, ist glaube ich
einfacher. So, also als erstes sagt man ihm, dass Traffic diesen Container balancen soll,
ich sag übrigens lieber mal balancen, ist es in dem Fall Proxyn, aber balancen kommt
mir einfach einfacher über die Lippen, ja. Ähm, also als erstes sagt, weil hier oben
haben wir ja gesagt, exposed by default, false. Das heißt, wir müssen jetzt jeden Container,
den wir nach außen hin anbieten wollen, müssen wir jetzt explizit sagen, diesen Container
soll nach außen hin angeboten werden. Dann sagt man hier die Domain, G-Stalls 90, Juhu
weiter, so exzellent, drei Monate, Dankeschön. Ähm, hier sagt man die Domain, die man verwenden
möchte, in dem Fall nehmen wir mal ping, ping.broggers.xyz. Domains müssen wir gleich noch einrichten,
haben wir noch nicht gemacht, ne. Ähm, und unten drunter als letztes sagen wir Entry
Points Web, Entry Points Web ist Port 80, kein HTTPS oder sonst was. So, das ist unsere
Standard-Config, speichern wir und sagen, ich kann euch jetzt schon gleich sagen, funktioniert
noch nicht, weil unser DNS noch nicht funktioniert, wir sagen docker-compose ab. So, und der konfiguriert
jetzt komplett unsere Container, unsere Infrastruktur so, wie wir das haben wollen, docker-compose
HTTPS, es laufen zwei Container, dann Traffic nach außen hin, von außen erreichbar auf
ähm, ah, Port, Port, Port und der hier hinterlauft Port 80. So, wie gesagt, ich weiß, dass es
noch nicht funktioniert, aber ich erkläre euch noch gleich, warum es nicht funktioniert.
Ähm, wenn man sich die Logs anguckt, wird man auch sehen, naja, passiert nicht allzu
viel. So, ähm, was ich jetzt machen kann ist, ich kann noch mal auf die IP gehen, wenn
ich die IP finde, ja, wenn ich jetzt auf die IP gehe, sehe ich schon mal, aha, ist schon
ein bisschen mehr wie vorher, da läuft jetzt was, da läuft jetzt was, was mir sagt, aha,
Seite nicht gefunden. Warum Seite nicht gefunden? Naja, der weiß ja gar nicht, wo ich hin will.
Im Prinzip passiert jetzt folgendes, es schlägt irgendwas auf dem Reverse-Proxy auf, aber
der Reverse-Proxy, das ist ein Proxy, der weiß ja nicht, wohin, also sprich, der Reverse-Proxy
hat bei diesem Request keinen plassen Schimmer, auf welchen der Container dahinter der Request
weitergeleitet werden soll und deswegen sagt der, nö, gibt es nicht. Und warum weiß er
das nicht? Naja, ich hab ihm gesagt, es kommen Requests mit Host ping.progas.xyz und 10.61.35.197.113
ist halt nun mal nicht ping.progas.xyz, deswegen kann das Ganze nicht funktionieren. So, deswegen
machen wir das Ganze nochmal down und jetzt richten wir, nee, am Port erkennt das nicht,
weil da könnte ich ja nur eine Sache betreiben. So und jetzt richten wir mal unsere Domains
ein bei Digital Ocean und wir müssen da gar nicht sonderlich viel machen, wir müssen nur
noch mal die IP-Adresse kopieren von meinen, wobei ich hab sie doch hier irgendwo gehabt.
Da. Wir gehen jetzt nochmal zu Digital Ocean rüber, äh, Moment, falsch, wir gehen nochmal
zu Digital Ocean rüber, zu DNS und wir sehen, es ist noch nichts eingerichtet für progas.xyz.
Wir machen es uns jetzt total einfach, wir machen einen Wildcard-Eintrag, also wir sagen
Add Record, Wildcard und alles geht auf diese IP. Safe. Ähm, das bedeutet, jegliche Subdomain
progas.xyz wird jetzt immer auf diese IP aufgelöst. Wir können mal gucken, ob das funktioniert,
also gucken wir erstmal dick an. Dick funktioniert nicht, weil wir haben ja die Domain selbst
nicht eingetragen, nur die Subdomains. Sagen wir zum Beispiel mal test.progas.xyz und siehe
da die IP von meinem Server. Ähm, ping.xyz, die IP von meinem Server. Äh, keine Ahnung,
QtChat, die IP von meinem Server. Also im Prinzip scheißegal, was ich eintrage, die IP von
meinem Server. Das heißt, das ist alles an DNS-Config, was wir tatsächlich machen müssen.
Mehr müssen wir an DNS-Config nicht machen. Wir brauchen einen Wildcard-Eintrag, der auf
meinen Server zeigt. So, und wenn ich jetzt Docker Compose abmache, so, und jetzt auf
ping.progas.xyz gehe, dann werdet ihr sehen, funktioniert. Wenn ihr es ausprobieren wollt,
könnt ihr machen. Ihr könnt bei euch im Browser eingeben ping.progas.xyz und ihr kriegt eine
Antwort. So, und was jetzt passiert ist, ähm, übrigens mein Domain-Registrar kann ich eigentlich
wobei, ich lass mal lieber auf, vielleicht brauchen wir das alles noch. Und was jetzt
passiert ist folgendes, euer Server, äh, nicht euer Server, euer Desktop, Rechner, Browser,
was auch immer, macht einen Name-Lookup, Zertifikate kommt gleich, Zertifikate kommt gleich, IP-Leak,
schau wieder, aje, was hier laufend liegt, äh. Der macht einen DNS-Lookup für ping,
also eure Kiste macht einen DNS-Lookup für ping.progas.xyz und bekommt dafür die IP
von meinem Ubuntu-Server. Dort ist Port 80 offen, Port 80 ist der normale HTTP-Port und
das Ding landet auf dem Reverse-Proxy. Allerdings sieht der, ähm, der HTTP-Request ja folgendermaßen
aus, host ping.progas.xyz. Also wir reden hier jetzt nicht von dem Domain-Name, sondern
wir reden von dem Host-Namen, von dem Virtual-Host-Namen oder wie auch immer, von dem Host-Namen, der
im HTTP-Request drinnen steht. Das hat nichts mehr mit DNS in dem Sinn direkt zu tun. Das
steht Plain Text, also das ist das, was die Anfrage in jeder Browser geschickt hat an
den Server im Endeffekt. Wer es mir nicht glaubt, übrigens, wir können das auch von
Hand machen, äh, wir können mal ganz low-level sagen, telnet auf ping.progas.xyz, Port 80,
also low-level als telnet geht's ja nicht, get HTTP-Version 1.1, host ping.progas.xyz
und wir kriegen die gleiche Antwort. Und damit ihr auch seht, dass das funktioniert, dass
das mit dem DNS-Namen nichts zu tun hat, ich kann auch einfach mal die IP-Adresse einfügen,
mich da drauf connecten und ich sag jetzt wieder das Gleiche, wir wollen HTTP-Request
machen und wir wollen das für diesen Host machen und ihr seht da, bam, funktioniert.
Also hat nichts mit dem DNS-Namen direkt zu tun. So, und wer jetzt big brain genug ist,
wird feststellen, ok, wenn wir gar keine DNS-Namen für alle unsere Services registrieren müssen,
sondern einfach mit einem Wildcard-DNS auskommen, dann ist die einzige Stelle, wo wir DNS-Namen
oder Service-Namen definieren müssen, eigentlich hier in unserer Infrastructure-Config und
das ist natürlich richtig geil, weil unser Ziel ist ja, dass unser komplettes Environment,
was wir aufbauen wollen, alles in dieser Config-Datei drin steht, dass ich einfach mit Docker Compose
hoch und runter fahren kann, egal auf welchem Server ich bin.
Mat 9908, naja, das kann ich dir jetzt so nicht so einfach erklären. DNS auf Cloudflare
hab ich ja vor einer Stunde umgestellt oder so. So. Und dementsprechend muss ich auch
keine DNS-Config machen, wenn ich einen zweiten Who-Am-I-Container haben will. Guck mal, wenn
ich einen zweiten Who-Am-I-Container haben will, den nennen wir einfach mal Who-Am-I-2,
und der ist jetzt verfügbar unter dem Namen, keine Ahnung, pong.progressxyz. Übrigens
eine Sache darf ich nicht vergessen, das ist in der Traffic-Config ein bisschen eklig,
das muss dann hier auch drinne stehen. So. Und ich brauche keine DNS-Config oder irgendwas,
ich fahr das Ganze jetzt hoch. Ich hab einen Loadbalancer davor, zwei Who-Am-I-Container,
ich bin auf ping.progress, guckt, funktioniert immer noch, und ich bin auf pong.progress,
funktioniert auch. So, wir haben nichts am DNS angepasst, und wir können alle möglichen
Subdomains von progress.xyz verwenden. Kannst du auch mehrere Container dynamisch erstellen?
Nee. Dafür ist es auch nicht gedacht. Da musst du Richtung Container-Orchestrierung gucken,
Richtung, was weiß ich, Kubernetes, Swarm und sonst was. Das ist eher die kleinere Variante,
die sich aber auch für daheim eignet. Sebaro, das ist ein komplett anderes Szenario mit
Cloudflare-Denos-Schutz, weil dort ist der Endpunkt bei Cloudflare, und es geht durch
Cloudflare durch und dann zu dir. Das ist ein komplett anderes Szenario. Da kann ich
jetzt so auch nichts zu sagen. Aktuell, das Einzige, was wir von Cloudflare verwenden,
ist den DNS. Also es geht kein Traffic durch Cloudflare durch. Und das ist natürlich schon
mal echt cool. Also sprich, ich kann hier beliebig viele Dienste anlegen im Hintergrund,
und es funktioniert einfach. Und da sieht man es auch, wie einfach das ist. Wie ich
im Vorfeld gesagt habe, ich muss an meiner Loadbalancer-Konflikt nichts ändern, sondern
ich kann hier einfach neue Dienste, ich kann in der Nextcloud hinzufügen. Container Nextcloud,
ändert die Domain, und das Ding ist verfügbar. Ich kann in den Git-Server hinzufügen, ändert
die Domain, Docker Compose ab, noch Git-Server zusätzlich verfügbar. Also relativ easy,
ohne dass ich am Loadbalancer was ändern muss. Mit welchen Befehlen siehst du deine öffentliche
IP in der Konsole? IP-Ed? Also der Server steht öffentlich im Internet. Ja. Der Server steht
öffentlich im Internet, der ist bei DigitalOcean, der ist nicht bei mir lokal. Sonst könntet
ihr ja auch gar nicht drauf zugreifen. So, das ist der erste Schritt, und ich glaube,
jetzt hat man auch ganz gut verstanden, was das hier eigentlich macht. Sprich, man hat
einen Einstiegspunkt, und der balancet, oder eigentlich proxy, aber ich sag mal lieber
balancet, auf die unterschiedlichen Services dahinter. So, das ist der erste Schritt dazu,
man sieht, das funktioniert auch relativ gut. Mal einen Daumen. Man sieht, das funktioniert
auch relativ gut. Und ihr habt es im Browser ausprobiert, tut. Ach, by the way. Ach ja,
mit IP geht das auch. Jaja, mit IP geht das auch. Also du kannst auch hier eine IP reinschreiben,
allerdings, wie sieht das aus, wenn man es lokal machen will? Ganz genauso, es ist kein
Unterschied. Was du machen würdest, wenn du es lokal verwenden willst, hast du zwei Varianten.
Entweder, du trägst hier eine lokale IP ein, also ein Public DNS kann auch lokale IPs
auflösen, warum nicht. Du trägst hier eine IP ein. Oder, was noch viel besser ist, du
skippst diesen ganzen Cloudflare, sonst war es Geschiss, und biegst das einfach lokal
ein. Du machst einfach einen statischen Eintrag auf deinem Router für die Domain, auf eine
interne IP. Eine gültige Domain brauchst du für Zertifikate trotzdem. Extreme Nerd
fragt, geht das auch mit verschiedenen Hosts? Geht das auch mit z.B. Hans.de und Franz.de
auf einem Server? Das ist dem vollkommen egal, für welche Domain. Du kannst den ersten Container
bereitstellen für Hans.de und den anderen für Franz.de, das ist kein Problem, das kannst
du machen. Du kannst sogar den einen Container bereitstellen für Franz.de und den anderen
für Hans.com. Die einzige Sache, die gewährleistet sein muss, ist, dass der DNS Lookup auf deinem
Server rauskommt. Also sprich, wenn du es irgendwie hinbekommst, dass Hans.com auflöst
zu der IP von deinem Server und dass Franz.de auflöst zu der IP von deinem Server, also
quasi wenn du Besitzer dieser Domain bist und das machen kannst, dann funktioniert das
dann überhaupt kein Problem. Dafür ist es ja unter anderem da, um genau sowas zu machen.
Wir wollen ja gleich noch Zertifikate machen und das wird ein bisschen komplizierter jetzt
noch in der Config. So, das ist so die Basics, die man mal machen muss. Also die Basic Config,
sprich, jetzt fahre ich das Ding hoch. Wir können jetzt noch mal richtig Big Brain sein,
wir sagen jetzt noch Git Init, wir machen hier noch ein Git Repo drinnen. Git Status, Git
Add, alle Files und sagen Git Commit, keine Ahnung, Initial Commit. Ja, ich heiße jetzt
Max at QChat, perfekt. Ah ne, darf ich nicht committen, ok, dann heiße ich jetzt so, Your
Name und Example, perfekt. Können wir, wir machen sogar noch ein Git Repo dann, das schlägt
das DevOps Herz höher. So, gut, das war die Basic Config. Also man habt jetzt gesehen,
das Balancen klappt ziemlich gut, ein Einstiegspunkt und mehrere Services dahinter. Wir können
unterschiedlichste Hausnamen verwenden, wie wir lustig sind, hans.de, franz.de, ping,
pong, progas.xyz, solange wir die Domain haben. Ja, solange wir Einfluss darauf haben,
auf was die Domain auflöst. By the way, ihr könnt auch google.de nehmen und die daheim
bei euch im DNS umbiegen. Also wenn ihr schon immer mal google.de besitzen wolltet, könnt
ihr das machen. Ihr müsst bloß sicherstellen, dass euer lokaler DNS google.de mit eurer
internen IP auflöst. Da könnt ihr aber halt google.de nicht mehr auflösen, das ist
jetzt auch nicht so wirklich sinnvoll, aber es würde funktionieren. Machst du das nur
zum Spaß gerade oder willst du darauf auch einen nützlichen Dienst drauf laufen lassen
am Ende des Tages? Ich hab das bei mir daheim schon laufen. Hostdatei editieren kannst du
auch machen, allerdings, Hostdatei editieren auf dem Server bringt nichts, du musst Hostdatei
auf dem Client editieren, weil der Client Browser das richtig auflösen muss. Was übrigens
nicht geht, mit Zertifikaten. Google.de, na das funktioniert nicht. Also google.de müsst
ihr dann HTTP Plain Text machen. Ihr könnt auch DuckDNS verwenden, ihr könnt euch eine
eigene Domain machen lokal, aber spätestens wenn ihr Zertifikate, und das ist das nächste
was wir jetzt machen, spätestens wenn ihr gültige Zertifikate haben wollt, ich starte
das Ding gerade mal nochmal, dann braucht ihr eine Domain die euch gehört. Sei es über
einen dünnen DNS, DuckDNS, sonst was, oder eben euch für 9 Dollar im Monat eine Domain
kaufen. Achso, Ping gibt es ja noch. So, weil ihr seht, wenn ich jetzt auf ping progress
7x9ZG und dann auf HTTPS, werdet ihr feststellen, OMG, der Hacker-Man ist am Start. Das Zertifikat
ist nicht gültig. Naja, weil es kein Zertifikat ist von irgendeiner Zertifizierungsstelle.
Bam. Erstmal die Sonnenbrille aufsetzen Leute. Also man sieht, der hat ein Self-Signed SSL
abgeneriert, aber ich kann jetzt ja auch schon sagen, Accept Risk and Continue, dann findet
er es natürlich jetzt erstmal nicht, weil ich Entry Point, weil ich hier gesagt habe,
Entry Point ist Web und nicht Web Secure, aber man sieht prinzipiell schon, dass er
auf den Traffic draufkommt. So, wollen wir aber nicht, wir wollen ja ein richtig echtes
gültiges Zertifikat haben. So, und das ist jetzt der nächste Schritt, was wir machen.
Damit wir ein gültiges Zertifikat bekommen können, gibt es eine kostenlose Variante,
die auch sehr verbreitet ist, das nennt sich Let's Encrypt. Let's Encrypt ist eine CA,
also eine Zertifizierungsstelle eines, was heißt CA nochmal genau, Certificate Authority
glaube ich, also quasi eine vertrauenswürdige Stelle, die überprüft, ob ihr auch vertrauenswürdig
seid und dann euch ein Zertifikat gibt, dass ihr ihr seid. Das ist übrigens alles, was
ein Zertifikat sagt, das sollten wir an der Stelle vielleicht auch nochmal erklären.
Nur, weil eine Seite ein gültiges Zertifikat hat, heißt es noch lange nicht, dass es auch
wirklich die Seite ist, auf die ihr wollt. Zum Beispiel, wenn ihr auf die Seite geht,
minebank.de und die hat ein gültiges SSL-Zertifikat und das ist auch wirklich eure Bank. So,
dann ist alles gut. Geht ihr auf die Seite minenbank.de, ihr habt euch verschrieben und
die hat auch ein gültiges Zertifikat, das geht, dann seid ihr aber auf der falschen
Seite. Also sprich ein Zertifikat bedeutet nicht, dass es irgendwie die richtige Seite
ist, sondern ein Zertifikat heißt nichts anderes, dass die Domain legit, also nee,
nicht legit, dass das, was hier oben in der Adresszeile steht, auch wirklich das ist,
wo ihr drauf seid. Und wenn ihr euch verschrieben habt und das Zertifikat für die verschriebene
Domain ausgestellt ist, ist das trotzdem ein gültiges SSL-Zertifikat. Matt, das stimmt
nicht. Es wird so verkauft, ja, also sprich, wenn sie auf der richtigen Bankseite sind,
das erkennt man am grünen Symbol, das stimmt nicht. Also als Beispiel, wenn ich jetzt hier
sagen würde, meinebank.de, ich geh da jetzt nicht drauf, ich weiß nicht, wo ich da rauskomme,
das wäre die richtige Seite und ich hab mich jetzt verschrieben, die hier, so, minebank.de,
es können beide Seiten komplett legit gültige SSL-Zertifikate haben, also auch von Browser
akzeptierte SSL-Zertifikate und das eine ist eine Fake-Seite und das andere ist eine echte
Seite, das ist kein Problem, das geht, weil das Zertifikat weist ja nur aus, dass der
Name übereinstimmt, dass ihr derjenige seid, dem die Domain gehört und dass der Domain-Name
und das Zertifikat übereinstimmt. Hat das Zertifikat dann überhaupt was mit der SSL-Verschlüsselung
zu tun? Ja. Hat's. Das für Verschlüsselung und das weist euch quasi als Besitzer oder
als rechtmäßiger Besitzer der Domain aus und dass ihr auf der richtigen Domain seid,
die ihr eingegeben habt. Was anderes sagt das nicht, wenn es ein gültiges Zertifikat
ist, es kann genauso gut eine Scammer-Seite sein. So, das muss man jetzt an der Stelle
noch mal sagen. Also, Let's Say Grypt ist eine Zertifizierungsstelle, bei der man sich
kostenlos SSL-Zertifikate ausstellen kann und die mittlerweile auch in jedem Browser
trusted sind. Also, das funktioniert folgendermaßen, wenn ihr ein Zertifikat bekommt, dann steht
in dem Zertifikat drin, welche Zertifizierungsstelle euch das gegeben hat. Und euer Zertifikat
funktioniert nur, wenn der Browser der Zertifizierungsstelle vertraut. Und um's noch krasser zu sagen,
die Zertifizierungsstelle, die die Zertifizierungsstelle zertifiziert hat, der muss auch vertraut werden
und der, der da raufkommt auch. Chain of Trust nennt sich das Ganze da. Also sprich,
das ist eine ganz lange Kette, wer wem vertraut. Das wurde in der Vergangenheit auch schon
ab und zu mal gebated, so Komodo haben sie ihren Root-Key geklaut damals. So, und Let's
Encrypt ist eine Zertifizierungsstelle, die es kostenlos erlaubt, SSL-Zertifikate auszustellen
und denen jeder größere Browser traut. Das heißt, das Zertifikat, das SSL-Zertifikat
von Let's Encrypt ist exakt genauso gut, wie ein Zertifikat von Komodo oder was VeriSign
oder was es da nicht nur alles gibt. Was ist, wenn der Browser einfach nur der Root-CA vertraut,
sind dann alle Subdomain auch trusted? Nö, es sind die Sachen trusted, für die das Zertifikat
ausgestellt ist. Wenn das Zertifikat für ein Domain ausgestellt ist, dann ist nur die
Zertifikat trusted und wenn es mit Wildcard ist, dann sind auch Subdomains trusted. Raum
drauf an, für was das Zertifikat ausgestellt ist. Boah, PC lustig, ich weiß nicht, wie
die das genau intern handeln. So, und deswegen, wir wollen das Ganze, was wir jetzt aufgebaut
haben, auch noch mit Zertifikaten versorgen. Weil wir wollen hier den, den da, wir wollen
den gültigen, das grüne Häkchen wollen wir haben. Und das grüne Häkchen ist nicht einfach
nur das, damit man sich gut fühlt. Auch nicht nur im internen Netz, es gibt Services, die
setzen zwingend SSL voraus. Zum Beispiel WebRTC Verbindungen im Browser sind mittlerweile
nur über SSL möglich. Das ist quasi Latency, eine Video-Audio-Streaming-Geschichte mit niedriger,
mit niedriger Verzögerung. Und auch PWAs und Apps, die man zum Homescreen auf Smartphones
hinzufügt, brauchen zwingend SSL. Also sprich, wenn ihr intern was betreibt, zum Beispiel
eine Nextcloud, ein Home Assistant oder sonst was und ihr möchtet den Home Assistant bei
euch auf den Startbildschirm vom Smartphone hinzufügen oder ihr wolltet, ihr wollt Nextcloud
Videokonferenz machen, irgendwas. Ja, also es gibt noch jede Menge andere Sachen, was
nur über SSL geht, dann braucht ihr auch intern ein gültiges SSL-Zertifikat. Wie ihr das
gültig macht, ist erstmal dahingestellt, ihr könnt es auch irgendwie importieren, aber
die einfachste Sache, die es gibt, ist tatsächlich sich ein Domain besorgen und mit Let's Encrypt
sich ein Zertifikat ausstellen. Und wie einfach das ist, zeige ich euch jetzt. Also hier mit
der Config ist es ein bisschen komplizierter, weil wir es halt auch erweiterbar machen,
an sich ein Zertifikat auszustellen für Let's Encrypt mit CertBot oder anderen Skripten
ist wirklich eine Sache von einem Befehl, es ist total einfach. So, wir konfigurieren
das Ganze jetzt mal hier. Es gibt zwei Hauptvarianten, wie man sich von Let's Encrypt Zertifikate
ausstellen kann. Und das sind die HTTP-Challenge und die DNS-Challenge. Challenge ist in dem
Fall quasi die Aufgabe, die man überwinden muss, damit man ein Zertifikat bekommt. Also
sprich, es gibt einmal ein Authentifizierungsverfahren über HTTP und einmal ein Authentifizierungsverfahren
über DNS. Ich mache mal kurz hier den Darkreader aus. Ich weiß, es blendet ein bisschen, aber
ich finde, so das kann man besser erkennen. Das sind so die zwei Hauptverfahren. Es gibt
noch andere Zeug, aber das verwendet eigentlich kaum einer. So, der Unterschied ist folgendes,
ich erkläre euch mal, wie das funktioniert. Das ist eigentlich ziemlich big brain. Damit
euch Let's Encrypt ein SSL-Zertifikat ausstellen kann, müsst ihr ja irgendwie beweisen, dass
euch die Domain gehört. Also Leute, soll ich wieder Darkseam machen? Ist mir wurscht.
Ich bin da schmerzfrei. Also irgendwie müsst ihr ja beweisen, dass ihr der rechtmäßige
Besitzer der Domain seid. So, und da gibt es bei Let's Encrypt zwei Varianten, wie man
das machen kann. Einmal HTTP-Challenge und einmal DNS-Challenge. HTTP-Challenge ist
die einfachere von beiden. Die funktioniert folgendermaßen. Auf eurem Server, zum Beispiel
auf dem hier, startet ihr einen Web-Server und hinterlegt dort eine Datei. Ne, stimmt
gar nicht. Stimmt gar nicht, was ich erzähle. Muss ich ehrlich sagen, ich habe sehr selten
eine HTTP-Challenge gemacht. Da wird das abgeloadet, oder? Oder muss man da was? Ehrlich gesagt
weiß ich gar nicht so genau, wie es ist. Ah, hier. Genau, also folgendermaßen. Ihr installiert
einen Web-Server auf eurer Linux-Kiste und stellt sicher, dass, ich habe wieder eingefallen,
wie es funktioniert, und stellt sicher, dass die Domain, für die ihr das Zertifikat ausgestellt
haben möchtet, auf diesen Server zeigt. Dann führt ihr ein Programm aus auf diesem Server,
das sich zu Let's Encrypt verbindet und sagt, bitte stellen wir mal ein Zertifikat aus für
diese Domain. Das Programm hinterlegt dann eine Datei mit einem Passwort auf dem Web-Server,
mal ganz billig gesagt, ab. Also sprich, es wird eine Datei mit einem geheimen Token auf
eurem Web-Server abgelegt. Let's Encrypt guckt nach, stimmt dieses Token überein mit dem
Token, was ich erwarte, und wenn ja, bedeutet das, euch gehört die Domain. Weil euch muss
die Domain gehören, denn Let's Encrypt nimmt die offizielle DNS-Auflösung und den Server,
den sie damit aufgelöst haben, stellt quasi das gleiche Token zur Verfügung auf seinem
Web-Server, wie Let's Encrypt erwartet. Das heißt im Endeffekt nichts anderes, wie ihr
müsst das da hingelegt haben, ein anderer kann das da nicht hingelegt haben, weil ein
anderer errät kein 128-stelliges Random-Token. Das heißt, wenn Let's Encrypt das auf diesem
Web-Server findet, dann weiß er, ok, du bist der rechtmäßige Besitzer dieser Domain, dieses
Servers, und du bekommst ein Zertifikat. So, das ist die eine Variante, wie es funktioniert.
Das ist ein bisschen doof intern zu verwenden, denn was man dazu braucht, ist einen Web-Server,
der öffentlich erreichbar ist von Let's Encrypt. Und ja, mein Server ist öffentlich erreichbar
von Let's Encrypt, aber euer Server, euer Raspberry Pi, den ihr daheim stehen habt,
der nicht. Und ich mach das hier auch stellvertretend für Leute, die das ganze daheim verwenden
wollen. Dass wir das public machen, ist eigentlich bloß ein kleiner Gag da dran. Wir müssen das
also anders machen. Sprich, die HTTP-Challenge funktioniert nicht, wenn der Server bei euch
intern steht. Ist ja klar, ihr könnt zwar einen DNS-Wildcard einfügen. Also mal angenommen,
ihr fügt einen DNS-Server von eurem Anbieter, fügt ihr einen Wildcard, Sternchenpunkt,
meineDomain.com auf eine interne IP von euch. Dann macht Let's Encrypt eine Namensauflösung
auf eine interne IP und die kommt natürlich nie an bei euch. Wie soll Let's Encrypt von
sich auf eine interne IP bei euch zugreifen können? Funktioniert nicht. Man kann das
natürlich machen, indem man Ports weiterleitet und sonstige Geschichten macht. Machbar ist
das alles, aber es ist ziemlich kompliziert. Und dementsprechend nimmt man einfach was
anderes, nämlich man nimmt die DNS-Challenge. Die DNS-Challenge finde ich auch in allen
anderen Belangen viel einfacher. Die DNS-Challenge, also sprich, über DNS sein Zertifikat auszustellen,
funktioniert, äh, jung, Snorlax, ja so ähnlich, so ähnlich. Die DNS-Challenge funktioniert
ähnlich zu dem, wie ich erklärt habe, nur, dass man keinen Web-Server verwendet, um das
geheime Talken Let's Encrypt zugänglich zu machen, sondern einen TXT-Record vom DNS.
Also sprich, man geht wieder zu Let's Encrypt hin und sagt, Let's Encrypt, stell mir bitte
den Zertifikat aus für ping.proggers.xyz. Dann sagt Let's Encrypt, alles klar, mach
ich, beweis mir mal, dass du der Eigentümer der Domain bist, indem du in deinem DNS,
auf dem ja nur der Domain-Eigentümer Zugriff hat, äh, folgendes langes Random-Passwort
hinterlegst. Dann gehst du auf deinen DNS, machst einen TXT-Record mit dem super langen,
geheimen Passwort, was dir Let's Encrypt mitgeteilt hat, dann macht Let's Encrypt ein DNS-Lookup,
TXT-Record auf deine Domain und sieht, aha, da ist ja das lange, geheime Passwort-Talken
hinterlegt, dann muss das ja wohl der rechtmäßige Eigentüm dieser Domain sein und du bekommst
dein, ähm, Zertifikat. So, im Prinzip sind die beiden Challenges relativ ähnlich, das
einmal funktioniert der Talkenaustausch über den Webserver, einmal funktioniert der Talkenaustausch
über DNS. So, und das verwenden wir, weil das könnt ihr intern verwenden und das können
wir auch auf unserem Server hier verwenden. Also wir verwenden DNS-Challenge und das ist
auch der Grund, warum wir Cloudflare verwenden. Das ist der Grund, warum wir Cloudflare verwenden.
Und man kann damit Wildcard-Zertifikate benommen, das kommt ja auch noch dabei. Das ist der
Grund, warum wir Cloudflare verwenden, weil wir können in Cloudflare über die API DNS-Einträge
anlegen und wir brauchen ja einen TXT-Record, der uns als Eigentümer der Domain ausweist
und wir können über Cloudflare einen API-Talken generieren, worüber wir DNS-Einträge TXT-Records
anlegen können und Traffic, also sprich das Ding, was wir hier als Load Balancer Reverse
Proxy verwenden, der unterstützt Cloudflare schon eingebaut. Das heißt, wir müssen eigentlich
nix anderes machen, wie dort in Traffic unser Token zu hinterlegen für Cloudflare und das
komplette Handling, die komplette DNS-Challenge und die ganze Magic im Hintergrund macht Traffic
für uns. Das einzige, was wir machen, müssen wir erstens hier unser DNS-API-Talken hinterlegen
und sagen, auf welcher Domain der Server verfügbar sein soll. Fertig. Ach ja, und wir müssen
die Domain besitzen, sonst funktioniert es natürlich nicht. So, das heißt, deswegen
machen wir unseren DNS mit Cloudflare und damit das funktioniert, müssen wir uns erst
mal einen API-Talken generieren lassen. Also, gehen wir mal auf, keine Ahnung, ich glaube
im Profile ist das irgendwo, genau, API-Talkens und da muss man jetzt ein bisschen aufpassen.
Ich zeige euch jetzt auch mal einen kleinen Trick, oder was heißt ein kleinen Trick, was
wichtig ist, worauf man achten muss, wenn man sowas macht, vor allem wenn man sowas im Stream
macht, worauf man achten sollte. Also, wir gehen jetzt erst mal auf Create-Talken und
jetzt kann man auswählen, was möchte man mit, ich leake das API-Talken jetzt, aber
ich beschränke das auf die IP von meinem Server. So, E-Mail ist auch nicht leaked,
das ist meine offizielle Business-E-Mail, die ist eh öffentlich zugänglich auf YouTube
und Twitch. So, also Edit DNS-Zones möchte ich den API-Talken für anlegen. Achja, irgendjemand
hat gefragt, ob Cloudflare auch SSL kann, das ist was anderes. Cloudflare SSL ist dafür
da, dass du deinen Traffic durch Cloudflare durchtunnelst, also quasi Cloudflare macht
für dich DNS und leitet das dann quasi auf deinen Server weiter, das heißt dein Traffic
geht durch Cloudflare durch. Was wir hier aktuell machen ist, wir verwenden nur den DNS von Cloudflare
und der Traffic geht nicht durch Cloudflare. So, also was wir machen wollen ist, wir möchten
einen API-Zugang für Cloudflare anlegen, nämlich wir wollen DNS-Zonen editieren dürfen, editieren,
Resources für Procast XYZ und jetzt sagen wir IP-Attress-Filtering. So, was ihr jetzt
hier machen würdet, normalerweise ist, die IP eintragen, eure Public-IP, mit der ihr
von daheim zugreift oder aber es einfach leer lassen, weil ihr ja euren API-Key nicht öffentlich
in einem Livestream liegt, so wie ich das jetzt gleich machen werde. Deswegen werde
ich das beschränken und zwar, der Server, der das hier macht, ist ja meine Linux-Kiste.
So, und das heißt, ich sage Cloudflare, okay, der Request, der muss von dieser IP kommen,
also sprich, wenn der Request nicht von dieser IP kommt, macht nichts. Und das muss ich machen,
weil ich sonst garantiert ganz viele lustige Leute im Chat habe, die Cloudflare zusperren
mit meinem API-Talk. Deswegen sage ich, okay, IP-Attress-Filtering ist in, hat drin und
so gut ist. Das heißt, ich kann es nur von meinem Server aus machen. Continue to Summary,
Create Token, jetzt kommt der Big Leak, so und ich zeige euch jetzt mal, dass das nicht
funktioniert. Ich führe es von meinem Server aus. This API-Token is valid and active. Ich
führe es von meiner lokalen Kiste aus. Okay. Na gut, dann delete ich halt das API-Token
wieder. Warum geht denn das nicht? Das muss doch funktionieren. Hä? Okay, nochmal, Create
Token, Edit DNS Zone. Gucken, ob irgendwelche lustigen Leute schon was angelegt haben. Nein,
nicht, so schnell war keiner. Ja, keine Ahnung, warum das funktioniert. Normalerweise, ich
würde jetzt eigentlich von ausgehen, dass er sowas sagt wie Exist Denied oder sowas,
aber... Ne, den manuellen DNS-Challenge mache ich nicht, das ist ja... Okay, machen wir
das Ganze nochmal. Create, Edit DNS Zones. Wir machen mal nur Read, wir machen mal nur
Read, dann kann man nämlich testen, ob es funktioniert, ohne dass wir was kaputt machen
können. Zones include specific zone progress, IP-Address-Filtering is in. So, das ist doch
meine IP hier, wird jetzt total hängen geblieben. Das ist auch die, auf die ich SSH gemacht habe
vorhin, ja. Keine Ahnung, is in. By default, the stone will apply to our IP-Address. Okay,
select IP-Addresses or range of IP-Addresses. Muss ich da vielleicht noch angeben? Slash
32 oder so? Ne, macht er ja automatisch, ist er schlau genug für. Okay, warum auch immer.
Create Token, ja, leak, IP-Talks. Okay, kann mir irgendjemand erklären, warum das funktioniert?
Okay, keine Ahnung. Also, das hier ist vom Server ausgeführt und das hier ist von mir
ausgeführt. Das sollte eigentlich nicht funktionieren, würde ich sagen. Also, ich hätte jetzt gesagt,
da sollte so was drinstehen wie Exist Denied, ja. Funktioniert es bei euch auch, wahrscheinlich,
ja. Ich mein, ihr könnt eh nur lesen, insofern kann da nichts passieren, aber. Select. Is
not in. Plötzlich. Is not in. Der Token. Gucken. Okay. Okay. Okay. Okay. Okay. Okay. Okay.
Nö, es juckt den auch nicht. Hä? Hm, sehr merkwürdig. Das ist doch die richtige IP,
oder? Ja. Ist in? Weiß ich auch nicht.
Okay, ich hab ehrlich gesagt keinen Schimmer, woran das liegt, dass das jetzt so, so merkwürdig
ist. Okay. Vielleicht brauchst du ein paar Minuten, bis die Regel setzt. Nee, das wäre
ganz schön fail. Ich mein, was anderes kann ich doch hier nicht machen. Okay, wie lese
ich denn über die AP? Cloud, Flare, Read, Read, DNS, AP. Guck mal, probieren wir mal
aus. Cloud, Flare, AP. Wie lese ich denn hier ab, was? What? DNS. DNS Records. List DNS
Records. Was ist denn das Sound Identifier? Wow, wow. Das da, das da muss ich mal, ne?
Also das da, das da. Probieren wir das mal aus. Okay. Moment, E-Mail will ich nicht.
Ich will nicht E-Mail, sondern ich will dieses komische Toppen. Authentification Error, ja,
ähm, Fallzone. Alle, alle DNS Records. Und jetzt brauch ich noch meine Zone ID, was ist
meine Zone ID? Moment, was ist meine Zone ID? Wo sieht man
das? Zone ID. Authentification Error. Ah, okay, okay, also das ist mal echt fail. Das
ist mal echt fail. Also, okay, das funktioniert nicht. Das funktioniert so wie gedacht. Allerdings
ist es fail, dass die, dass die Tests, dass der Test nicht richtig als Fehler geht, ne?
Also sprich, man kann das nur von dem Server ändern, aber man kann abfragen, ob das AP-Tücken,
ähm, ja. Okay. Ja, was auch immer. Also es funktioniert alles. Gut, dann können wir
das Toppen jetzt ja ändern. Bug Bounty plus 500 Prozent. Wahrscheinlich ist das sogar Absicht.
Okay, AP-Talkens. AP-Talkens, Edit. So, jetzt sagen wir Edit, DNS-Zone. Gut, nämlich wenn
ich jetzt hier abfrage, dann geht's. Und wenn ich hier abfrage, geht's nicht. Ja, Authentification
Error. Und da ist exakt genau der gleiche Shit, der, also sprich, der, der hier geht,
der geht bei mir lokal nicht. Alles klar, alles gut, funktioniert. Cloudflare ist nur
merkwürdig. Also, jetzt können wir mit der eigentlichen Sache weitermachen, die wir eigentlich
da machen wollen. Also, wir haben jetzt dafür gesorgt, dass wir einen AP-Zugang haben zu
Cloudflare, dass wir DNS-Challenges, dass wir die, dass wir TXT-Records anpassen können
für die DNS-Challenge von NetEncrypt. Allerdings, wie ich gesagt habe, wir wollen das ja nicht
selbst machen von Hand, sondern wir möchten, dass Traffic das Ganze für uns macht. So,
und was wir jetzt mal machen werden, ist, dass unser Ping-Service ein gültiges SSL-Zertifikat
abbekommt. So, was man da für machen muss, ist Folgendes. Das ist jetzt, da sieht das
ein bisschen kompliziert aus, deswegen muss ich auch, muss ich auch gerade mal kurz abgucken.
Ups, so, muss ich abgucken, weil das kriege ich auch aus dem Kopf, aus dem Kopf nicht
zusammen. Also, muss ich mir jetzt zusätzlich sagen, ok, ich möchte, Traffic, ich möchte,
dass du für mich Let's Encrypt-Zertifikate abrufst. So, da muss man zuerst einmal das
hier einfügen. Ich copy paste mir das, da kriegst du es durch, wenn du das jetzt von
Hand schreiben musst. Das da, man muss nämlich sagen, ok, Zertifikat Resolvers DNS-Challenge,
das ist das Let's Encrypt-Protokoll und ich will DNS-Challenge machen. Also, DNS-Challenge
ist quasi der Name, dem ich diesem Zertifikat-Dings da gebe und DNS-Challenge heißt, ich möchte
keine HTTP-Challenge machen, also nicht das hier, sondern ich möchte DNS-Challenge machen.
Also, ich sag Traffic, mach das mal für mich. So, das nächste, was ich brauche ist, von
wo überhaupt? So, das setze ich auf Cloudflare, weil ich verwende ja Cloudflare. So, das nächste,
was ich brauche ist, ich muss ihm sagen, Playlist ist schon wieder vorbei. Nochmal, wir hören
das jetzt, bis wir durch sind. Das nächste, was ich ihm sagen muss, ist, wo er das ganze
speichern soll. Da kommen wir gleich dazu. Er soll das nämlich unter Let's Encrypt hier
in dieser JSON-Datei speichern, denn man muss ja dazu sagen, wenn er die Zertifikate nicht
irgendwo speichern würde, persistent auf dem File-System, jedes Mal, wenn ich docker-compose-stopp
down mache und ab, würde der ja neue Zertifikate ausstellen. Erstens hat man relativ schnell
das Limit erreicht dann, wenn man das mehrfach am Tag macht, was Let's Encrypt einem am Tag
ausstellen lässt. Das zweite ist, es ist ja auch ein bisschen verwirrend für den User,
wenn sich laufend Zertifikate ändern und SSH meckert ja auch. Also, wir müssen ihm sagen,
wo er die Zertifikate speichern soll, dass das Neustart überlebt. So, und das letzte
ist was, das braucht man, man kann es leider nicht ausstellen, normalerweise mach ich's
immer weg, aber bei Traffic kann man es nicht ausstellen. Man muss ihm sagen, welche E-Mail-Adresse
als Ansprechpartner fungiert und da nehmen wir mal die allseits bekannte keqw.progas.xyz.
By the way, Progas hat nicht mal einen MX-Rekord, der kann überhaupt keine E-Mails zustellen,
aber das juckt Let's Encrypt nicht, Hauptsache steht eine E-Mail-Adresse drin. So, das haben
wir und wer jetzt aufgepasst hat, BigBrainTime, der wird festgestellt haben, ok, ich möchte
was speichern, allerdings, ich hab ihm gar nicht gesagt, wo er was speichern soll. Muss
die Chase nicht auch gemounted, was machen wir jetzt? Ich muss ihm ja auch noch sagen,
wo er was speichern soll. So, und dann nehmen wir jetzt mal einen Ordner, keine Ahnung,
ein Verzeichnis oben drüber oder hier home max let'sencrypt, da soll er was drin speichern
und intern im Container ist das Ganze unter slash let'sencrypt verfügbar. Also alles,
was ich im Container, in diesem Traffic-Container unterhalb von let'sencrypt speichere, kommt
auf meinem eigentlichen Host hier im Fallsystem raus. Ich glaube, da lässt das TXT-Challenge
taubend rauf. Bis zum nächsten Mal dann. So, und was jetzt passiert ist, wenn ihr jetzt
DNS-Challenge macht, ein Zertifikat ausstellt, dann ist das dann überlebt das auch Neustarts,
Neustarts, weil das hier auf dem Fallsystem ablegt. Was wir jetzt noch machen sollten
ist mkdir let'sencrypt einen Ordner anlegen, der let'sencrypt heißt, sonst merkt er wahrscheinlich.
Und nun sind wir soweit fertig mit der DNS-Challenge. Jetzt müssen wir ihm natürlich noch sagen,
wie er Zugriff auf Cloudflare überhaupt hat. Und da kommt jetzt unser Token ins Spiel.
Unser Token ist ja das hier, das ist ja unser Token, was hier, by the way, nicht funktioniert,
glücklicherweise. Das ist hier unser Token und das müssen wir dem jetzt irgendwie beibringen,
wie das funktioniert. Und da habe ich mich echt dumm und dusselig gesucht, als ich das
zum ersten Mal versucht habe, in den Traffic Docs zu finden, wie das funktioniert. Ich
zeige euch mal, wo das steht. Das ist total, total versteckt. Das ist Trafficv1. Das ist
total versteckt. DNS-Challenge, Provider, dann sucht man sich hier auf Cloudflare, additional
configurations, additional configurations und dann findet man hier die Variablen, die
man setzen muss, wo man das Token reinpappen kann. Und in dem Fall, was wir suchen, ist
CFDNS API-Token. Das gibt es übrigens erst relativ neu. Früher ging das Ganze nur mit
Vollzugriff auf Cloudflare. Das wäre jetzt hier schlecht zu leaken. Jetzt geht es auch
mit DNS-Token. In den Untiefen der Doku, also das ist wirklich echt big brain versteckt.
So und jetzt sagen wir, okay, damit du die Zertifikate abrufen kannst, verwende folgendes
Token, environment. Also sprich, wir setzen jetzt eine Umgebungsvariable, nämlich die
Umgebungsvariable, ja fast. Wir setzen hier, wir setzen die Umgebungsvariable, fuck, Alter.
So, CFDNS API-Token setzen wir auf unser Cloudflare-Token. So und jetzt kann Traffic für uns diesen
ganzen Geschiss automatisch machen. Also sprich, jetzt kann Traffic, sobald es einen Container
gibt, für eine Domain dorthin gehen zu Let's Encrypt, unser API-Token verwenden, DNS-Challenge
machen, geheimes Token hinterlegen, Zertifikat bekommen, speichern, den Service hier load
balancen mit dem richtigen Zertifikat. Ohne, dass wir jetzt ab jetzt, müssen wir nichts
mehr konfigurieren für weitere Container großartig. Und wir kriegen immer ein neues
Zertifikat für unsere neuen Container gültig direkt von Let's Encrypt. Und das ist natürlich
ziemlich poggers. Wir gucken uns, dass das Ganze noch funktioniert. Einzige Sache, die
wir jetzt noch machen müssen ist, wir müssen dem hier sagen, dass er als Entry Point Web
Secure verwendet. Also Web ist Port 80, Web Secure ist Port 443, haben wir hier oben eingestellt.
Und eine Sache müssen wir noch machen, warum auch immer, verstehe ich nicht, warum man
die machen muss, aber man muss die machen. Man muss dem jeweils in Container noch sagen,
über welchen Weg er das Zertifikat abrufen soll. Also kann ich verstehen, wenn man zum
Beispiel mehrere Domains darüber verwendet, dann muss man ja vielleicht für die eine Domain
diese Authentifizierung nehmen und für die andere Domain diese Authentifizierung nehmen.
Könnte ja sein, deswegen muss man das hier unten angeben, okay, meinetwegen. Kann ich
mitleben? Passt, gut. So, und jetzt gucken wir mal, ob der ganze Kram funktioniert. Jetzt
sagen wir nämlich, okay, Docker Compose. Hallo, Docker, ist alles down, by the way, ja. Jetzt
sagen wir, Docker Compose, fahr mal unsere neue Config hoch. Er startet das, er startet
das. Er sollte jetzt, oh, ich hätte Debug, ich hätte Debug einschalten sollen, weil
jetzt sehen wir nix. Also er sollte jetzt zuletzt Encrypt gehen, ein Zertifikat abrufen,
das Zertifikat speichern und wir sollten ein gültiges Zertifikat bekommen. Probieren
wir mal aus. Ping, also HTTPS, doppelt Punkt doppelt, Ping Progas XYZ und siehe da, ein
gültiges SSL Zertifikat. Ist das nicht nice? Und ich musste nichts machen von Hand. Das
ist echt nice. So, wahrscheinlich, gehe ich mal von aus, ist den meistens nicht klar,
wie viel Arbeit einem das abnimmt. Nur mal so als Beispiel, wir haben es jetzt konfiguriert,
das war jetzt ein relativ großer Aufwand, könnte man sagen, vor allem, wenn man es
noch nicht gemacht hat, aber guckt mal. Mal angenommen, ich möchte jetzt noch ein paar
mehr Who Am I Container haben. Der würde für, also ich mein, ich müsste jetzt den Namen
ändern und die Domain, der würde jetzt für alle Domains neue Zertifikate ausstellen
gültige. Ich mach mal kurz Debug an, dann sieht man nämlich auch, was er macht. Wie
schaltet man Debug ein? Locked Level Debug. Locked Level Debug, alles klar. So, machen
wir mal Who Am I 1, oder hier, 2, 3, 4, 5, da brauchen wir noch unterschiedliche Domains,
das ist Who Am I, keine Ahnung, Ping, ah noch, komm wir sind unkreativ, wir machen Ping 2,
Ping 3, Ping 4, Ping 5. So, und achso, eins nicht vergessen, das wäre sonst zu einfach,
hier muss man den Kram auch eintragen, 2, 3, man macht das ja normalerweise nicht für
den gleichen Container, sondern für unterschiedliche Services, 4, 5. So, und jetzt starte ich den
Kram, erstmal down machen, erstmal down, up, und nun starte der, oh, Moment, irgendwas
verkehrt gemacht, ach Containername hab ich vergessen anzupassen, alter, ich kack noob,
Containername, 3, 4, 5, so down, up. Äh, nee, das ist jetzt, da verwendet er keinen Wildcard
dafür, aber du kannst Wildcards mit DNS Challenge verwenden, wenn du wirklich willst. Es ist
aber besser, du verwendest keinen Wildcard, weil du mit den Raid Limits von Let's Encrypt
so besser hinkommst. Also du kannst auch mit dem Wildcard Zertifikat machen, aber wozu,
das ist viel praktischer, finde ich. So, jetzt starten wir das Ganze mal, und wir sehen jetzt
schon, wir haben eine Config Änderung vorgenommen, der startet für uns, alle Container holt sich
Zertifikate, Announce Zertifikat, ok, was auch immer, guck, er ruft sich Zertifikate
ab, Ping Proggers, Ping 2 Proggers, äh, Zertifikat Request, so, gehen wir mal hier drauf, Ping
Proggers gültiges Zertifikat, Ping 2 Proggers gültiges Zertifikat, Ping 3 Proggers gültiges
Zertifikat, und das ist extrem nice, und nimmt sehr viel, ähm, sehr viel Arbeit ab,
das ist, das ist, ich glaube das könnt ihr euch jetzt vorstellen, das ist wirklich sehr
praktisch, das ist wahrlich exzellent. So, der Beispiel jetzt hier mit den 5 WhoAmI Containern
war natürlich ein bisschen an den Hahn herbeigezogen, das würde man normalerweise nicht machen
mit WhoAmI Containern, sondern man würde verschiedene Services verwenden, ja, also nicht nur WhoAmI
Container, sondern vielleicht noch irgendwie ein, was weiß ich, ein, ne Ahnung, Next Cloud
oder so, oder ein Git, Git Server oder sowas, Speedcast, Speedtest Container, alle möglichen
Sachen, ähm, so, da können wir noch, können wir jetzt beispielsweise noch was anderes
machen, was auch sehr praktisch ist, also wir sehen jetzt das hier, was ich aufgemalt
hab funktioniert, genau so, wunderbar, ähm, hab ich mal ein Bild, also unser Traffic Reverse
Proxy Proxied, wunderbar, hast du wirklich Sternchen in deiner Zone stehen, ja hab ich,
ähm, Proxied wunderbar, macht auch wunderbar Zertifikate für jeden weiteren neuen Backend
Container, den wir hinzufügen, und bei dem wir sagen Traffic Enable True, also wir können
damit auch Container konfigurieren, die rein intern sind und nicht nach außen weiter gereicht
werden, also wenn ich Traffic Enable True weglasse, dann lässt er das ganze bleiben,
so, ähm, so, dann würde ich sagen, dann legen wir jetzt nochmal, ach ja, stimmt, eine
Sache kann ich euch auch noch zeigen, was auch ganz cool ist, ich hab ja gesagt, wenn man
hier Services betreibt, die selbst keine Authentifizierung brauchen, ja, und die selbst keine Authentifizierung
unterstützen, kann man die Authentifizierung hier machen, das ist, das ist sinnvoll, zum
Beispiel, mal angenommen ich sag hier, dieser Who Am I Container, ich möchte nicht, dass,
dass man das hier ohne Passwort aufrufen kann, oh, dann kann ich sagen, ja, Reverse Proxy,
bevor du die Anfragen weiter proxiesst, an den Who Am I Container, dann mach doch mal
nen Basic Aus, mach doch mal ne Passwortabfrage davor, was auch sinnvoll sein kann, das können
wir noch, das können wir noch machen, wenn ihr wollt, ähm, weil das hab ich nämlich
auch in meinem Spickzettel drinne stehen, ähm, da kann man nämlich an der Stelle sagen,
wir möchten jetzt noch mal eine Runde, eine Runde Basic, Basic Aus einrichten, kurz schauen,
wo ich das gemacht hab, genau, Basic Aus, heute definitiv kategoriere lehrreich, ja,
genau, so, Basic Aus machen wir folgendermaßen, äh, ein, ich muss mir das grad mal copy pasten,
Basic Aus, zack, das brauchen wir jetzt noch zusätzlich hier bei, äh, hier, bei, bei
Commands, ne, bei, bei Labels, Labels, komm ich auch noch, so, fügen wir das mal hinzu,
was wir jetzt hier anlegen ist ein, äh, Kombination, Username Max, Passwort 123456, HTTPS redirect,
könnte ich zeigen, ist aber unnütz kompliziert, wir werden, wir werden HTTPS nämlich einfach
ausschalten jetzt, erstmal, HTTPS einfach weg, also das hier ist, ob ihr mir das glaubt
oder nicht, das ist die Kombination, wenn ich, wenn ich, wenn ich es noch richtig aus dem
Kopf hinkriege, Max und Passwort 123456, was man eingeben muss, ähm, kriegt man folgendermaßen
raus, Traffic Basic Aus, wir können es auch mal von Hand machen, Traffic Basic Aus, genau,
so, so generiert man das ganze, man das, wenn man das will, Apache Utils, können wir installieren,
Ups, install, Apache 2 Utils, so, äh, äh, Moment, nicht User, Passwort, Max, Passwort
123456, und übrigens ein Tipp, wenn ihr nicht wollt, dass solche Commandos bei euch unter
History von der Shell stehen, macht einfach ein Leerzeichen davor, und wenn ihr jetzt
in die History guckt, seht ihr, das steht nicht drinnen, also Super, Super Secret, ne,
das ist richtig Big Brain, jetzt muss ich das ganze natürlich noch mal machen, Max,
123456, so, das ist die Kombination, das ist quasi die Username mit Hashwert und Salt und
Gedöns, wie auch immer, vollkommen egal, muss man nicht verstehen, was man wissen muss,
ist, man muss das an der Stelle in die Traffic Conf rein Copy Pasten, da, hier, an der Stelle
muss man das rein Copy Pasten, so, und wenn Wim den Scheiß dann auch noch mal aufhören
würde, eins zurück, wäre auch gut, gar nicht, der Traffic Container hat Zugriff,
Read Only auf Docker, und der guckt nach in der Docker Config, der Traffic Container
hat Zugriff auf Docker, Docker weiß natürlich, welche Labels angelegt sind oder welche Infos
bei einem Container dabei stehen, und der Traffic Container guckt über Docker nach,
was da für Labels dranstehen, so, und jetzt können wir dem Who Am I Container sagen,
danach gucke, muss, wie das funktioniert, und muss über den Spickzettel, genau, und
jetzt können wir dem Who Am I Container sagen, ok, benutze mal als Basic Auth das Passwort
hier, so, und wenn ich jetzt starte, möchte der von mir den Passwort wissen, wenn ich
alles, wohlgemerkt, wenn ich alles richtig gemacht habe, möchte der von mir den Passwort
wissen, ich hoffe, ich habe alles richtig gemacht, Dankeschön für die 3 Cent Sebastian
Zuchtbude, so, Down, Up, Moment, Down, Wim, Scheiß mal auf Debug Output, das muss ich
ja nicht übertreiben, jetzt, ab, was, Auth does not exist, warum nicht, das habe ich falsch
gemacht, ok, ich habe irgendwas verkackt, was habe ich denn verkehrt gemacht, Auth does
not exist, ne, ne, das stimmt, was habe ich denn verkehrt gemacht, der Auth muss in, ah,
stimmt, stimmt, so, ne, stimmt, ja, ok, das würde an der Stelle, aber man kann ihn auch
irgendwie global konfigurieren, so, auf geht's, ok, Ping 3 gibt es nicht mehr, not found,
Ping, ho, Passwort, und das, obwohl der eigentliche Service überhaupt kein Passwort Authentifizierung
kann, Max, 1, 2, 3, 4, 5, 6, und jetzt haben wir wieder Zugriff drauf, also sprich, wir
haben jetzt einen Service, wir haben jetzt unseren Service hier hinten mit Authentifizierung
ausgestattet, der selbst gar keinen hat, was natürlich auch eine praktische Geschichte
ist, also sprich, wir haben jetzt unserem Service hier hinten beigebracht, SSL zu können
und Authentifizierung zu können, ihr könnt's ausprobieren, also ihr müsst die gleiche
Abfrage bekommen, wenn ihr ping.poggersxyz macht, Max, 1, 2, 3, 4, 5, 6 ist das Passwort,
das ist natürlich sehr praktisch, also wenn ihr irgendwas laufen lassen wollt, oder extern
zugänglich machen wollt, was selbst keine Authentifizierung hat, ich würde da mit das
eh nochmal überlegen, aber mal genommen, ihr wollt das, dann könnt ihr das zumindest
soweit Passwort schützen, natürlich auch praktische, sehr praktische Geschichte, ne?
Oh, down. Oh, Levantin links ist da ganz korrekt, was das angeht, ja, es ist TLS tatsächlich,
hat er recht, und auch ne neuere Version, 1.0 und 1.1, wobei gab's 1.1 überhaupt,
also 1.0 ist auf jeden Fall vorbei jetzt, ja, für Wartungsarbeiten ist das auch ne ganz
gute Geschichte, man kann auch irgendwie Redirects zu Wartungsseiten machen und sowas,
wenn man's voll übertrieben machen möchte, aber man hat jetzt nem Service beigebracht,
SSL zu können, also dem Service nicht wirklich, der funktioniert ja nach wie vor ohne SSL,
aber man hat nen Service jetzt, SSL davor, ein gültiges SSL Zertifikat und ne Authentifizierung,
die er vorher nicht hatte und veröffentlich im Internet zugänglich war, das ist natürlich
äußerst praktisch und das Beste ist, ich kann jetzt einfach, ich mein, ich muss nichts
konfigurieren, ne? Ihr seht's ja grad, Leute, ich muss nichts konfigurieren, das Einzige,
was ich brauch, meine Docker Compose Datei, ich sag Docker Compose up und der konfiguriert
mir das komplett, wie ich das brauch und starte das so, das heißt, wenn ich das jetzt
als Ausgangspunkt nehme, kann ich alle meine anderen internen Services konfigurieren und
entweder nur intern verwenden oder auch von extern zugänglich machen, wie ich das will,
oder halt intern bei mir über den Reverseproxy zugänglich machen. Ich hab das bei mir beispielsweise
auch so laufen, also mein ganzes Zeug, was ich hier auf der Kiste hab, also sprich von
Nextcloud bis das Gitfrontend, die Kameraüberwachungssoftware, das ist alles hinter hier in nem Traffic Reverseproxy
weil das Handling halt total easy ist. Traffic verbraucht leider viel CPU-Leistung, das ist
möglich, kann ich, also Performance kann ich nix sagen, aber da haben die meisten Leute
kein Problem damit. So, und jetzt wollen wir noch auf einen weiteren Punkt zurück zu
kommen, den ich am Anfang genannt hab. Übrigens, ich kann euch jetzt bei der Gelegenheit auch
mal zeigen, wie easy es sein kann, dort jetzt sagen wir mal nen, was kann ich da jetzt mal
kurz laufen lassen? Was kann ich denn da mal kurz laufen lassen, wo man nix kaputt machen
kann? Nen Git-Server. Ich lass jetzt einfach mal, naja. Was, wie monitort man die Container?
Na entweder intern mit irgendeinem Prometheus, was Docker versteht und kann, oder halt ganz
normal von außen guckt halt den Service nach. Ich mach mal nen Git drauf, da müsste ich
aber mal nen Passwort generieren, was ihr nicht kennt. Da muss ich mal nen Passwort generieren,
was ihr nicht kennt. So, da muss ich euch mal kurz rausschmeißen hier. So und das ganze
muss ich mir auf der anderen Seite aufschreiben, weil sonst vergess ich's definitiv. Gut, da
sind wir wieder. Wim Docker Compose. Das hier ist das Passwort. Da, da. Mal gucken. So,
wir legen mal nen Git-Server an. Machen wir mal. Kann ich hier mal abgucken von meiner
anderen Config? Wir legen mal nen Git-Frontend an jetzt. Zack, Set-Paste. Aus dem Geräusch
der Tasten natürlich das Passwort rekonstruieren. Exzellente Idee. So, wir legen jetzt mal hier
nen Git-Tier, wie auch immer man das ausspricht. Web-Frontend zum Git-Management an. In den
Ordner Home, HomeMaxGit-Tier-Dings. So, das geht nach Data. Ports brauchen wir jetzt Ports
22 für Git, sonst funktioniert's nicht. Wir sagen TrafficEnableTrue. Wir sagen Git-Progress.xyz.
SecureDNS-Challenge. Port 3000. Braucht man, weil intern läuft's auf Port 3000. Und gut
ist. Das hier übrigens, wenn man hier die Ports konfiguriert, die gehen vorbei am Reverseproxy.
Müssen sie in dem Fall auch, weil SSH kann der Reverseproxy nicht. Oder kann er das?
Doch, das müsste er wahrscheinlich auch können. Könnte man bestimmt auch konfigurieren.
Kann er SSH? Nee, kann er nicht. Kann er nicht. Der kann keinen TCP-Load balenzen. Geh ich
mal von aus. Ach, keine Ahnung. Hab ich nicht ausprobiert. Okay, schauen wir mal, ob das
Ganze jetzt funktioniert. Wir müssen jetzt natürlich noch sagen, ja, das brauchen wir
noch. Authentifizierung. Zack. Das ist mein super secret special Passwort. Und das nennen
wir nicht Auth, sondern hier BigBrainAuth2. Und das da unten nennen wir auch nicht WhoAmI,
sondern nennen wir Git. Nee, Git. Einfach nur Git. So, und das sollte jetzt hochfahren
und es sollte unter dieser Domain, git.progress.exe.z, den Service starten mit BasicAuth an mit
einem Passwort, was ihr nicht kennt. Und dann gucken wir mal, ob das funktioniert. Wenn
nicht, ist es auch nicht schlimm, dann mache ich es halt wieder aus. Down und ab. Exzellent.
Guck, und er pullt sich den neuen Container runter, startet das Ganze, holt sich ein neues
Zertifikat. Okay, er macht da Gedöns, was auch immer. Okay, gucken wir mal, Git. Ah,
er hat noch kein Zertifikat. Ich war zu schnell. Ich war zu schnell. Nee, ich habe glaube ich
was vergessen. Kann das sein, dass ich vergessen habe, die Domain anzupassen? Wartet mal kurz.
Kann das sein, dass ich vergessen habe, die Domain anzupassen? Ich glaube ich habe vergessen,
die Domain anzupassen, ne? Hier, nee, passt. Git.progress.exe.z. Nö, ist eigentlich vollkommen
richtig. Übrigens, das da muss weg. Nö, das müsste eigentlich so funktionieren. Okay,
schauen wir mal ab. Git, genau, Git. Ah, guck mal, basic aus, funktioniert schon mal. Äh,
Moment, ich muss mal mein Passport nachgucken, was ihr jetzt nicht wisst. Huge Big Brain
Passport. Und, zack, da sind wir. Ich blende euch mal. Und schon haben wir einen Git-Server
laufen. Ah, wir können jetzt hier noch Zeug einstellen, wie das ganze heißt. SSH-Server-Domain,
ist Base-Url. Git.progress.exe.yz. So, und dann SSH-Domain-Administrator-Passport. Gut.
Wie sollte das da eh nicht draufkommen? Und save. Ah, Passport. Okay, äh, ja, admin-add-boggers.xyz.
Äh, warum? Ah, weil ich heute die PS vergessen habe. Ah, exellent. Guck, und schon können
wir hier unsere, können wir ein paar Git-Repos anlegen, Zeug verwalten und managen und was
wir, und was wir so wollen. Und er hat für uns ein gültiges Zertifikat ausgestellt und
das Ganze hinzugefügt, sodass es von extern zugänglich ist. Also eigentlich eine richtig
super, super Geschichte und einfache Geschichte auch. Also, besser managen kann man die Sache
eigentlich daheim nicht, wenn man Container verwenden will. So, schmeißen wir das mal
wieder raus. Ich will das nicht unnötig lange laufen haben, den ganzen Kram. Ja, das ist
richtig gut. So, ich zeige euch jetzt noch mal eine Sache, die auch sehr praktisch ist.
Ich habe ja im Vorfeld gesagt, man kann die Container automatisch updaten lassen und dafür
gibt es hier folgendes. Nämlich nennt sich das Ganze Watchtower und was da, eGit, SetPaste,
CanTrafficTLS 1.3. Ich würde mal vermuten, dass das so ziemlich alles an TLS kann, was
schon Standard ist. So, das Ganze nennt sich Watchtower. Was das macht ist, das guckt
bei Containern, die man ihm hier angibt, zum Beispiel den WhoAmI-Container. Das andere
haben wir jetzt ja nicht. Guckt das nach, ob es neue Versionen gibt. Und in diesem Setup
ist das halt Next Level Big Brain. Übrigens, er konfiguriert das alles wieder von uns.
Äh, by the way, stopp. Naja, macht mal aus. Ja, der Kommandator, wie gesagt, das Setup
kann ich daheim nur empfehlen, das habe ich bei mir auch laufen. Moment, was hat er denn
für Schmerzen hier? Will er denn da? Ah, okay, weil ich ihn gelöscht habe, bevor ich
down gemacht habe wahrscheinlich. Jetzt aber, ab. Wunderbar. Also, der startet jetzt Watchtower,
WhoAmI und Traffic. Und wir sehen jetzt auch hier, was der macht ist, der schaut nach,
also der guckt jetzt in der Stunde irgendwie wieder nach, ob es neue Updates gibt von diesem
Container. Und wenn es neue Updates von dem Container gibt, von dem WhoAmI-Container in
dem Fall, weil es der einzige ist, den ich konfiguriert habe, dann updatert er den, also
sprich, stoppt den Container, updatert den und startet ihn wieder. Hier, guckt da. No
New Images for WhoAmI. Und damit hat man jetzt quasi ein System, wenn man das einmal schön
konfiguriert hat. Äh, ja, ich weiß, dass das ein Webinterface hat, aber wenn ich das
Webinterface anschalte, muss ich auch gleichmaßen die AP einschalten und das will ich von außen
nicht machen. Also, Traffic hat ein Webinterface. Ich zeige euch mal eine Demo davon, falls
die eine haben. Ne, das ist 1.7. Genau, das hat ein Dashboard, ist eigentlich ganz praktisch,
so sieht das dann aus. Da sieht man, ähm, was da so gerade an Traffic drüber läuft
und welche Dienste, Container teilweise auch ab sind dahinter, wie viel es Fehler gibt.
Das ist ganz nett. Das ist ganz nett. Aber, wenn man, äh, wenn man beispielsweise irgendeinen
Grafana laufen hat, kann man sich die Metriken auch da schön anzeigen lassen. Aber ist eine
nette Geschichte, kann man einschalten. Das, wenn man ein bisschen Übersicht, wenn man
ein bisschen Überblick über seinen LordBalancer haben will, das kann man machen. So, und man
sieht hier, er guckt im Internet nach, ähm, ob es von diesem WhoAmI-Container neue Updates
gibt. Ihr sagt ja auch No New Images Found gibt es nicht. Sollten die jetzt zufälligerweise
gerade ein neues Image pushen, würde er den stoppen, updaten den Container und wieder
neu starten. Also sprich, wir haben jetzt ein Setup, was automatisch für neue Services,
also egal wie viele Services sich hier dahinter packt, erst einmal, äh, neue Zertifikate,
gültige SSL-Zertifikate ausstellen kann, was den einzigen Eingangspunkt hat in meinem
System, ohne dass ich diese Services exposen muss, irgendwie ins Internet oder ins lokale
Netzwerk oder sonst was. Und als, als, äh, Bonus obendrauf updaten sich die Sachen auch
noch automatisch. Was, wenn bei einem Auto Update was kaputt geht, ja alles gleiche, wie
wenn du ein Update von Hand machst. Es geht nicht mehr. Deswegen versuche ich es auch
immer so zu machen, dass ich meine Container nicht auf Latest stelle, so wie die hier,
sondern immer auf die letzte Major-Version und nur meiner Version automatisch updaten
lasse. Das funktioniert nur, wenn die Projekte das richtig taggen. Also normalerweise schreibe
ich in meine Config rein, Nextcloud, zum Beispiel Nextcloud Version 19, dann macht der Updates
für Nextcloud 19 inklusive Sicherheitsupdates für Version 19. Allerdings, er macht kein
automatisches Update auf Nextcloud 20. Ja, das, äh, heißt natürlich, man muss ein bisschen
drauf schauen, ob die Docker-Container-Hersteller, bzw. die Docker-File-Typen von Docker hat,
was man verwendet für seine Container, die Sachen richtig taggen. Dann hast du eigentlich
selten Probleme. Also innerhalb eines Major-Releases gehen die Sachen selten kaputt, aber unterm
Strich, ja gut, es geht genauso kaputt, wie wenn du es von Hand updaten würdest. Nur
dass halt hier ein Rollback relativ einfach ist. Also sprich, ähm, wenn ich jetzt hier,
keine Ahnung, von Version 1 auf Version 2 update und Version 2 ist kaputt, dann trage
ich hier einfach wieder Version 1 ein und starte das Ding und in der Regel geht's. Es sei
denn, Version 2 hat die Config-Files, die diese Anwendung vielleicht hat, beim Update
inkompatibel kaputt gemacht zu Version 1, dann kannst du auch nicht einfach rollbacken,
aber dann sind wir wieder bei ganz klassischen Sachen wie, vielleicht sollte man ab und
zu mal seine, äh, Configs-Backupen. Und, ähm, wenn es einfach nur rein um Configs
geht, spricht auch nichts dagegen, die Configs für die Anwendung hier im Git mit einchecken.
Keine Ahnung, äh, äh, jetzt haben wir sogar noch ein Git-Update gemacht, einfach weil
es geht, nicht weil es jetzt irgendwie, weil wir es bräuchten. Kann man auch die einzelnen
Docker-Instanzen gut back-upen? Du musst die Docker-Instanzen nicht back-upen, das
einzige was du back-upen musst ist, ähm, die Ordner, wo diese Instanzen ihre persistenten
Daten liegen haben. Und da kannst du updaten, wie du lustig bist. Kannst mit Borg back-upen
machen, mit allem, mit R-Sync, äh, was auch immer, ja. Es gibt bestimmt, habe ich mich
aber nie mit beschäftigt, es gibt bestimmt sogar fertige back-up, ähm, Scripts, die
du in dein Compose-File reinhauen kannst, die selbst als Docker-Container laufen und
das irgendwie für dich machen. Würde ich wetten, würde mich sehr wundern, wenn es
das nicht gibt. JollyYoka, zwei Monate abonniert, dankeschön, excellent subscription. Ja, und
so sieht das ganze mit Docker-Compose aus. Und man, es ist ja nur wirklich nicht großartig
kompliziert, ne. Ich meine, wir brauchen hier ein bisschen Config für den Traffic-Container,
dann haben wir hier so ein Test-Container drinne und ein Update-Container. Das war's. Alles
weitere, was ihr jetzt hier reinschreibt, wären Services, die ihr betreiben wollt.
Von Nextcloud bis Gitfrontend bis irgendwie ein Dashboard bis Home Assistant, Heimautomatisierung,
irgendwelche Torrent-Download-Dinger, was auch immer. Ihr schnappt einfach euch irgendwie
ein x-beliebiges Docker-Image, beziehungsweise aus der Docker-Registry, Docker-Hub, irgendwas,
was ihr betreiben wollt, dem ihr traut, ne, darf man immer nicht vergessen, wenn man einfach
mit Docker irgendwas startet, man hat offenbar jetzt gar keine Ahnung, was man da startet,
also sprich, ihr startet auch nur irgendwas, dem ihr traut, dass es was taugt, fügt das
hier ein und Docker-Compose ab, fertig konfiguriert, SSL-Zertifikat, Alternifizierung davor, falls
ihr braucht, und Auto-Updates. Also einfacher kann's eigentlich nicht mehr gehen. Man muss
es halt einmalig jetzt hier einrichten, so wie wir's hier gemacht haben. Das ist schon
ziemlich poggers. Next Level Big Brain. Ich hab übrigens gesehen, dass es im Chat viele
Wim-Fans heute gab. Soll ich euch noch mal einen richtigen Big Brain Wim-Trick zeigen?
Also den hab ich euch ja schon gezeigt, ja? In irgendeine Zeile gehen und Change in der
Anführungszeichen tippen für alles zwischen zwei Anführungszeichen löschen. Ich zeig
euch jetzt nochmal den absoluten Big Brain Wim-Trick. Also gehen wir mal von aus. Also
das erste, der Low-Brain, die Low-Brain-Variante von diesem Trick ist, Block-Select. Wim hat
zwei Sachen. Wim hat normalen Select, Wim hat Line-Select, äh Schwachsinn, Wim hat
Line, hallo? Wim hat Line-Select und Wim hat Block-Select. Damit kann ich zum Beispiel
als bei diesen Zeilen untereinander die Leer-Zeichen löschen komplett. So, aber das wollte ich
euch jetzt gar nicht zeigen. Gehen wir mal von einem anderen Fall aus. Ähm, achso, Block-Select
ist Steuerung-V. Gehen wir mal von aus, wir möchten jetzt, wir haben uns hier verschrieben.
Oder keine Ahnung, was war man da jetzt? Ja, wir haben uns hier verschrieben. Wir haben
uns hier verschrieben. Es muss Minus-Minus sein, aber wir haben nur Minus gemacht. Jetzt
geht's Big Brain Wim-Trick. Also, Block-Select, großes I, einmal das Minus einfügen und dann
Escape drücken und dann fügt's überall für euch ein. Wim-Magic. Geht übrigens umgedreht
auch, also wenn ihr hier vorne Leer-Zeichen vergessen habt und wollt Leer-Zeichen einfügen,
Select, Groß, Groß I wohlgemerkt, nicht Kleine I, Groß I. Einrücken, Escape drücken, zack,
also sprich, der macht das hier, was ihr hier oben tippt, exakt in den anderen Zeilen, die
ihr markiert habt, danach nochmal. Ähm, ja. Auch noch eine weitere coole Geschichte ist,
mal angenommen, ihr sucht das Wort, das Wort Traffic oder Labels, nee, was nehmen wir mal?
Image, Image. Ihr sucht das Wort Image in der Datei, fangen wir mal oben an. Die Noob,
die Noob-Variante ist Image. Das kann jeder, ne? Slash Image. Was mehr Big Brain ist, Sternchen
drücken, ne? Also suchen wir mal, keine Ahnung, ich zeig euch mal, dass es funktioniert. Wir
suchen mal jetzt nach, äh, Traffic, Traffic. Einfach draufgehen, Sternchen drücken und
automatisch alle Traffic-Vorkommen finden. Mit Next. Also, man kann auf, oder, wenn ich
Huemi suche, Sternchen drücken und dann mit Next oder Back zu den nächsten Huemi-Vorkommen
springen. Was natürlich auch ganz praktisch ist, zum Beispiel, stellt euch mal vor, stellt
euch mal vor, wir machen jetzt Sternchen, wir machen jetzt hier, Sternchen. Huemi, Sternchen.
Ähm, und wir wollen jetzt da nicht Huemi draus machen, sondern Huemai. Zwei. So, dann drücke
ich jetzt einfach, SK, N, nächste, nächste, nächste Vorkommnis, Punkt O. Okay, zu viel
Wim-Magic hat nicht funktioniert. Müsste, müsste, es müsste aber eigentlich funktionieren.
Zwei. Ah, ich weiß, warum es nicht funktioniert. Kann das sein? Next. Moment, warum hat es
jetzt nicht funktioniert? Next. Zwei. Next. Ach so, weil er nicht hinten an das, weil
er nicht hinten an das Wort rangeht. Also, man kann mit Punkt nämlich den letzten Inside-Profil
doppelt machen und das geht nicht, weil er an der Stelle ist, er müsste an die Stelle
springen. Okay, vergesst, was ich euch zeigen wollte, das war ein Scheißbeispiel. Aber
ich kann euch, ich kann euch noch, ich kann euch noch was anderes zeigen. Ja, natürlich
mit Search and Replace geht das auch, aber das ist die Fikule, wo sie das Wim zählen
kann. Wim kann zählen. Also, zum Beispiel, wenn ich jetzt sagen will, Traffic 2.2 will
ich nicht, sondern ich will Traffic 3 oder vielleicht sogar Traffic 4 oder Traffic, Traffic
1.62. Kann ich direkt in Wim machen, ohne dass ich da selbst tippen muss. Ich mein, in
dem Fall könnte ich einfach einschreiben 3, ja. Aber ich kann auch mit Steuerung A und
Steuerung X, also mein, Steuerung A, Steuerung X, intuitivere Key-Shortcuts kann es ja für
addieren und Subtra hier nicht geben, ja, Steuerung A, Steuerung X. Ich mein, wer kommt
da nicht sofort intuitiv drauf? Kann man hochzählen und runterzählen, ne? Also, mal angenommen,
ich möchte jetzt sagen, ah ne, ich will Version 3.0, zack. Noch, wie? Ja, so sieht's aus. Wim
Magic. Und wer übrigens keinen Bock hat, Wim mit Doppelpunkt X zu beenden, der kann
noch viel besser, der kann Shift ZZ drücken, da geht's auch zu, ja. Warum? Die Existenzberechtigung
dafür hat sich mir noch nicht erschlossen, aber es ist halt da. Werden die Container
nacheinander gestartet, also dass WhoAm I wartet, bis Traffic gestartet wurde? Ich glaube,
es geht von oben nach unten. Aber ich bin mir ehrlich gesagt nicht sicher, keine Ahnung.
Sollte das nicht der Fall sein, kann man dem garantiert sagen, der Container hängt mit
dem Container zusammen und der muss warten. Das geht mit Sicherheit, habe ich aber noch
nicht gemacht. Ja, ist auch ein paar krasse Wim Hacks. Ja, da sind wir fertig, hat wunderbar
funktioniert. Also wir machen das noch nicht aus, aber wir sind mit dem Projekt jetzt eigentlich
fertig. Zack. Wir löschen mal, wir löschen mal unser, unser DNS-Token. Vorpapier anmachen
wir auch wieder zu. So, wir haben unser DNS-Token gelöscht. Und, oh, ganz wichtig, ich muss
meine Digital-Ocean-VM löschen. Also, wollt ihr noch irgendwas sehen, weil ich lösche
jetzt meine, meine, vor allem wo ich das drauf gemacht habe. M-RF, äh, Slash, das funktioniert
nicht mehr. Das ist, das geht nicht mehr. Man muss No Preserve Route eingeben. Codeserver
wolltest du noch machen? Ne. Ne, ne, ne, habe ich mir anders überlegt. Ich mache kein
Public Codeserver da drauf. Wer weiß was die Leute da für komische Dinger reinpasten.
Aber bin ich noch dran schuld? Ne, ne, ne, ne. Okay, bam, in your face. Destroy. Äh, Moment,
ich will es löschen. Destroy. Monkeys, destroy. Die Musik passt da auch gut dazu. Bam. Grip,
droplet. So, die Site wird noch gelöscht. Remove Site from Cloudflare, zack.
Leute. Alles umsonst. Und jetzt lösche ich noch meinen Cloudflare-Account. Wie
geht denn das? Geht das überhaupt? Kann man seinen Cloudflare-Account löschen? Wie löscht
man seinen Cloudflare-Account? Leak. Wie lösche ich, wie lösche ich meinen Account?
Hat irgendjemand eine Ahnung? Delete Cloudflare-Account. Click Cloud für Icon. Ne. Ne,
Luso97, das geht nicht. Da haben die schon, da haben die vorgesorgt, Luso97, dass es nicht
geht. Wenn du das probieren würdest, äh, müsstest du andere, müsstest du andere DNS-Server
eintragen, als die, die ich eingetragen habe. Da haben die schon mitgedacht. Müsste in meinem
Profil gehen, ja, aber wo? Mit einem Profil. Edit. Geht, geht nur über Support. Das ist
mal wieder was. How do I delete my account? Äh, ja, ja, ja, ja, ja, ja, ja, ja, ja, ja,
ja. Äh, what? Subscriptions? Ne. Das scheint, okay, das scheint enorm big brain zu sein,
meine Account zu löschen. Haha, warum ist das wieder so kompliziert, du fucking Account
zu löschen, Alter? Cloudfair, not Cloudflare. Kennste, ich will keine Subscriptions, ich
will meinen Account löschen. Hyprons, zwei Monate, dankeschön. Exzellenz Subscription.
Äh, ich, ich hab in meinem Profil keine Subscriptions, weil ich hab ja keine Billing-Informations
hinterlegt. Ich hab nur Authentification, AP Talks. Ähm. Billing? Ah, hier, Subscriptions.
Ne. Email? Hahaha. Du kannst unter Members dich austragen, was, Members? Ja, ne, das
ist so, ich will, ich will meinen Account löschen. Das löscht wahrscheinlich nicht
meinen Account. Tja, geht wohl nicht. Geht wohl nicht. Schreib den Support an, oh meine
Güte ey, das ist so voll lächerlich, warum muss ich mir, ich mein, ich hab kein Problem,
ich kann auch den Cloudflare-Account einfach behalten, ist nicht so, als würde mich das
jetzt großartig jucken, dass ich Cloudflare-Account hab. Oh, Logout, gut und Tschüss. Digital
Ocean und Tschüss. Exzellenz. Userzahlen, weil sich niemand löschen kann, ja das vermute
ich nämlich auch. Big Brain. Äh, was sagst du eigentlich zu der Heisemeldung? Die hab
ich noch gar nicht gelesen. Äh, das Docker, als 80% der Docker-Images sicher als Lünger
haben. Ja, wundert mich nicht. Wann kam das? Äh, wundert mich nicht. Ähm, viele bauen
halt Docker-Images für sich daheim, wo das vielleicht nicht so relevant ist bei einem
internen Service. Äh, mit Ollen, mit Ollen-Versionen von irgendwelchen Libraries, mit Ollen-Versionen
von Software. Ähm, juckt mich nicht. Äh, äh, äh, wundert mich nicht. Desktop ist
der beste. Ja, exzellent. Massive Desktop. Und Windows XP im Hintergrund natürlich, ja.
Wie viel hast du jetzt für den Server gezahlt? Äh, kann ich nicht nachgucken, aber wir haben
den Server jetzt angelegt vor ungefähr drei Stunden. Also hab ich null Komma abgerundet
ungefähr null Komma zwei Cent oder so bezahlt. Nee, zwei Cent, zwei Cent, nicht null Komma
zwei Cent. Zwei Cent hab ich bezahlt. Zwei Cent. Das geht natürlich unglaublich ins Geld.
Also wenn ich da jetzt mindestens noch 15 Twitch Prime Subscriptions kriege, dann kann
ich mir das nicht leisten. Da muss ich meinen Internetabschluss, meinen Internetanschluss
abbestellen. Dann gibt's keine Streams mehr. Das geht überhaupt nicht. Nee, also für so
kleine Sachen und vor allem das kleinste Setup bei Digital Ocean ist wirklich nicht
so teuer. Deswegen sag ich ja, für mein, ähm, Open Street Maps Pre-Processing, was
ich da mache ab und zu, da miete ich mir gerne so fette Kisten mit 96G RAM und 48 CPUs und
sowas, weil dann geht das Pre-Processen sau schnell und ich bezahle am Ende auch nur 3,50
Cent, falls halt nach eineinhalb Stunden fertig ist. Schön steuerlich absetzen. Oh ja. Zwei
Cent. Das ist mir viel zu anstrengend, das über drei zu schreiben. Durst. Hörst du
eigentlich Rap? Nee, nicht wirklich. Eher zur Belustigung. Einzige, was ich mir geben
kann, ist Eminem. Und ich finde, das sagt schon alles aus, ja. Also, Eminem gilt ja,
oder galt ja mal, zeitlang so als der krasseste, geilste Rapper-Man auf der Welt, ja. Wenn
das, also wenn quasi der beste der besten, ähm, den einzigen ist, den ich ertrage, spricht
nicht unbedingt für dieses Musikschore. Weil alles andere halte ich meistens nicht
lange aus. Was machst du da mit Open Street Maps? Wir haben eine Software gebastelt, mit
der Handwerker sich Routen berechnen lassen können. Alter, die Musik.
Wie, SL ist nicht installiert? Ist das nicht SL mit dem Zug? Wie ist das mit dem Zug?
Was nicht, SL? Warum gibt es das nicht zu installieren hier? Was ist da los? Warum gibt
es hier kein SL zu installieren? Aha, anscheinend doch, ok. Ah, exzellent. So, Traveling Salesman,
genau, genau. Und wir verwenden einmal die Google Maps API. Was muss man hier nochmal
machen, dass das, ich habe keine Ahnung, ob das eine Option hat für Loop. Wir machen
jetzt die Big Brain Loop überhaupt. Ah, exzellent. Was wollte ich jetzt gerade sagen? Also wir
nehmen Google Maps, die Google Maps API für Adressvervollständigung und solche Geschichten.
Aber das eigentliche Routing berechnen machen wir mit Open Street Maps. Und dafür braucht
man einen riesen fetten Rechner, um die Open Street Maps Routing Machine Sachen zu preprocessen.
Wenn man das erst mal preprocessed hat und man das einfach nur benutzen will, dann kommt
man mit viel weniger RAM aus. Aber das preprocessen braucht massig Rechenleistung und massig RAM
und das ist ganz gut, wenn ich das in Digital Ocean vm mache, weil da bezahle ich wie gesagt
350 für 1-2 Stunden mal 96G RAM und irgendwie 32 Kerne. Das ist dann ganz praktisch. Kannst
du nicht auch öffentliche Open Street Maps Server benutzen? Doch, aber die sind ja rate
limited ohne Ende und die sind ja auch nicht zur kommerziellen Nutzung freigegeben. Also
wenn wir da immer mal viele Anfragen stellen von der gleichen Absender-IP, blocken die
uns halt und dann geht unser kompletter Service auf einmal nicht mehr. Also Open Street Maps
selbst reicht nicht, ich muss OSMR verwenden. Oder OR... frag mich nicht wie das Ding heißt
jetzt aus dem Kopf. Und die blocken einen, ja. SL-A, was macht minus A? Ist das... Oh guck
mal. Big Brain, ich kanns nicht mehr beenden Leute. Ich kanns nicht mehr beenden, weil
ich ne Schleife gemacht hab. Die Schleife ist so... Die Schleife ist schneller als ich
canceln kann. Jetzt muss ich sagen kill all SL-Bear... Oh ne da gehts ja gleich wieder an.
Kill all... Nö. Was davon ist jetzt meine Shell? Ah die letzte Big Brain. Die hier
das seine ich kann nicht mal copy paste mehr geht nicht aus minus 9 ok das war
nicht die richtige schell ja was wir machen das anders big brain schießen
einfach das teamwork spayen ab was macht sl minus was minus a was macht minus a
was macht minus a ach an accident ok lollcat habe ich das installiert ne aber das das brauchen wir
das ist das wichtigste kommandos wo ist da los das ist das wichtigste kommando zeilen
programm überhaupt lollcat das braucht man ohne lollcat geht nix gar nicht warum ich das nicht
installiert habe das ist huge important ah jetzt excellent so ist das doch schön kann man auch das
ascii aquarium nach lollcat palmen oh wow poggers all die fische haben irgendwas genommen
das ist ja so lsd fisch disko fisch
so was gab es noch für frank wie läuft eigentlich der internet seit dem wipp hochstufung
ohne mist wunderbar die haben sich ja nie dazu geäußert dass das vielleicht einen community
manager oder wie auch immer man das bei unity medialand keine ahnung war pr man hat ja keiner
sich irgendwie dazu bekannt aber es war sehr merkwürdig die meld die message die ich da
gekriegt habe so nach dem motto mit refund und allem ab und vor allem dass seitdem mein
internet zeug ohne jegliche jegliche probleme funktioniert also chris down edge wir machen
das halt für ganz europa ganz europa so pre-processen dauert wir haben sie mal im stream gemacht
irgendwie zwar eineinhalb zwei stunden brauchst halt 96 g ram und viele cpu kerne und es ist
schlimmer als traveling salesman weil wir haben termine also wir brauchen quasi traveling salesman
mit time windows und im zweifelsfall sogar noch mehreren autos da gibt es ein extra name für
traveling salesman ist quasi unterkategorie davon also wir haben verschiedene wir haben
mehrere autos und termine wo man routen mit planen muss ist aber richtig gut weil wir
müssen den kram nicht selbst implementieren da bin ich viel zu low brain dafür oder besser
gesagt ja ja da bin ich zu low brain für weil die kombination aus ich bin zu faul
für oder muss man sich richtig reinarbeiten dass man da was gutes hinkriegt da bin ich
definitiv zu low brain für deswegen bin ich froh dass ich nur das frontend bauen muss für
den open source projekt was das alles schon macht der high geht ab hier und unten drunter
machen wir noch sl und drunter machen wir noch sl an oben flippen die fische aus und unten schreien
die leute im zug um hilfe wo kaufst du deine moments die habe ich jetzt für den stream gekauft
bei park bahn kann man t max in lol catpipen ist glaube ich nicht weil t max hat kein output
also kein vorbei keine ahnung scheint letztlich weiß ich nicht habe ich nicht aus will ich auch
nicht ausprobieren jetzt wofür brauchst du in reverse proxy also ich habe ihn ja schon lange
laufen heute haben wir es eingerichtet weil im letzten stream einer das als thema vorgeschlagen
hat und ich fand das nicht schlecht da mal darauf einzugehen ja also wofür ich brauche ich habe
es bei mir intern laufen für git git web frontend den next cloud was habe ich denn da alles ich
habe es ich habe es euch doch mal aufgeschrieben kriegt es gerade aus dem kopf gar nicht mehr
alles zusammen wie gesagt next cloud git frontend fällt mir gerade nicht ein ich habe aber vier
fünf sachen da auf home assistant natürlich heim automatisierungszeug back up sind sogar
eher von sechs sachen nicht vier fünf sachen jenny finde wofür habe ich nicht laufen ich
verwende als obwohl ich ja der self-hosted verfechter bin ja amazon prime musik
dass du nachts gut schlafen kannst wenn du das alles mal hä ja wie willst du es denn
sonst machen was ist denn die alternative du verwendest halt irgendwelche fertigen services
und verlässt dich darauf dass es andere machen ja kannst du auch machen wenn du selbst machen
willst bleibt der nix anders übrig als selbst zu machen kannst du erst die querung auf respite
installen ja aber ich glaube ist nicht im standard report drin ansible kann man machen ja aber
aber für das was wir heute gemacht haben ist das doch komplett unsinnig da warum soll ich
dann ansible script für basteln wenn das eine 20 zeilen konfig sind die ich einmal erstelle
in mein repo einchecke und was alles andere für mich händelt ich brauche ich brauche ja keine
ich brauche ja kein server konfig tool was mein infrastructure konfig tool konfiguriert das
wäre schon ein bisschen übertrieben
oh guck mal der soundtrack ist fertig geblendet aber auf
er hat ansible script gesagt na ja es war eigentlich ein ganz guter vergleich den einer
freund gebracht hat wir haben ja heute relativ viel docker compose geschichten gemacht das
docker compose und ansible gar nicht mal so unterschiedlich sind von dem was am ende
rauskommt man legt konfig datei an und hat ein konfig management tool was dann das system
in den zustand bringt wie man es dort beschrieben hat und ich wie gesagt ich brauche kein konfig
management tun um ein konfig management tool zu konfigurieren also man kann es ja irgendwo
auch übertreiben gibt es gibt es da keinen switch für endlos gibt es eigentlich bessere
distribution die auf dem respekt viel laufen nö respiren ist das beste hallo das kann
kein help was ist denn da los bist du eigentlich schon auf meine frage mit dem öffentlichen
dienst eingegangen nee habe ich nicht aber dafür haben wir ja mein poggers auch wenn
es ganz schön hell ist gebe ich zu ein poggers fragen mit log tool da hier kommt mal das
fragen mit log tool das funktioniert exzellent was hältst du eigentlich davon als healer
beim öffentlichen dienst zu arbeiten spiele mit dem gedanken rum mich auf solchen stellen
zu bewerben ich halte da weder was von noch halte ich da nix von das ist ein job wie alles
andere auch die frage ist ob die bezahlung passt ich habe mich ja auch mal ein bisschen
umgeguckt und was du da teilweise was was da teilweise für eine gehaltgruppe drin steht
das war ja armselig wie lief es mit der einrichtung hat wunderbar funktioniert würde gerne e3
wäre im aufsetzen gutes total ja wir haben einen livestream gemacht und das installiert
das hast du sogar das haben wir irgendwo im archiv leute ist das archiv schon durchsuchbar
ist das neue archiv schon durchsuchbar also der chat ist ja big brain die programmieren
gerade in archiv aber guck mal ich sehe mich selbst die drei wm fast moment das ist das
ist zu alt das stimmt so nicht manjaro einrichten ist das glaube ich das sind nur clips das
kann doch gar keine streams durchsuchen ok ok vergiss das warte mal wo ist das stream
wo ich manjaro einrichte das kann ich so das kann ich so lange her sein hier geht es zur
übersicht das kann ich so lange her sein search txt manjaro hier 30 sitz ne
das müsste es hier gewesen sein 27 der dritte es gab mehrere streams in einem stream hatte
ich ein bisschen verkackt das hier das hier müsste das stream sein wo manjaro eingerichtet
haben und danach noch barbecue bed boys geguckt ja das das müsste das stream sein ja das
müsste das stream sein wupplors.tv findest du das archiv ja wupplors.tv dann oben auf
archiv und dann gehst du zur alten übersicht die neue archivseite geht noch nicht richtig
die ist broken gerade einfach hier im google ordner für 27 den dritten gucken also da
muss man den wir müssen übrigens den sebaro nochmal loben dass der sich da auch immer
schön ums archiv kümmert weil ansonsten werden die alten dinger jetzt schlechter greifen
weg chat eine runde ajaja für den sebaro
sl kann man wohl nicht loben lassen na gut ich find die bahn ist top wie die hier im
kreis fährt naja dann machen wir doch wieder eine schleife sl bamm perfekt ja leute habe
ich irgendwelche anderen fragen übersehen eventuell sogar stimmt jede menge kann ich
kann ich das nicht hier aufmachen habe ich habe ich hier nicht dark ah dark reader excellent
hast du erfahrung mit frinas ich habe es mal ausprobiert hat mir nicht gefallen wie
jetzt ja aktuell mir geht es gut frinas hat mir nicht gefallen eine sache die mir über
frinas instant auf den sack gegangen ist die community die auch irgendwelche fake news
verbreitet und darauf besteht es wäre so wie zum beispiel dass zfs unbedingt ecc ram braucht
oder irgendwie was erzählen sie ein giga oder irgendwie was erzählen sie immer gigabyte
ram pro terabyte zusätzlich und so komische dinger kompletter schwachsinn das brauchst
du vielleicht wenn du zfs in einem in dem business umfeld betreiben möchtest ja wenn
du daheim eine nass betreiben willst brauchst du das nicht wie gesagt das hatten wir schon
domains habe ich wie gesagt bei pork bunn gekauft aber die würde ich nicht empfehlen
die sind einfach nur billig ansonsten haben die keinerlei features und habe ich gebannt
aber da bin ich selber dran schuld ja wie gesagt funktioniert gut hatten wir schon hatten
wir schon hatten wir schon lokal lokal alles lokal bei mir wie gesagt 22,1 cent habe ich
für den selber bezahlt das hatten wir auch schon das hatten wir auch schon
wie heißt das klipport tool für e3 das ist echt kompliziert das habe ich jetzt nicht
mal gemacht das ist rofi nennt sich das rofi und als klipport tool selbst ist klipp kreen
klipp klipp klipp kreen klipp als klipport manager und rofi als anzeige zum auswählen
das coole ist man kann da auch progas man kann auch drinne durchsuchen und das ist echt
sehr praktisch ja das mit dem token hat mich ganz schön gebadet hast du eine eigene mail
serve für private mails oder bei welchem haus ein bisschen habe ich nicht sehe ich
auch keinen sinn drinne ehrlich gesagt eine mail server für private mails zu machen wozu
rofi mochi nee aber ich kann mir vorstellen was es ist und wahrscheinlich klappt ganz
gut ne brauche ich nicht sehe ich sehe ich auch keinen keinen sinn drinne mail privat
zu hosten ich habe ich habe total viele emails bei unterschiedlichsten anbieter auch bei
gmail ja gezwungenermaßen wenn du youtube account anlegst das hälfte von portana finde
ich überflüssig ich brauche kein web frontend dafür sage ich aber vielen anderen sachen
auch ich lach mich da immer teilweise so ein bisschen kaputt wenn ich die leute bei uns
auf der arbeit sehe die sich partout weigern so die gett basics in der kommando zeile zu
lernen und dann mit irgendwelchen gett guise ankommen die unsinnigste sachen machen so
leere leere comments einfügen und uns komische sachen das schlimmste plugin für gett ist
eget aus eclipse das verbindet alles was ich nicht mag java eclipse und gett frontends
das wie gesagt da wüsste ich nicht was ich machen soll das habe ich schon beantwortet
weil wir auf der arbeit zum größten teil cento s verwenden und mir persönlich aber
Ubuntu lieber lieber ist und besser gefällt kennst du mailbox org nee kenne ich nicht
kenne ich nicht aber wie gesagt brauche ich auch nicht also ich habe genug email adressen
für alle möglichen dienste die ich verwende und kalender kontakte habe ich mein nex cloud
über kaldorf kardorf und emails benutze ich so gut wie kaum noch ich glaube ich glaube
ich habe jetzt ohne miss ich glaube ich habe dieses jahr noch nicht eine email geschrieben
aus der arbeit außen vor ja das ist das natürlich aber privat habe ich glaube ich dieses jahr
noch nicht eine email geschrieben email ist outdated mittlerweile kann man mit cream clip
nicht aber halt mit dem ruf im menu kannst du halt filtern ne
aber ich habe tatsächlich vor dass sie bald kommen aber ihr kennt mich
wenn ich bitte war nutze dann hätte ich über den reverse proxy beziehungsweise über letzt
encrypt ein ssl zertifikat ich möchte nur mein server von innen zugreifen von aussicht
ja klar das wichtige dass du ein gültiges letzt encrypt zertifikat bekommen kannst
ist dass dir die domain gehört und du zugriff auf den dns server hast davon dann kannst
du auch den eigentlichen service nur intern verwenden das überhaupt kein problem was
ich auch nur empfehlen kann so wenig wie möglich irgendwie extern verfügbar machen es gibt
ja leute die sagen ich habe mein raspberry mit nextcloud ich hänge jetzt einfach mal
direkt an meine fritzbox transport weiterleitung wunderbar und dann alles mögliche drauf ja
von der letzten steuer erklärung bis zu privaten fotos und alles und sich dann wundern dass
da irgendwas in die hose geht würde ich nicht machen also gerade wenn ich nextcloud hätte
was ich möchte dass es ins internet vom internet zugegriffen werden kann würde ich das immer
über den reverse proxy machen also zwei sachen heim automatisierung und nextcloud das sind
so zwei systeme die würden unglaublich davon profitieren über den reverse proxy zu gehen
weil ich traue so sagen wir mal im engine x oder im traffic eher was security sachen
angeht und äh autentifizierung zu wie jetzt so der komplexen software wie nextcloud oder
home assistant und dann mache ich einen basic os davor mit meinem reverse proxy und dann
ist das schon mal relativ sicher die allerbeste variante ist natürlich äh gar nicht von
außen aufmachen sondern nur einen vpn erlauben von außen und dann erst vpn einwahl und dann
über vpn das verwenden das ist die allerbeste variante ja der das tool lockt nur entwobblos
mit also wenn einer will dass ich irgendwie was wirklich sehe da muss man entwobblos dabei
schreiben weil dann ist es rot im chat und mein fragentool lockt es mit ha gar nicht
erstmal ok ich glaube wir haben alles exzellent guck mal was für ein timing es ist sogar
22 uhr aber so haben wir so zehn minuten oder so hätte ich hätte ich noch zeit wenn
es irgendwas äh gibt was was wir noch besprechen müssen ja also wenn es doch irgendwas interessant
es gibt zehn minuten zehn minuten hätte ich noch wie fandet ihr den stream heute war
relativ äh viel technik gebastelt aber ich glaube ein thema was auch einige interessiert
hat ich meine wir hatten zwischenzeitlich 230 viewer 230 viewer hast du selten bei so
einem thema bist du jetzt zufrieden mit dem 42 herz monitor ja top monitor top monitor
ich mein es ist für grafikdesigner ein scheiß monitor aber für mich der damit klar kommt
wenn der monitor halbwegs gut eingestellt ist dass die farben so annähernd echt aussehen
und hauptsächlich drauf spielt und keine quasi print anwendung hat oder so äh ist
der monitor echt super welchen hast du dir gekauft äh ein ein ein ein ein benkyo den
hier das ist der neun das den gein den gibt seit ein paar jahren allerdings seit diesem
jahr in der verbesserten variante und das mit dem s hinten dran den hier mir gekauft
gibt sind eigentlich liefertermin unbekannt guck mal ich hab wohl einer den wenigen bekommen
die verfügbar sind aber das ist richtig guter monitor ja es ist halt es ist halt nur ein
full hd und es ist auch nur ein 24,5 zoll reicht ja vielen heute nicht mehr aber wenn
du 240 herz willst dann also hohe bildwiederholrate und hohe auflösungen eben beides zusammen
geht halt noch nicht äh sebaro ich weiß es ehrlich gesagt nicht genau aber in meinem
dot file repo auf github ist alles drin hoffe ich zumindest muss mal gucken äh deiner meinung
nach ein passendes einstiegs gehaltener für die physik nach ausbildung kann man pauschal
nicht sagen kommt darauf an was man macht und kommt auf die region an und wo man gelandet
ist kann man so pauschal nicht sagen wollte vor kurzem einen server in mein home network
verbinden der server ist aktuell nur über ein vpn direkt erreichbar hast du da eine
idee wie ich das hin bekomme dass ich ein vpn dauerhaft im netzwerk habe und alle geräte
im netz ohne einen eigenen vpn darauf kommen äh äh ich bin mir nicht sicher ob ich das
jetzt richtig verstehe aber geräte im eigenen netz kommen doch eh drauf es ist doch eigentlich
nur die frage wie per vpn drauf kommt oder also mal angenommen dann dein server ist in
netz a und äh dann können alle alle rechner da drauf auch zugreifen und selbst wenn du
ein eigenes vpn netz hast muss einfach nur gucken dass das routing stimmt und ähm die
firewall freischaltung stimmt ansonsten oder ich verstehe es nicht der server ist in gehost
und hat aktuell nur vpn freischaltet a du willst so eine bridge bauen oder wie a jetzt
habe ich es verstanden du willst quasi das das das koppeln irgendwie so als so als würde
dieser server in deinem vpn in deinem in deinem netz stehen ja dann ist das was baden i beiden
schau mal nicht schlecht in den bridge die war also tap anstatt tun ja es ist eine möglichkeit
ansonsten könntest du auch gucken da muss ich jetzt erstmal ein bisschen überlegen
ansonsten müsstest du halt gucken dass du dich verbindest dass dann halt ein router das
vpn aufbaut und dann müsstest du halt routing einträge in deinem router machen dorthin
dann ist es zwar nicht das gleiche netz aber du hast zugriff ohne vpn also du baust einen
tunnel auf von einem router zu deinem server und dann musst du in der routing tabelle von
einem router natürlich noch reinschreiben ok oder das wird wahrscheinlich automatisch
drin stehen dass er das weiter leitet dahin das müsste auch gehen also du musst kein
du musst da kein layer 2 gedönst machen layer 2 vpn war übrigens das thema meiner abschlussarbeit
na usb f und bgp bringt er da jetzt nicht wirklich was einup da müsste ich mir also
site to site vpn ist auf jeden fall das richtige stift stichwort dafür aber ich habe mich
letzterzeit so wenig was mit vpn gemacht also so aus dem erbel schütteln kann ich jetzt
auch nicht wie man es mir was am besten macht poggers weiß achso ja das das stimmt das
kannst du machen aber in dem fall wäre es eine wäre es eine route ja also ich glaube
man kann auch verkraften aber ja ja stimmt hast recht ja das ist korrekt na oder ich
meine du kannst ja auch egal ja das geht als du ein bisschen overkill
habe ich das jetzt übersehen wegen der ausbildung dass da auskommen antwort gekommen ist noch
schon mal nachgedacht solche streams auf youtube zu stellen ja schon von anfang an aber das
interessiert auf youtube bei mir kaum jemand außerdem ist das viel zu lang das müsste
ich dann zusammen schneiden das ist ein riesen akt und viel zu wenig so audience für die
leute wollen irgendwelche battlefield talk oder sonst was sehen auf youtube sieht man
ich sehe ja was gerne geguckt wird und was nicht ab und zu mal ein technikvideo mögen
die leute also wenn ich mich über irgendwelche aktuellen sicherheitslücken oder so auslasse
das kam immer ganz gut an aber ansonsten wollen die leute auf youtube eher themenbasierten
aktuellen themenbasierten oder eventuell vielleicht könnte man sogar anstrengend gaming themenbasierten
laberstellen haben und heutzutage wollen sie auf youtube reactions sehen ja das stimmt
allerdings bei mir wird ja wenig reacted könnte ja mal auf mein altes video reacten und dann
reaktieren ja später auf das video wo ich reaktet habe
es ist wunderbar jetzt bin ich müde jetzt kann man stream ausmachen gar nicht wechseln
excellent der hängt aber ganz schön hier beim beenden
kann es sein dass du sehr wenig schlaf brauchst nee warum ich penn ganz normal ich mein ich
gehe jetzt klar penn irgendwann so zwanzig minuten halbe stunde und dann stehe ich um
also aktuell so um kurz nach sieben auf wenn ich kein homeoffice hab stehe ich fünf vor
45 auf das sind also sagen wir so ich bin selbst wenn ich sag mal runden wir mal auf
sechs Uhr auf sagen wir mal runden wir mal auf sechs Uhr auf und sagen wir mal ich gehe
erst um 23 Uhr im Bett das heißt ich liege mindestens sieben stunden im Bett mindestens
und selbst wenn ich davon nur sechs stunden penne ist es nicht so als wäre ich da jetzt
maßlos unter unter versorgt ja ich komme mir schon ganz schön müde vor manchmal aber
sechs stunden wenn ich wirklich nur sechs stunden penne ansonsten wenn ich jetzt ins
Bett gehe und dann bis sieben Uhr pennen kann dann sind es ja acht acht stunden nicht
ganz sieben sieben halb acht stunden es reicht doch sieben stunden ist doch genug sieben
stunden da ist man fit vielleicht nicht jeder wie lang pennt ihr so chat wollte ich übrigens
gar nicht einblenden oder ich den hier einblenden wie viel stunden müsst ihr schlafen dass
ihr wach seid also ich glaube die meisten ist so sechs sieben stunden also wir reden
nicht von stunden die man im bett liegt sondern stunden quasi ab dann wenn man eingeschlafen
ist 10 stunden oder bis man nicht gleich wieder umkippt ja sechs sieben stunden ja ich glaube
das ist auch relativ normal mag zwar die ein oder andere geben den vier stunden ausreichen
es dürfte aber die Minderheit sein
ich finde diesen soundeffekt immer noch so geil
so leute ich gehe ins bett wir sehen uns dann morgen oder vielleicht bisschen bisschen
später mal gucken ok outro musik sonst könnt ihr wieder mal nicht in die schlafen habe ich
gehört also leute bis denn see you
