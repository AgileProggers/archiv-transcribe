So, kurz was trinken, müsst ihr mich dran erinnern, ich muss regelmäßig ertrinken
im Livestream, sonst kriege ich so einen trockenen Hals und das merkt man spätestens so nach
1-1,5 Stunden merke ich das und dann ist aber eigentlich zu spät.
Deswegen jetzt ordentlich hydraten.
Ich glaube Twitch hat noch gar nicht gecheckt, dass der Stream überhaupt online ist.
Oh doch, jetzt ist es in 7 Leuten da, ganz davon abgesehen, so viele werden wir wahrscheinlich
heute auch nicht werden, weil es ist 12.30 montags, oh das ist ein nice Seamote, wo kommt
das her?
Okay, sagt mir gar nichts, aber das finde ich gut.
Also das war ein bisschen rare people, extra rare, also nicht gegrillt, sondern selbe,
okay, ich glaube Twitch hat doch noch nicht gecheckt, dass der Stream online ist.
Snacks, wie hast du es gefunden, zufällig oder über Notification?
Weil das dauert immer unterschiedlich lang, mal dauert das 15 Sekunden, dann hat Twitch
kapiert, mal dauert es aber auch 5 Minuten und es hat auch teilweise schon mal an die
10 Minuten gedauert.
Ich sehe das immer daran, wenn erstens wenn Notifications rausgehen und wenn auf einen
Schwung irgendwie 40-50 Leute kommen, dann weiß ich immer, ah, jetzt hat es Discord,
Discord hat es jetzt auch mitgekriegt, Stripes kriegt das immer über Discord mit.
Hast du Urlaub oder ist das ein Pausestream, weder, noch, jetzt überleg mal scharf was
sonst noch sein könnte, der Chat spoilert schon wieder, ich gehe montags nicht arbeiten.
Ich kriege aber auch kein Geld für montags dann logischerweise.
Hey Max fand es echt cool, das ist ein ITler YouTuber, ja ich bin ja so halbe halbe, gibt
er in der Nähe wohnt, ja siehste, Pog wo wohnst du?
Redux ist auch am Start, jetzt hat Twitch auf jeden Fall mitgekriegt, Moin aus der Pause,
nice, Pausechamp, also quasi richtig echter Pausechamp, aus dem Gym, 12.35 montags, wer
ist denn da im Findestudio, Hanau, ja da Hanau kenne ich auch, es ist lustig, dass ich als
Benchmark für die Discord Notifications genutzt werde, ich weiß, dass du das immer über
Discord kriegst, du bist Schauswängler, ja das kannst du bestimmt unter Weiterbildung
buchen oder so, heute steppen wir mal wieder etwas unser Frontend Game ab und machen bisschen
Datenbank Kram, ich zeige euch gleich wo wir stehen geblieben sind, ist nichts großartiges,
also versteht man wahrscheinlich in zwei Minuten, haben nicht viel gemacht, wir haben bis jetzt
mal ein bisschen Postgres rumgebastelt und ein Autocomplete Feld im Browser gebaut,
ich zeig das gleich nochmal, aber ich hab eine, finde ich, müssen wir mal gucken ob
das klappt, aber ich habe da eine Idee gehabt, wie wir das noch viel viel schneller machen
können, aktuell haben wir Autocomplete Zeiten so von 70 Millisekunden oder sowas und ich
hoffe wir kriegen es damit deutlich schneller, nicht dass man das bräuchte, es ist einfach
nur dass es funktioniert, dass das geht, agiler Twitch Coder, ja genau, der Taunuskreis war
dann alter Ausbildungsbetrieb, ok ich wusste gar nicht, dass die Physis oder sowas ausbinden,
ja ich hab gern Mario Kart Playlist an, das ist nicht zu aufdringlich und nicht zu einschläfernd,
also das ist optimale Mischung, finde ich für sowas, übrigens wusstet ihr, das muss ich
jetzt mal revealen an der Stelle, ich hab vor zwei drei Tagen erfahren, dass mein Ur-Opa,
nicht mein Opa, mein Ur-Opa, kurz gucken ob die Lautstärke von der Musik passt, ja ist
ok, ich hab erfahren, dass mein Ur-Opa aus Südafrika gekommen ist und ich bin mir jetzt
nicht sicher, ich bin ja eigentlich quasi ein Achtel Südafrikaner jetzt, Zulul, genau
Zulul, verbotene Emotes hier, das muss vor dem zweiten Weltkrieg gewesen sein, das muss
vor dem zweiten Weltkrieg gewesen sein, weil mein Opa war im zweiten Weltkrieg irgendwie
so, keine Ahnung, 20 oder so, das muss also vor dem zweiten Weltkrieg gewesen sein, wo
er in Südafrika war, mein Ur-Opa, Max hast du schon von dem Politiker in Afrika gehört,
da gibt es nö, aber da gibt es einige, keine Ahnung, war relativ beliebt dahin auszuwandern
und ein paar Jahre später wieder zurück, ernsthaft, vielleicht etwas unglücklicher
Name auch für einen südafrikanischen Politiker, auf der anderen Seite wahrscheinlich hat
er sich nicht ausgesucht, das ist aber doch schon ganz schön Payne's Champ, wenn man
so heißt, was der ist Präsident von irgendeinem Land, sehr ernsthaft, ja, wo es nicht alles
gibt, wie gesagt, ich bin ja auch zu einem Achtel Afrikaner, der war wegen Corona in den
Medien, aha, wahrscheinlich wüsste sonst gar keiner, dass es den gibt, so, aber widmen
wir uns mal wieder unserem Upsteppen des Frontend Games, Max wie powerst du deine ESP so, wenn
ich jetzt sage mit Strom, wird dir das wahrscheinlich nichts helfen, du willst wahrscheinlich wissen,
ob USB oder Batterie oder sowas in der Richtung, die meisten per USB, nahezu alle per USB, ich
habe mir irgendwo mal so ein PoE Kit gekauft, da kann man das dann quasi, also da steckst
du Kabel rein, Netzwerkkabel rein, machst PoE am Router oder am Switch an und der zwackt
das ab und konvertiert dir das dann quasi in so einem Stecker in drinnen schon irgendwie
in 5 Volt oder so, habe ich nie verwendet, ähm, ansonsten USB, ich habe eigentlich nur
USB, USB für den ESP, Vollkornmilch pro Dange für den Zap, hat es wieder nicht gebimmelt
heute, das ist sehr unzuverlässig gerade Steamlabs, oder ich habe es nicht gehört, ich habe nämlich
gerade MassivePepoFat gemacht, Leute, es kann sein, dass ich ein bisschen hart gebimmelt,
aber es kann sein, dass ich ein bisschen müde bin, weil Verdauung gerade einsetzt.
Mein Stromverbrauch müsste relativ hoch sein, geht eigentlich, nee, warum, ich mein, weder
Raspberry Piles noch ESPs brauchen nur sonderlich viel, dass es großartig auffällt, ich weiß
aus dem Kopf nicht, keine Ahnung, also Gaspreise sind krass teuer geworden, wie sieht es mit
PoE am Freitag aus, nee habe ich gerade Zeit für, kein PoE, mit dem ganzen Server, ja,
das ist ein Inter-Low-Power-Server, der Eidl 8 Watt braucht, also das wird sich jetzt nicht
nennenswert auf den Stromverbrauch auswirken, klar, sag mal so, ähm, die Festplatten, wenn
die laufen, brauchen sie ein bisschen mehr, der braucht 8 Watt Eidl, Stripestesser, der
braucht nix, inklusive SSD, allerdings ohne Platten, mit den Platten braucht er dann natürlich
mehr, aber die Platten sind ja zum größten Teil im Sleep, da braucht mein 10G-Switch
mehr, also ich glaube, das Netzwerkequipment braucht eine ganze Ecke mehr, ich mein, das
ist der MikroTik-Router, der 10G-Switch, dann die 3 Access Points, die am Router über PoE
dranhängen, und dann halt, dann noch die Fritzbox und dieses Ding von Unity Media, also da kommen
wahrscheinlich, da kommen wahrscheinlich 50, 50 Watt Netzwerkgeräte zusammen, und
der Server fällt da kaum ins Gewicht, ja, in dem Gehäuse ist tatsächlich 80% Luft
drin, in dem Gehäuse ist ja noch, das Netzteil liegt ja auch mit drin noch und alles, so,
ich mach mal kurz meine VM an, und dann erzähl ich euch, genug hier Lederhosen, Winkpippe
gehabt, dann zeig ich euch mal, wo wir stehen geblieben sind, kann sein, ich glaube, ich
muss erstmal VM kurz update und neu starten, habe ich so im, irgendwie das Gefühl, dass
ich das machen muss, heute steppen wir mal wieder unser Frontend Game ab, genau, der
Desktop, ja, der ist, finde ich schon, der ist sehr strukturiert, der mag jetzt vielleicht
dem ein oder anderen nicht ordentlich erscheinen, aber der hat schon sein System, dein ganzes
System, das ist aber ordentlich, ah, hier ist ja noch unser Datenbankgedöns, vorletztes
Mal, alles klar, so, ich mach mal kurz, alles klar, eh, mal kurz, mal kurz, Update, ja,
dachte ich mir, oh, Polkit, ja, das sollte man updaten, wieder mal Zeit, so, Polkit,
Ghostman, wird auch wieder geupdatet, du hast alle Weihnachtseamots rausgeworfen, ich hab's
gesehen, richtig Massive, Pog, weil ich hätte das nie gemacht, ihr kennt mich, wenn ich
sowas mache, dann dauert das da ein halbes Jahr und dann ist eigentlich schon wieder
Weihnachten, du hast auch schon einmal, ja, das macht keiner gerne, wofür nützt du deinen
Surfer aktiv oder mehr oder weniger just for fun, Ackerman Blog, also, wenn du es genau
wissen willst, was ich laufen hab daheim, dann gehst du auf meinen YouTube Channel und
guckst dir das vor, vor vorletzte Video an, das, das Home-Surfer-Enjoyer-Video und da
zeige ich dir 26, 25 Minuten lang, was ich wie wo hab. So, ich starte mal, ich starte
mal kurz das Ding hier neu, jaja, hat er jetzt geupdatet? Okay, hoffe ich mal, ich starte
mal kurz neu. Nächstes Jahr Weihnachten, dieses Jahr Weihnachten, ja, dann wird's da wieder
eklig, weil das kann das Zebaro machen, das Zebaro ist die ganze Zeit schon immer afk
und macht komische Dinger, was, was seh ich da im Hintergrund, was ist das? Das ist das
Bing Image of the Day, also nicht, dass ihr denkt, ich wüsste, was auf meinem Desktop
Hintergrund ist, was seh ich da? Leute mit Hut, die, ich hab keine Ahnung, irgendwelche
Stimmen, Segel, nee, was ist das? Saffran, ja wirklich, ernsthaft, Lumen-Air, ist das
so? Ich hätte jetzt eher gedacht, die stecken, die stecken das da rein. Alter Chat, Chat
ist wieder richtig high IQ, Chat weiß sofort, was es ist, die ganzen Prime-Subs haben sich
gelohnt, zahlt sich aus. Lohnt sich Ryder? Ja finde ich schon. Du kannst dir, wenn du
viel von JetBrains verwendest, du kannst ein bisschen Kohle sparen, wenn du das Desktop
Package kaufst. Also wenn du mehr als eins verwendest. Und kauf dir die Privatversion,
wenn du es privat verwendest. Also hier für persönliche Nutzung, nicht hier Organisation.
Für persönliche Nutzung kriegst du das All Products Pack für 250 Euro im Jahr und ab
dem zweiten Jahr, also bis auf 60% geht das runter im dritten Jahr. Ich finde das lohnt
sich, wenn man mehr als eins von denen verwendet. Weil allein schon, ich glaube JetBrains Ryder
alleine kostet auch irgendwie 150 Euro oder sowas. Zeig mal, wo ist es denn? Entwicklertools.
Muss mal kurz gucken, ich weiß es selbst gar nicht, was es kostet. Kaufen. Ja, nee, hier,
fast. Guckt, also wenn man mehr als eins verwendet, lohnt sich eigentlich das All Products Pack
schon wieder. Ich finde es nicht schlecht und ganz ehrlich, wenn man damit professionell
oder semi professionell arbeitet, so viel sind 250 Euro bzw. wird dann immer weniger, geht
dann irgendwie runter bis auf 190 oder irgendwie was. Ist das im Jahr jetzt auch nicht, wenn
man das täglich oder öfters verwendet? Ist Ryder nicht dasselbe wie das Code? Nee. Ryder
ist eher das wie Wishl Studio. Ryder ist quasi die Konkurrenz zu Wishl Studio, nicht
zu Wishl Studio Code. Nur mit dem Unterschied, dass mir Ryder von den Funktionen und der
Handhabung mittlerweile besser gefällt als Wishl Studio. Ich habe jahrelang auch für
.NET und sowas Wishl Studio verwendet, aber seitdem ich jetzt hauptsächlich.NET, und
das ist auch schon wieder jetzt die letzten paar Jahre,.NET hauptsächlich unter Linux,
fast exklusiv unter Linux entwickle, ist halt Wishl Studio selbst keine Option mehr. Wishl
Studio Code ist für.NET nicht so fein und Ryder ist super. Das verwenden wir mittlerweile
unter Windows auch. Ja, aber noch nicht selbst aus, ich habe mir ein paar Videos zu angeguckt.
Da bin ich mal gespannt, ob sie es da schaffen, Wishl Studio Code ein bisschen Konkurrenz
zu machen. Für Java Script und Frontend zeug ich wahrscheinlich weniger, aber es gibt ja
auch viele Plugins für Wishl Studio Code, die beliebt sind. Ja, von Go bis Rust und
sonst was, vielleicht da. Für Go haben sie ja eine eigene IDE. So, ich zeige euch mal
kurz wo wir stehen geblieben sind. Ich muss mal kurz die Musik da noch einen Ticken leiser
machen. Das ist mir das zu anstrengend. So, oh, Leute. Ich muss, gestern hat schon einer
gemeint, ich höre mich anders an. Das liegt daran, weil Teams mit der an meinem Mikrofon
rumgestellt hat. Teams macht das gerne, weil Teams einfach nur zackt in der Richtung.
Ich lege komplett von Windows zu Linux. Ja, dann überleg mal. Also, kann man jetzt ja
auch hier gar nichts dazu sagen, wenn du nicht, zumindest ein bisschen erzählst, um was du
machen willst. Also, einfach so ins kalte Wasser springen würde ich auf jeden Fall nicht.
Ich würde mir erstmal, ich würde noch nicht mal das machen, ich würde es erstmal so machen
wie ich Linux in eine VM packen unter Windows und mir das ein bisschen angucken, weil du
kannst nahezu alles relativ gut in einer VM machen. Außer Videos gucken und sowas, dann
ist ganz schön hohe CPU-Last. Aber zum Ausprobieren ist eine VM das beste, was du machen kannst.
Das hast du schon gemacht, ja. Wenn es da nichts mehr gibt, was du exklusiv unter Windows
machst, ja, warum nicht? Kann man ja machen. Aber dann gleich Art-Schließungs, Art-Schließungs
by the way. Und dann die Menschheit bekehren, dass alle Art-Schließungs verwenden. So,
ich zeige euch mal kurz wo wir stehen geblieben sind. Wie habe ich denn das Projekt genannt?
SearchChamp. Also.net run. Und jetzt, wie ist das Frontend-Ding? Ah, Frontend, da hätte
ich auch selbst drauf kommen können. So, also ich zeige euch mal kurz was wir das letzte
Mal gebaut haben. Wir haben ein Autocomplete-Feld, ob ich das Studio Code vielleicht aufmache
neben dran. Ja, also wir haben ein Autocomplete-Feld gebaut, was Sachen vom Server autocompleted,
ja. Wenn ich jetzt hier z.B. eintippe A oder S, dann sollte das normalerweise autocompleten.
Was ist, oh, oh, was ist hier los? Ah, ich weiß woran es liegt. Chat, warum sagt mir
das denn keiner? Die Datenbank läuft nicht. Wie? Hä? Warum ist mein Datenbank-Image weg?
Jetzt bin ich verwirrt. Wo ist mein Datenbank-Image hin? Wo waren wir denn hier? Temp, pg, data.
Äh ja, sudo, denkst dir. Ok, die Datenbank-Daten sind noch da. Die Datenbank-Daten sind noch
da, hier, 1,6 Gigabyte, ok. Docker-Run? Ah, weil ich ja M gemacht habe. Keg-Wait. Warum
mache ich auch so ein Mist? Ja gut, aber das schöne an Containerkram ist, die Daten sind
ja noch da. Rest kann ich einfach so lassen. Bam, wieder starten. Und dann sollte das eigentlich
wieder funktionieren. Schauen wir mal, ob es jetzt autocompleted, neu laden, ha, ha,
der Harold, da ist er. Also wir haben so ein autocomplete-Ding gebaut, da kann man z.B.
dann sowas hier eingeben. So hier, Ashley, autocompleted ist oder Dom oder so oder Punkt
Name. Das sind übrigens random Daten, die er da generiert. Host, ne Host haben wir da
nicht drinne. Das sind random, hier Punkt Net oder so. So, wir haben so ein autocomplete-Ding
gebaut und das autocomplete-Ding ist halt relativ schnell, weil wir haben 1,6 Gigabyte,
Penny Punkt Name, Klassik. Penny. Oh ja, beste, beste. Ganz schön viele Leute die gleiche
Domain, oder? Penny Punkt Name. Ja, und das autocomplete ist relativ schnell, obwohl wir
haben eine Postgres-Datenbank mit 1,6 Gigabyte und ich glaube irgendwie 4,5 Millionen Einträgen
oder so. Was ist denn 3000 mal 1500? Ja, also wir haben, habe ich doch richtig im Kopf, wir
haben 4,5 Millionen Einträge in der Datenbank, die alle gleich aussehen, die alle aus einem
Vorname bestehen und einer Domain. Die Daten sind eigentlich relativ egal, das geht ja
nur, dass man da schnell autocompleten kann. So, also wir haben eine Datenbank mit 4,5 Millionen
Elementen drin und die ist insgesamt 1,6 Gigabyte groß und ihr seht, so das autocomplete ist
schon sehr schnell. Wir brauchen für einen Datenbank-Query ungefähr 7 und 3, also 28
bis 37 Millisekunden. Am langsamsten sind die Queries, wo man nur ein Buchstabe eingibt,
der dauert 284 Millisekunden, weil der dann halt relativ viel zu suchen hat. Und da habe
ich mir gedacht, das können wir jetzt noch ein bisschen optimieren. Das ist eine gute
Frage. Ok, das ist die high IQ Chatfrage. Wäre das auch noch schnell, wenn deine Anwendung
bei 100.000 User hätte oder skaliert deine Lösung Scheiße? Naja, das ist Read-Only,
das spricht schon mal dafür, dass das relativ schnell sein müsste, auch bei mehreren Usern
gleichzeitig. Postgres Read-Only ist ja kein Ding. Also ich würde sagen, das müsste auch
bei 100.000 Usern relativ schnell gehen. Ob das jetzt mega krass diagonal, horizontal
und vertikal skaliert, müsste man ausprobieren. Aber im Prinzip würde ich sagen, ja, das
wird wahrscheinlich auch mit 100.000 Usern relativ schnell gehen. Wäre für so eine Anwendung
nicht Redis perfekt? Naja, Redis wäre insofern von der Idee her nicht schlecht, weil es rein
in Memory ist. Aber das Problem an Redis ist, mach mal 4,5 Millionen Einträge rein in Memory
sind. Das braucht schon ein bisschen RAM, das ist das erste. Und das zweite ist, wahrscheinlich
ist es sogar langsamer als Postgres in dem Fall, weil Postgres explizit einen Modus hat
für Textsuche, der das ganze beschleunigt. Soll ich euch mal versuchen, so weit wie ich
es verstanden habe, zu grob zu erklären, wie das Postgres macht. Das ist eigentlich
relativ sechsköpfig. Und zwar, wenn man Postgres sagt, dass man jetzt Text in die Datenbank
speichert, zum Beispiel das Wort Hallo möchte man in die Datenbank speichern. Allerdings
so, dass man es schnell wieder finden kann, schnell wieder durchsuchen kann. Dann speichert
Redis, dann speichert Postgres das normalerweise halt einfach als Feldtext. Einfach Hallo
drin und gut ist. Dann kannst du aber nicht schnell suchen, weil dann musst du ja vom
ersten Eintrag der Datenbank bis zum letzten Eintrag der Datenbank suchen. Und was Postgres
macht, ist jetzt folgendes, damit Postgres das macht, muss man folgendes setzen, man
muss diese zwei Sachen in Postgres einschalten. Also man muss diese Postgres Erweiterung laden,
und man muss sagen, dass er ein Textsuche, wie auch immer, Index anlegen soll da drauf.
So, und was Postgres jetzt macht, ist, um das schnell durchsuchbar zu machen, der macht
aus diesem Wort 3er Buchstabenpaare. Das heißt, Postgres macht daraus dann irgendwie
sowas, macht irgendwie h, und dann h a, a h, glaube ich, und dann h l, a, und so, so.
Diese Varianten werden da irgendwie rausgebastelt. Das kann man sich, Moment, das kann man sich
sogar anzeigen lassen. Ich warte mal, ich lasse mir das mal anzeigen. Da gibt es nämlich
eine fertige Funktion, die das macht. Wartet mal, das machen wir jetzt. EF, Functions, Show,
hier, so. Also das, was Postgres speichert, hör hallo. Natürlich speichern wir den Text
nur in klein, weil wir ja case insensitiv suchen wollen. Was kommt da übrigens zurück
jetzt? Ein String Array, ok. Schleife, gucken wir uns das mal an, was Postgres daraus macht.
Ja, lul, cw, lul, return, zack. So, gehen wir uns das mal aus. Also aus hallo, macht
Postgres. Was? Ach, das muss man in einem Query machen, das kann man nicht einfach so
machen, oder wie? Wie soll ich denn daraus einen Query bauen? Hä? Ok, wir gucken uns
jetzt einfach ein Beispiel an. Example. Gibt es ja schon genug Leute, die das machen. Kennst
du mich mit QuestDB aus? Nein. Hier, also. Das macht immer so dreier Buchstabenpaare
daraus. Und dann speichert es das in irgendeinem sortierten Index oder so ab. Zumindest hat
das den Vorteil, dass man dementsprechend relativ schnell Wildcards suchen machen kann.
So nach dem Motto enthält ein Wort den Buchstabe a oder enthält ein Wort die Zeichenfolge
ca oder sowas. Das geht dann relativ schnell, weil er die Wörter ja schon so aufgesplittet
speichert und sich in seinem Index per Binary Search relativ schnell da lang hangeln kann.
So reime ich mir das zumindest zusammen. Nachteil ist, Rides dauern länger und die Datenbank
wird viel größer. Das ist ja oftmals so. Das ist immer so ein bisschen Tradeoff zwischen
Größe und Aufwand, dass man es dann schneller wieder rauskriegt. Select Word. Ok, das probieren
wir jetzt mal aus, ob das funktioniert. Also ich soll da einen Query daraus machen. Ok.
Raw SQL. Database. Raw SQL. Execute Raw SQL. Ok, also. Mal schauen. Hab ich noch nie gemacht.
Mal gucken, ob wir das Postgres irgendwie entlockt kriegen. Was ist denn das? Show.
Hier. Ok. Select. Alles klar. So. Wir wollen nicht Word-Similarity, sondern Show drücken.
Für Hallo. Für Hallo. So. Gucken, ob das funktioniert. Das knallt jetzt wahrscheinlich
gleich wieder. Und was kommt da als Ergebnis raus? Ein String oder was? Oder wie Execute
Raw SQL. Ne. Ey, keine Ahnung, wie das funktioniert. Ja, Update, Update. Weiß nicht, wie ich das
dem beibringen kann. Ja, super, aber da kriege ich doch jetzt keine Ausgabe von. Ja, nice,
nice. Das Query funktioniert, aber ohne dass die Ausgabe. Ok. Execute Raw SQL. Output.
EF Core Output. Also mal gucken, wie das haut. Oh, jetzt wird es High IQ. Moment. Was?
Da kommt ein Int zurück. Warum kommt da eigentlich ein Int zurück? Warum kommt da ein Int zurück?
Warum kommt da nicht irgendein Text Output zurück? Aber wir können das ja einfach mal
mit pet-docker machen und uns connecten in die Datenbank. Hier, Docker, PS, noch mal
Bash. Bin, Bash. So, Docker, Exec, Postgres. Ne, Container-ID Bin-Bash. Ne, das war. Ach,
wie ging das noch mal? Minus. Number of Affected Roles kommt zurück. Ja, super. Ich will aber
den Text, den Text. Wie ging das? IT, IT war das. Genau. Ja. So, PSQL. Failed. Wie
jetzt? Ich darf mich nicht auf meine eigene Datenbank verbinden oder was? Minus U. Postgres.
Ne, was ist, was ist User? Wir machen wieder Zeug, was ich überhaupt nicht machen wollte,
aber ok. User. U. Da sind wir. Postgres. So. Kommandosignal. Select. Sternchen. From.
Was? Ah, wir müssen uns erst mal zur Datenbank verbinden. Sekunde, erst mal wieder öffnen.
Was ist das Minus? Wie gibt man die Datenbank an, wohin man sich verbinden will? DB Name,
Minus D. So, und unsere Datenbank heißt wie? Unsere Datenbank heißt QChat Database. So,
ok. Jetzt aber. Select. Jetzt funktioniert's. Nice. Also, das sind diese, das sind diese
Triple Buchstabenpaare, die Postgres für das Wort Hallo speichert in der Datenbank.
Also HA, HA, AL und dann HAL und dann LO und so. So, und wenn er das jetzt abspeichert,
dann kannst du relativ easy feststellen, ob ein Wort eben beispielsweise einen Buchstaben
enthält. Der kann dann einfach in seinem, wenn du wissen willst, enthält ein Wort A,
dann guckt er in seinem Index nach und stellt fest, ah ja klar, A fängt mit A an. Das heißt,
er kann dann wahrscheinlich per Binary Search oder wie auch immer, die die das genau machen,
ziemlich schnell finden, auch wenn du das, was du suchst, mitten im Wort ist. Und du
kannst trotzdem auch Wort teilen, also wenn du wissen willst, enthält das, enthält das
irgendwie LO oder LL oder so. Dann kann er hier auch nachgucken. Dementsprechend sind
die Queries auch so schnell, weil er für jeden Texteintrag so ein Ding hier erstellt. Also,
du hast zwar nur einen Text, aber in der Datenbank speichert er ganz viele verschiedene Abwandlungen
bzw. Teile davon. Und deswegen dauert ein Insert länger und deswegen ist die Datenbank
auch größer, weil er nicht einfach nur Text in irgendeinem Datenbankfeld drin speichert, sondern da
noch ein paar Sachen für machen muss und auch mehr Sachen speichern muss. Aber deswegen sind
die Queries, wenn du wissen willst, enthält das ein A, enthält das ein H, enthält das HL oder so,
viel schneller. So, so weit zur Theorie. Ich habe mir jetzt folgendes überlegt, was man machen
könnte ist. Also aktuell sehen wir ja, die Queries dauern irgendwie, ich höre das mal wieder aus,
das ist Donkey Kong Musik, oder? So, die Queries dauern hier so ungefähr, wenn man hier mal nach
Name sucht. Hier 100, 100, Name gibt es halt oft, 191 Millisekunden. Wenn man sich mal überlegt,
das ist relativ gut eigentlich schon für eine Datenbank mit 4,5 Millionen Texteinträgen und die
1,6 Gigabyte groß ist. Aber ich glaube, wir können das noch viel, viel, viel schneller machen,
wenn ich die Datenbankabfrage sinnvoll mache, weil meine Datenbankabfrage ist ziemlich dumm. Ich bin
nach dem letzten Stream aufgefallen, weil ich zeige jetzt, ich zeige mal hier, wie das hier
im Frontend funktioniert. Wenn man hier in diesem Suchfeld was eingibt, dann ruft er,
es ist natürlich groß hier, guck, das ist mit HTML und CSS und JavaScript zusammen mit 127 Zeilen,
der ruft diese Funktion auf bei jedem Tastendruck quasi in diesem Inputfeld hier, Query Server,
und, muss ich mal kurz überlegen, hier ist das Value vom Inputfeld, genau. So, und er ruft diesen
Endpunkt auf in unserem Backend, ja, slash api slash search und dann übergibt er das Value,
was hier oben im Inputfeld drinne steht. Und das hier ist die Funktion, die auf dem Server
aufgerufen wird, api slash search query. Das ist übrigens auch richtig dumm gemacht. Ich
müsste jetzt eigentlich irgendwie so, ich weiß gerade gar nicht, wie da die richtige Syntax für
ist. So, und was würde es länger dauern, wenn die DB-Einträge vom Wort an sich länger wären und
spielte das? Naja, das ist ja das Schöne daran. Es dauert länger beim Einfügen und es wird größer,
umso länger das Ganze ist. Aber die Suche, die wird wahrscheinlich auch minimal langsamer,
aber im Prinzip bleibt die Suchzeit relativ konstant. Das ist ja gerade das Gute daran.
Weil normalerweise, wenn du linear die Datenbank durchsuchen würdest, dann wird es halt mit der
Länge immer länger. Majorink, danke für den Sub. So, und jetzt gucken wir uns bei meinen
Datenbankquery an. Das ist nämlich ziemlich dumm, ist mir im Nachhinein eingefallen. Also,
was wir abfragen ist folgendes Text-Values ist die Tabelle. Nee, nicht die, doch. Nee,
nicht Tabelle. Wie nennt man das? Doch Tabelle, ne? Text-Values. Text-Values ist die Tabelle. In
dem Fall bei ASP.io heißt es DB-Set. So, Text-Values sieht in.NET sieht dann so aus. Das ist eigentlich
nur eine Klasse mit einer ID und dem Text zum Durchsuchen. Hält sich wirklich in Grenzen. Da
ist wenig, wenig, was wir extra gemacht haben, um uns aufs Eigentliche zu konzentrieren. So,
und die Datenbankabfrage ist ziemlich doof. Also, in dieser Tabelle mit Text-Values, also das,
quasi das einzige, was in der Datenbank steht, machen wir ein Wear. Sagen, okay, wir suchen alle
Einträge, die, und das ist Postgres, das ist Postgres-Magic. Was macht das DB-Set? Du musst
in Entity Framework Core, wenn du das verwenden willst, und damit du Queries gegen eine Datenbank
machen kannst, muss das in einem DB-Set sein. Das ist halt so von den Framework-Erstellern gedacht.
DB-Set stellt dir dann Methoden zur Verfügung, worauf du Datenbank-Queries machen kannst. Also,
Wear, Order, Buy und so was in der Richtung. Das geht nur, weil es ein DB-Set ist. Also,
wir gucken Einträge, die, und das hier, wie gesagt, ist Postgres-Magic, die unser Query enthalten. Also,
in dem Fall wäre das jetzt Name. Und davor und danach ist ein Prozent. Prozent ist in Postgres
Wildcard. Also, sprich, das Query kann irgendwo stehen. Also, Name kann irgendwo hier drinstehen,
ist vollkommen egal. Also, wenn ich nach Geo suche, zum Beispiel, funktioniert das halt richtig,
weil ich sortiere, aber der würde auch Sachen hier drinnen finden. Aber ich ordne das hier
eben, wenn es ihn anfängt. Wir können auch HTTP suchen, zum Beispiel. Also, seht ihr,
also er findet die Sachen, egal wo sie stehen. Was ist dieses Get und Set? Da? Das? Das ist ein,
wie heißt das in C-Sharp? Automatic Property oder sowas? Weiß gar nicht, wie man das offiziell
nennt. Also, das ist Getter und Setter, wie es das in Java auch gibt. Auto-Property, Auto-Property,
genau. Das ist Get Set, wie es das in so fast jeder objektorientierten Sprache gibt. Nur
mit dem Unterschied, dass der im Hintergrund das eigentliche, die eigentliche Variable anlegt. Die
musst du nicht mal selbst machen. Also, das hier ist die Kurzvariante von, weiß gar nicht, ob man
das hier, genau. Das ist die Kurzvariante von dem hier. Du hast ein privates, eine private Variable
Text und dann hast du Getter und Setter für diesen Text. Früher hat man das übrigens nicht so
geschrieben. Es geht noch länger. Früher hat man das übrigens so geschrieben. Ups. Früher
hat man das so geschrieben. Da musst du halt so viel Gedöns schreiben, obwohl du eigentlich
auch einfach nur das schreiben könntest. Was ist da von der Unterschied zu einfach String Text?
Von der Funktion her ist das das gleiche. Du könntest auch sowas hier machen. Unterschied
zeige ich dir gleich. Du könntest auch sowas hier machen. Keine Ahnung, sowas. Public Variable
könntest du auch machen. Der Unterschied ist, in dem Beispiel eigentlich keiner, der Unterschied
ist, dass du in dem Fall noch zusätzlich was machen könntest, wenn du willst. Also,
du könntest zum Beispiel anstatt, du könntest das Set zum Beispiel weglassen, dann wäre das
Read Only und du könntest hier drinnen zum Beispiel gar keine Variable machen, sondern einfach Return,
was Statisches oder so zurückgeben. Also, du kannst hier drinnen dann quasi zur Get und Set
Zeit noch beliebigen, beliebigen Code laufen lassen. Du könntest hier an der Stelle auch machen,
hier get google.de HTTP Request und dann die Antwort Return oder sowas. In der Regel sagt
man halt, dass Public Variablen nicht best practice sind und dass man die Variablen privat
machen sollte in die Klasse und wenn man darauf zugreift, das Ganze entweder über irgendeine
Funktion macht, die dann oftmals Get und Set heißt und deswegen haben die sich bei Microsoft
überlegt, dass es ein sinnvolles Feature ist, das direkt in die Sprache einzubauen. In Java
würdest du, ich weiß übrigens nicht, ob sowas, ich sagte das nur vor ein paar Jahren, ich mache
wenig, so gut wie gar kein Java. Also, in Java würdest du dann sowas hier machen, zum Beispiel
String Get Text und da würdest du dann sagen Return Private Text oder so. Ja, du könntest in einem
Set auch checken, ob es Null ist und sowas. Ja, kannst du alles machen. Ja, dann ist es sehr
ähnlich in Java. Zumindest sind Public Variablen in der Regel nicht gerne gesehen. Der einzige
Unterschied ist, also wo ich das tatsächlich okay und sinnig finde, wenn man lokale Variablen
Public macht, ist das in irgendwelchen Interop Szenarien. Also, wenn du jetzt irgendeinen Struct
hast oder irgendeine Klasse, die du an irgendwelche unsafe FFmpeg Bindings übergibst, um dann da
irgendwie Video Frames reinzuschreiben oder sowas in der Richtung, da kannst du dem Zeug
nicht mit C-Sharp, Getter und Setter kommen. Da musst du Oldschool, Public, Int, Bloop machen.
Aber solange man sich im ganz normalen Managed-Land bewegt, würde ich das immer so machen. Hat
bestimmt noch mehr Vorteile, die ich gerade nicht draufkomme. Ja, okay, aber wenn wir uns
das Datenbank-Query angucken, ich muss was drehen. Chat sagt mir, dass ich trinken muss.
Bisschen kompliziert. Die.net-Schreibweise finde ich nicht so ganz gut. Kannste ja eigentlich
merken, sobald es Public ist, schreibst du es so. Fertig. Also, das Query, und ich zeige,
ich verrate euch jetzt auch klein, warum ich denke, dass das langsam ist. Ob das so ist,
müssen wir ausprobieren. Also, Datenbank-Query. Text-Values-Saw. Wo das Postgres Magic Wildcard,
also das habe ich ja gerade schon erklärt. Er nimmt das Query, in dem Fall hier Name
oder HTTP ist es jetzt, sagt, ich suche Wörter, die davor egal, danach egal, aber irgendwo
dazwischen, zwischen egal, HTTP enthalten. Also, das ist quasi Wildcard-Character in
Postgres. HTTP, was davor kommt, ist egal, was danach kommt, ist egal. So, das an sich
ist relativ schnell. Dadurch, dass wir das eben hier mit dieser, ich habe es jetzt nicht
mehr angezeigt, mit dieser Treecrime-Funktion von Postgres machen. Was ich allerdings ziemlich
bescheuer das mache, ist das hier. Danach sage ich, order by descending, und zwar in
der Richtung, wenn der Text mit dem Query anfängt. Also, ihr seht es ja zum Beispiel,
wenn ich jetzt nach hier Hazen, nach Huts suche zum Beispiel, dann sind die Einträge,
die damit anfangen, oben. Und damit das der Fall ist, das ist was, was ich haben will,
damit das der Fall ist, sage ich, order by. Und in dem Fall sage ich mir, okay, sortiere
mir das, danach die Einträge nach oben, wo der Text eben dieses Query am Anfang stehen
hat. Das ist schon ziemlich doof, weil auf der einen Seite suche ich Wildcard und danach
sortiere ich die, da habe ich das letzte Mal auch nicht drüber nachgedacht, und danach
sortiere ich die nach Dingern, die quasi damit anfangen, da könnte ich das Wear schon komplett
anders schreiben. Und, wenn ich zum Beispiel hier jetzt mal nur nach H suche, und ich keine
Ahnung, jetzt 2 Millionen, 2 Millionen Einträge in der Datenbank finde, dann sortiert der
mir hier 2 Millionen Einträge absteigend und von diesen Dingern, die er sortiert hat,
nimmt er dann am Ende nur 10. Also das ist jetzt nicht unbedingt gerade das alleroptimalste,
was man so machen kann. Und danach gibt er nur den Text zurück, anstatt, aber unten
ist erstmal wurscht. Also das hier ist das, was es langsam macht. Und wir können jetzt
mal überprüfen, ob das wirklich das ist, was es langsam macht, weil ich nehme das einfach
mal raus. Und dann gucken wir mal, ob das schneller ist. Also aktuell sind Queries mit einzelnen
Buchstaben so 315, 400, irgendwas Millisekunden lang. Und jetzt machen wir mal die Queries
ohne dieses Sortieren. Das ist nicht das, was ich haben will als Ergebnis, aber nur mal,
dass man die Hausnummer sieht. So, guck mal, und jetzt sind einzelne Queries für ein Buchstabe
sind schon nur noch 3 Millisekunden lang. Also das Order By macht es einfach um den Faktor,
keine Ahnung, 100, 200, langsamer. Das ist jetzt allerdings nicht das, was ich haben will.
Weil, wenn ich hier nach Huts suche, es ist nicht die Einträge, die mit Huts anfangen
oben. Und das ist ja das, was ich eigentlich will. Deswegen habe ich mir überlegt, wir
könnten das folgendermaßen machen. Und da bin ich mir nicht sicher, ob das gescheit
funktioniert. Also das Order By ist ja auf jeden Fall eine ziemlich dumme Idee gewesen,
wie ihr jetzt seht. Aber es ist vielleicht noch mal, damit man da mitkommt. Ich weiß
nicht, Chat, hat man das verstanden, warum das langsam ist? Ja, mit Index ist auch so
ein Ding. Das könnte man bestimmt sogar, das Order könnte man wahrscheinlich auch
noch beschleunigen. Ja, aber es ist langsam, weil er hier 2 Millionen Einträge findet,
die erst einmal alle sortiert und danach nur 10 Stück davon nimmt. Ja. Ich könnte mir
vorstellen, dass der Index hier drauf vielleicht sogar das schneller macht. Aber wir können
das, glaube ich, deutlich besser machen. Zwar, warum hast du auch mal vor, ein kleines Spiel
zu programmieren? Nee, Spieleprogrammierung, obwohl ich quasi täglich MMO, Kreiselgrinden,
alles mögliche mache, ich spiele ja viel. Aber Spieleprogrammierung ist tatsächlich
etwas, was mich gar nicht so sehr interessiert. Ist nicht meins. Top hat jeder so seins, aber
Spieleprogrammierung ist auf jeden Fall nicht meins. So, aber jetzt mal zu dieser Datenbankgeschichte.
Guck mal. Eigentlich, das ist mir nach dem letzten Stream eingefallen, als ich mir das
noch mal angeguckt habe. Das ist richtig bescheuert. Guck mal. Wir suchen uns alle Einträge raus
wo irgendwo drinnen, in dem Fall jetzt HTTP vorkommt, nur um sie danach alle zu sortieren,
danach ob der Antrag, ob das damit anfängt. Also eigentlich könnten wir uns das doch komplett
sparen und zwei Queries machen. Nämlich ein Query, was einfach nur checkt, fängt das
damit an und findet da 10 Elemente. Und wenn er weniger als 10 Elemente findet, dann macht
er noch ein zweites Query, nur, dass er dann ein Wildcard Query macht. Kannst du nicht
auch einfach, nachdem du 10 genommen hast, sortieren? Nee, weil dann sortiert er ja nur
die 10 und da sind nicht zwangsläufig die, die damit anfangen oben. Das funktioniert
nicht. So, wenn ich das hier jetzt ausführe, dann sollte zumindest ein Teil davon schonmal
stimmen. Hoffe ich mal. Wenn ich jetzt nämlich nach Hats suche, dann ist Hats am Anfang und
es ist immerhin noch relativ geschwind. Warum brauchen das nur sieben und Hats und Hats
brauchen 29? Zumindest man sieht, die eigentlichen Queries jetzt für ein Buchstaben und so sind
saumäßig schnell und es sind die, die damit anfangen oben. Natürlich kann es jetzt sein,
dass wenn man zum Beispiel nach so was wie HTTP sucht, er findet nix. Warum findet er
mit HTTP nix? Weil HTTP in der Mitte ist und HTTP eben nicht vorne steht. Deswegen klappt
das nicht. So, und ich hab mir gedacht, man könnte doch, man könnte doch, da müssen wir
ein bisschen basteln. Das ist alles, was ich mir im Vorfeld überlegt hab. Man könnte
doch jetzt einfach gucken, findet er 10 Einträge hiermit? Wenn es weniger als 10 sind, dann
macht er nochmal das gleiche, nur mit einem Wildcardquery. So, und das mit sortieren schenken
wir uns einfach. Das brauch ich ja dann nicht. Ich muss ja nicht sortieren, weil ich ja schon
automatisch hiermit alle, die damit anfangen, oben hab. Ich suche ja nur die Dinge, die damit
anfangen. Ich muss ja nicht Wildcard suchen, um dann danach zu sortieren, sondern ich kann
einfach direkt suchen, nach fängt an. Hast du da nicht in der zweiten Query die Ergebnisse
der ersten nochmal drinne? Es kann sein. Das kann zumindest passieren, dann müssen wir
das irgendwie uniken oder so. Mal gucken. Also, das sieht ja in soweit schon mal ganz
sinnvoll aus. Wir machen nochmal, wir führen nochmal was zum Testen ein. Nennen wir mal
hier Max Results und das sind aktuell 10. Aber, dass ich da mal ein bisschen hoch und
runter schalten kann an Ausgaben und gucken, ob das passt. Doppelte muss ich wahrscheinlich
filtern. Genau. So, das hier lassen wir erstmal weg. Das muss ich mir unten merken. So, also
das ist das erste Query. Okay, und jetzt gucken wir, ob Result Count, oder macht das so Sinn?
Wenn das kleiner Max Results ist, und wenn das kleiner ist, dann weiß ich, das hier hat
keine 10 Ergebnisse, oder in dem Fall 10 Ergebnisse gebracht. Wenn das keine 10 Ergebnisse
gebracht hat, dann muss ich nochmal, dann muss ich nochmal einen Query machen. So. Was sagst
du eigentlich zu, zu was? Zu CutefishOS. Was für ein Ding. Hab ich doch nie gehört. Oh,
China-Chinesen-Kram. Cutefish. Warum nicht CutechatOS? CutefishOS. Oh, das lädt ja schon
mal sehr geschwind. Highspeed aus China. Wird bestimmt über irgendeine ESP32 Steckdose
ausgeliefert oder so. Ach, so sieht China-Milch aus. Make a better DesktopOS. Simplicity, Beauty
and Practicality. User Experience. CutefishOS. Noch mehr Standard-Applikationen nachgebaut.
Eine Güte, ey. Muss das denn sein? Cutefish Desktop. Global Menu. Habe ich noch nie ausprobiert,
aber ich bin auch immer skeptisch über China-Destributionen. Ernsthaft. Den Download gibt es über Mega oder
Google Drive. Das ist ja sehr sicher und sehr vertrauenswürdig. Auch GitHub haben sie auch
am Start. Mega Upload. Ja, den brauchen wir auch mal wieder. Den brauchen wir auch mal.
Sekunde, Leute. Das muss jetzt mal kurz sein. Mega Upload Song. Kim wird uns schon nicht
Copyright striken. Ich glaube, das ist der letzte, der das macht. Yeah.
Mega Upload. Der Kerl hat garantiert keine Ahnung, woran er da drinnen gelandet ist,
warum er das überhaupt sagen sollte. Die haben so keinen Plan gehabt, von was die eigentlich
reden. So, genug jetzt. Genug Mega Upload Song. Das muss jetzt einmal wieder sein. Wie
viel Geld hat er ihnen in die Hand gedrückt? Ich glaube eher, wahrscheinlich war es nicht
umsonst, aber ich glaube eher, dass das so diese typische Geschichte war, wie hier auf
Twitch auch manchmal Leute in Chat kommen und so nach dem Motto, kannst du mal kurz
Max grüßen oder sowas. Die waren, die sind dann dann irgendwelche Agents von denen ran
und haben gesagt, ja hier, wir sind ein Radiosender oder was auch immer, könnt ihr mal kurz irgendwie
das und das sagen? Und dann haben wir das, da werden die wahrscheinlich nicht nein sagen,
ich habe keine Ahnung gehabt, worum es ging. Der hat ihnen bestimmt nicht gesagt, ja ich
habe hier einen Hostingservice, wo die Leute quasi eure Musik hochladen können und ihr
verdient da nichts dran und das ist nice. Bewerbt das mal. Das hat er ihnen bestimmt
nicht gesagt. War ganz davon abgesehen. Ich habe damit keine Schmerzen. Man sieht es aktuell
an der ganzen Thematik aus Abos, die man holen soll, von Amazon bis Netflix bis Disney plus
bis sonst was in der Richtung und jetzt wundern sie sich alle, oh nein, Sicherheitskopieren
verbreiten sich wieder mehr als vorher. Nein, wirklich, da hätte ja keiner drauf kommen
können, dass die Leute lieber wieder den Scheiß illegal runterladen, als sich 3000
Abos zu kaufen. Das haben wir ja noch nie gehabt und da wären wir nie im Vorfeld drauf
gekommen, dass das so wird. Ja und da wundern sie sich jetzt. Das ist so, wie die Musikindustrie
sich gewundert hat zu Zeiten von Napster, dass die Leute keinen Bock mehr haben, Audio-CDs
zu kaufen und dann auch noch in Werbespots als Mama-wo-ist-Papa im Knastweiler Raub kopiert
hat dargestellt zu werden. Und siehe da, es funktioniert. Kaum gibt es da gescheite Abos
in der Richtung, schon ist das deutlich weniger geworden und was Filme und sowas angeht,
da bewegen sie sich aktuell davon weg. Das heißt, mich wundert das nicht, dass das zunimmt.
Ob das jetzt, ja mal sagen, ob das jetzt ethisch verdrehtbar ist oder wie auch immer, sich
die Sachen da illegal runterzuladen, das kann jeder für sich selbst überlegen, das ist
mir vollkommen egal, das könnt ihr machen oder sein lassen, wie ihr lustig seid. Aber
die Tatsache, dass es so sein wird, hätte auch die Filmindustrie meilenweit im Voraus
sehen können. Das ist wirklich jetzt nichts Überraschendes gewesen. So ist es ja im Endeffekt
und seit man zu Zeiten, wo man keine Ahnung mit einem Netflix-Abo oder mit einem Amazon-Abo
sich das meiste, was man gucken wollte, angucken konnte, am besten auch noch in Originalsprache
und sowas, was ja eben viele wollen. Alles okay? Aber jetzt muss sie wieder anfangen
mit, nein, wir nehmen unsere Filme raus und du brauchst lieber 500 Abos. Das wundert
mich nicht, dass die Leute wieder mehr anfangen, auf Sicherheitskopien zu setzen. Das ist gut
oder schlecht, das hat damit überhaupt nichts zu tun. Es ist offensichtlich, dass es so
passieren wird und es ist auch so passiert. Bist du nicht Max FPS? Doch, nein, das stimmt,
das gibt's gar nicht, ich bin Wubblers. Was Linus meinte, das war bestimmt G-Baded, bei
ihm kann ich mir das nicht vorstellen, dass er wirklich mit, wobei, keine Ahnung. Mich
juckt das nicht, wenn einer meinen Twitch-Stream mit Ad-Blog guckt oder meine YouTube-Videos
mit Ad-Blog guckt es mir vollkommen egal. Können ruhig alle machen.
Ja, meine ich ja, das war klar, dass das so sein wird. Naja, egal, aber das war finde
ich offensichtlich, dass das so kommen wird. Ja und Cutefish OS werde ich mir nicht geben,
weil ganz ehrlich, ein China-Chinesen-OS, das nur über Mega und Google Drive vertrieben
wird, ist mir irgendwie ein wenig Suspekt oder Sus, wie man heutzutage sagt. Okay,
machen wir mal weiter. Also Datenbank-Krempel. Also die Queries sind jetzt auf jeden Fall
schon mal deutlich schneller. Guckt hier, Bäm, sieben Millisekunden. Suchen wir mal nach,
was? Ah, Delia, 29 Millisekunden. Also die Queries sind fast as fuck, könnte man sagen.
Ja, wir finden nur Sachen, die am Anfang stehen, nicht Sachen, die in der Mitte stehen.
Geben wir mal die Request-Time auf der Web aus. Ja, das könnte ich machen, da müsste
ich mir aber irgendwie einen besseren Return-Wert überlegen, anstatt einfach nur den Text.
Ach so, jetzt weiß ich auch, warum das so langsam ist. Nee, Stack. Wait a minute. Warum
funktioniert denn das überhaupt? Warum funktioniert das? Das sollte eigentlich gar nicht funktionieren.
Äh. Hä? Moment. Mal kurz, mal kurz die Response angucken hier. So. Response? Hab ich nicht
neu gestartet? Ich glaube, ich hab's nicht neu gestartet, ne? Ah, ja, ja, okay. Ja,
ich hab's nicht neu gestartet, weil ich filter gar nicht den Text raus, ich geb aktuell
die kompletten Objekte zurück. Deswegen hab ich mich gewundert, wie er so schlau ist und
checkt, dass es den Text davon nehmen soll. Ist er aber nicht. Okay, okay, gut, gut, gut.
Jetzt ergibt das Sinn. Ich will aber gar nicht die kompletten Objekte zurückgeben.
Ich hab mich nur gefragt, warum ist das aktuell so? Das waren wir hier unten rein. Select,
Text. So, wunderbar. So, wenn ich jetzt neu starte, dann funktioniert's nämlich auch wieder.
So. A. Das erste Query ist immer ein bisschen langsam. H. Sechzehn Millisekunden. A. Achtfünfzig
Millisekunden. L. Vierundvierzig Millisekunden. Das ist relativ schnell. Okay. Ähm. Wichtig
ist, dass so diese einzelnen Buchstaben, die haben ja vorteilweise vierundfünfzig Millisekunden
gedauert. So, und jetzt hab ich mir überlegt, wir gucken jetzt einfach, ob es weniger als
zehn Sachen gefunden werden. Und wenn weniger als zehn Sachen gefunden werden, dann machen
wir das Query einfach nochmal neu. Allerdings jetzt mit dem Wildcard Operator drin. Also
kopieren wir das jetzt nochmal. Kann man das, kann man das überhaupt, kann ich das jetzt
nochmal so machen? Und sollte ich hier count machen oder sollte ich das hier schon? Mal
gucken, mal gucken. Mir müssen wir ein bisschen ausprobieren. So. Das heißt, wenn ich jetzt
weniger als zehn hab, dann will ich Wildcard suchen. So. Setz doch die Abfrage komplett
in die If-Abfrage rein, lass die obere weg, oder dann funktioniert's doch nicht. Was soll
denn das bringen? Wenn ich die obere weglasse. Wenn ich nur die mach, dann hab ich die Dinger
nicht sortiert in der Reihenfolge, wie ich sie haben will. Wenn ich es so mach, dann
hab ich sie in der Reihenfolge sortiert, wie ich es haben will. Du solltest Result auf
jeden Fall den oberen Toolist machen. Schreib ich mir mal auf. Kann aber sein, dass es nicht
funktioniert. Muss man mal gucken. Also. Moment, Moment. Ich muss mal kurz überlegen. Also.
Wenn das weniger als zehn hat, wenn das hier weniger als zehn hat, dann machen wir nochmal
eine Abfrage mit dem da, jetzt allerdings Wildcard-Abfrage. Take zehn. Ha. Jetzt muss
ich die, irgendjemand im Chat hat vorhin geschrieben, jetzt hab ich Ergebnisse doppelt. Das kann
passieren. Ich müsste die jetzt irgendwie UNIQ machen, so. Irgendwie, wie mach ich denn
UNIQ gescheit? Wie stelle ich jetzt sicher, dass Ergebnisse nur einmal drin sind? Set?
Wie Set? Du meinst so eine Art Dictionary? Nee, das muss schon, nein, das muss schon
in SQL sein. Distinkt. Nee, ich will ja nicht Distinkt, ich will ja, ich will ja, ok, wenn
wir das jetzt Mengenlehre technisch machen, will ich ja eine, wie heißen das beide Mengen
zusammen? Ähm. Nee, warte mal, wie heißt das? Schnittmenge? Nee, Schnittmenge will
ich nicht, das sind beide, die sich überschneiden. Ich will beide Mengen zusammen, aber die Elemente,
die doppelt sind, will ich nur einmal haben. Ja, so combine sowas in der Richtung, jaja,
genau. Ähm. Wie nennt man das denn? Ok, wir müssen jetzt, ok, Wikipedia, Mengenlehre.
Was denn? Mengenlehre. Union, ja, Kompliment Mengenlehre. Ah, yes, excellent. Ja, das ist
genau das, genau das will ich haben, ja, ja, ja. Obvious, obvious. Gachibas Mengenlehre.
Union, ok, Union Mengenlehre. Kompliment. Gibt es da nicht ein paar gescheite, aha, ok,
eine echte Teilmenge, Schnittmenge, Vereinigung, ich will eine Vereinigungsmenge haben. So sieht
es aus, das will ich haben. Eine Vereinigungsmenge haben. Excellent, alles klar, Union sagt der
Chat. Das heißt, in dem Fall, ist das sowas? Oh, guck mal da, Union von Result, von dem
ursprünglichen. Und das könnten jetzt ja mehr sein als 10, also ich nehme hier von maximal
10, davon maximal 10, das könnten also im schlimmsten Fall 20 sein, also muss ich am
Ende nochmal ein Take-Things machen, oder? Ob das so funktioniert? Keine Ahnung. Der Chat
sagt schon, das geht nicht. Ja, warum eigentlich? Wir probieren das jetzt mal aus. Erst Union,
dann Take. Ne, ne, wenn ich erst Union mache, dann ist es ja wieder lahm as fuck, weil dann
mache ich ja die Union im Zweifelsfall wieder auf 2,5 Millionen gefundenen Elemente. Ok,
so guck mal, wie schnell wir jetzt sind. Also, HTTP. Aushalt funktioniert. HTTP. Ihh, das
ist ja slow. Slow AF. 935. Ihh. Warum ist das so langsam? Wäh? Warum ist das jetzt so
langsam? Aber der macht ja Union mit nichts. Ok, Moment, ich lasse das mit Union mal kurz
raus. Testen. Ok. Das ist ja immer... Warum ist das so mega langsam?
Hä? 946? Alter, das ist ja... Hab ich jetzt irgendwas da nicht richtig durchdacht? Moment,
das muss ich noch mal wegmachen. Das ist ja im Prinzip das gleiche, wie wenn ich das hier
dahin mache. Warum? Warum ist das jetzt so langsam? Schneller als mit Union. Ja, aber
eine Sekunde Query Time. Ich glaube, es geht los. Jetzt ist es fast as fuck. Ähh. Moment,
das verstehe ich jetzt nicht. Warum macht das überhaupt einen Unterschied? Also, das
müsste jetzt, das dürfte höchstens, das dürfte höchstens 10 Millisekunden sein oder
so. Warum ist das in dem If drin so viel langsamer? Das check ich nicht. Das ist doch genau das.
Ob der das jetzt vorher macht und nichts... Ah, nee. Das liegt da dran, weil der nichts
findet. Moment, Moment, Moment. Ich weiß, woran das liegt. Wartet mal. Wenn der nichts
findet, ist es langsam. Kann das sein? Wartet ihr PS? Alter. Fulltext Search bringt hier
an der Stelle nichts. Weil das Full in Fulltext Search bezieht sich auf ganze Wörter. Nee,
da dran liegt... Warum ist das denn so langsam jetzt? Warum wird das langsam dadurch? Das
verstehe ich nicht. Hab ich hier irgendwas Blödsinniges drinne? Ja, das Count, das
Count wird es ja auch nicht sein. Das Count ist Null dann, das kannst du jetzt... Warum
ist das so langsam? Ist das wirklich das Count? Ist das das Count, was so langsam ist? Okay,
Null wie Count. Das ist das Count, was so... Warum ist denn das Zählen von nichts? Na gut,
da muss die komplette Datenbank durchgehen, um festzustellen, dass es wirklich nichts
gibt. Aber das es nichts gibt, müsste er doch eigentlich relativ schnell rausbekommen.
Weil er in seinem Index nachguckt und feststellt, es gibt keine Wörter oder es gibt nichts,
was mit... Vielleicht, weil es mehr als drei Buchstaben sind? Moment, Moment, das muss
ich jetzt mal ausprobieren. Beim Count wird es das erste Mal ausgeführt, ja. Warte,
warte. Das ist auch nicht viel langsamer. Warum ist das so langsam? Macht das erste Result
zu einer Liste? Ja, das habe ich mir auch schon überlegt, aber die Sache ist halt die, aus
irgendwelchen Gründen dauert das komplette Ding auszuführen so langsam. Das würde ich
jetzt auch als nächstes... Aber hä? Warum ist das Count Query so krass langsam? Wird
es überhaupt indiziert, wenn man mit einem Triggum im String sucht? Ja, wird es. Aber
anders als ein normaler Index. Das muss ich jetzt mal zeigen für alle, die neu dabei
sind. Der benutzt, wo habe ich es denn hier? Da. Der benutzt, um das zu indizieren, eine
Postgres-Extension, nämlich PG Triggum, woran für jedes Wort immer Dreierpaare speichert
in einem Index und deswegen relativ schnell Wörter durchsuchen kann, auch bei Wildcard
in der Mitte. Dadurch sind Inserts langsamer und die Datenbank wird insgesamt größer,
und die Suche ist viel, viel, viel, viel, viel schneller. Ich habe irgendwas bestimmt
nicht richtig beachtet. Ich habe irgendwo da was Blödes drin. Ein Count davon kann
auch nicht so langsam sein. Gut, das ist jetzt die übliche Geschichte. So, da findet er
was. So, jetzt HTT. Das ist langsam? Okay, das verstehe ich jetzt nicht so genau. Das
ist langsam. Alles klar. Ich weiß nicht warum, aber aus irgendwelchen Gründen ist das hier
langsam. Warum? Warum ist das langsam? Das liegt nicht wirklich am Count. Das liegt an
dem eigentlichen Query. Warum ist das so langsam? HTT. Watt? Watt? Hä? Achso, ja,
das ist ja... Moment, Moment, Moment. Das muss ich hier unten reinmachen. Am Ende, hier
wird ja das Query erst ausgeführt. Aber, okay. Der müsste doch relativ schnell feststellen,
dass er nichts findet. Ah, das ist. Das ist einfach lahm, wenn er nichts findet. Gut,
das verstehe ich jetzt nicht. Sehr spannend. Habe ich jetzt nicht gedacht. Ich hätte jetzt
eigentlich vermutet, dass er dadurch, dass er das quasi so special indiziert, sehr schnell
feststellen kann, wenn es eben keine Worte gibt, die das enthalten. Wir machen gar kein
Count. Am Count liegt es nicht. Das Query, wenn er nichts findet, ist lahm as fuck. Und
ich weiß nicht so genau warum, wenn ich ehrlich bin. Man würde denken, es ist langsam, weil
er alles durchgehen muss, um zu gucken, ob er wirklich nichts findet. Aber dadurch, dass
er die Wörter in so Dreierbuchstabenpaare zerlegt, müsste der Instant eigentlich nachgucken
können, dass es eben nichts gibt, was damit anfängt. Aber das ist Instant halt ziemlich
schnell. Ja, das weiß ich jetzt auch nicht. Keine Ahnung. Wie sieht es aus, wenn du das
Query meinst, und da bin ich zu blöd für. Natürlich ist es dafür gemacht, es gibt
extra eine Extension dafür. So. Hey, welchen Editor IDE nutzt ihr? Komme von Java, NetBeans
und bin auf der Suche nach möglichen... Ne, guck dir das... Also gerade, wenn du aus dem
Java-Umfeld kommst, kennst du wahrscheinlich IntelliJ. Und die Hersteller von IntelliJ,
die haben ganz viele IDE's. Zum Beispiel haben die auch eine.NET IDE und eine Go-IDE und
auch eine C-IDE und auch eine Python-IDE. Und wenn du dir... Also hier siehst du ja,
was die alles am Start haben. Das ist C, das ist ihr komischer Visual Studio Code Konkurrenz.
Dann haben die Goland am Start, IntelliJ für Java, PHPStorm, PyCharm, Rider, RubyMine,
falls jemand Ruby machen will, WebStorm. So, und wenn du das alles haben willst, weil du
sagst ja, du willst Java, du willst Java, Python und C machen, dann kannst du dir zum Beispiel
hier... Das für dich interessant wäre dann hier sowas wie SeaLion und IntelliJ, wobei
das ist eh kostenlos. IntelliJ kostet ja nix. Was war das andere, PyCharm? PyCharm kostet
auch nix. IntelliJ ist kostenlos und PyCharm ist kostenlos. Das Einzige, was du dir holen
müsstest ist SeaLion. Zumindest, was ich dir zeigen wollte ist, die haben ein Package für...
Die haben ein All Products Pack. Das kostet dich 250 Euro im Jahr und ich denke, wenn man
das professionell oder semi-professionell verwendet, kann man das ausgeben, zumal es ab dem zweiten
und dritten Jahr nochmal günstiger wird. Hab ich mir auch gekauft. Also das ist auch das,
was ich am Start habe bei mir. Also ich verwende von denen auch drei Sachen. Ich verwende Rider,
ich, wobei es stimmt gar nicht, ich verwende sogar mehr, aber nicht oft. Also hauptsächlich
verwende ich von den Rider, weil ich.NET mittlerweile quasi fast exklusiv unter Linux
programmiere. GoLand verwende ich für Go. SeaLion ab und zu mal für Arduino Platform
my own Zeugs, wobei ich da mittlerweile zum größten an Whistle Studio Code verwende,
weil das Setup einfacher ist. Ich habe PyCharm und RubyMine auch installiert, aber verwende
ich beides relativ selten. Ja, also diese Dinger sind wirklich gut und gerade wenn du
aus dem Java Umfeld kommst, solltest du die glaube ich vom Namen her zumindest schon kennen.
NetBeans wusste ich gar nicht, dass es das noch gibt. Mit explaining Query, da müsste
ich ja wissen, was der ausführt. Da muss ich ja von Hand irgendwelche SQL Queries ausführen.
Ich bin dazu zu low IQ was Datenbank angeht. Keine Ahnung. Wir können uns das Query mal
ausgeben lassen und ich mach das von Hand. Können wir probieren. Das machen wir jetzt,
das machen wir jetzt, das Query von Hand. Ruby ist doch super. Ruby ist neben SeaSharp
meine absolute Lieblingsprogrammiersprache schlechthin. Leider ist Ruby so ein bisschen
in der Bedeutungslosigkeit verschwunden die letzten Jahre über. Vor allem weil Rails
nicht mehr angesagt ist. Aber Ruby selbst ist das beste was es gibt. Wenn du brauchst
das, dann würde ich halt sagen kannst du PyCharm verwenden, IntelliJ verwenden, da hast du
Python und Java schon mal abgedeckt und für C gibt es ja jede Menge andere Möglichkeiten.
Du installierst ja Vmware Workstation oder VirtualBox und installierst da drin über
einen ISO das Lieblungs deiner Wahl. Also das kriegt eigentlich fast jeder der ein bisschen
IT technisch interessiert ist hin. Ja das ist richtig gut. Also ich muss sagen die Preispolitik
finde ich in Ordnung. Wenn man das und spätestens wenn man damit Geld verdient mit dem was man
eben da drin macht. Also sag mal wenn du professionelles oder semi professionelles Zeug verwendest,
sind 250 Euro im Jahr bzw. im dritten Jahr dann irgendwie keine Ahnung 200, ne 100, 170
Euro oder so. Da kannst du dich eigentlich nicht beschweren. Rails finde ich cool. Also
ich mag das Ruby Ökosystem und Rails eigentlich auch, aber das ist mittlerweile ziemlich in
der Versenkung verschwunden. Stimmt das habe ich ganz vergessen. Wenn du einen E-Mail Account
hast von deiner Uni, dann kannst du glaube ich dort dir eine Studentenlizenz ausstellen
lassen. Ja ich habe es aber selbst noch nicht ausprobiert. Bin mal gespannt. Also ich denke
nicht das sie schaffen werden w.h. Studio Code Konkurrenz zu machen was Frontend JavaScript
Sachen angeht. Aber für andere Dinge wo es zum Beispiel keine offizielle JetBrains IDE
gibt, sowas wie Rust oder sowas, da könnte ich mir das schon vorstellen, dass das sich
durchsetzen könnte. Naja es kommt drauf an was man machen will. Also wenn du JavaScript
Frontend Zeug machen willst, würde ich eindeutig Visual Studio Code nehmen. Die Ausmal an Plugins
und dass der Krempel eben selbst in JavaScript programmiert ist, ist schon ganz gut. Für
Frontend Sachen würde ich immer Visual Studio Code nehmen. Manche schwören auf WebStorm,
ok, aber ich mag Visual Studio Code. Aber ganz ehrlich,.NET Entwicklung ist ein ziemlicher
Painschamp in Visual Studio Code. Du kannst das machen, du kriegst auch die ganzen Plugins
dabei, dass du Autovervollständigung hast und sonst was, aber schön ist es nicht. Es
ist irgendwie haklich. Ich mag das nicht. Deswegen habe ich hier auch zwei Sachen auf.
Ich habe hier eine IDE für.NET auf und ich habe hier Visual Studio Code für den Frontend
Chat auf. Und die richtig hardcore Leute, die machen es über NeoWim, genau. Den macht
dann hier, wie ist denn der Manke als Einsteiger hier, den macht dann Akira zum ersten Mal
auf und weiß nicht mal, wie er rauskommt. Wenn ihr Leute NeoWim empfiehlt. Jaja, Fleet
ist quasi der JetBrains IDE Core extrahiert und dann so gemacht, dass du es mit Plugins
erweitern kannst. Was ja jetzt schon geht, ich habe ja jetzt schon einige Plugins, aber
müssen wir mal gucken, was da rauskommt. So, aber gehen wir mal zurück zu unserem Datenbank
Query. Ich habe keine Ahnung, warum das Lamas Fuck ist. Wir müssen uns jetzt mal irgendwie
auch. Also, okay, wir gucken wir gucken uns jetzt mal an, was der für einen Query macht
und dann machen wir das Query von Hand in der Datenbank. Jetzt wird es jetzt wird es
waren, so HTTP. Ja, das Query macht er da. Select Text from Limit. Okay, auf auf. Bash.
P SQL. Bäm. Gibt es da nicht, Leute, gibt es nicht, von wo wir gerade bei dieser JetBrains
Geschichte sind, hatten die nicht auch ein Tool, wo man Datenbank Queries irgendwie schöner
drin machen kann? Hatten die nicht sowas? Habe ich letztens bei denen auf der Webseite
gesehen, habe ich noch nie verwendet. Datacrit. Wollen wir das mal ausprobieren? Ach nee,
ich habe ja mein Account hier gar nicht eingeloggt. Ich mache das jetzt mal kurz mal gucken. Ist
das kostenlos? Braucht man dann? Braucht man dann ein Account für? Ja, ich weiß nur mal
so für die Leute, die immer sagen, ich hätte, ich hätte, ich würde das ja nur erzählen
und in Wirklichkeit irgendwelche gecrackten Version zu verwenden. Ich habe das hier ganz
offiziell aktiviert für mich. Und ich kann euch das zeigen. Das kommt ja jedes Mal. So
nach dem Wort Jaja aktiviert. Lulul. About. Hier. License to MaxK. Ihr könnt jetzt natürlich
nicht verifizieren, dass ich das bin, aber die. Das ist relativ unwahrscheinlich, dass
ich den gecrackten Licens Key irgendwo habe, der dann auch auf MaxK und so Nachnamen, Nachnamen
liegt. Warum habe ich IntelliJ Community Edition installiert? Warum? Das muss ich mal kurz
aufmachen und gucken. Warum? Ich mache kein Java Kram? Oh, du nie warst drin gemacht.
Okay. Alles klar. Bam. Data. Datalore, Dataspell, Datacrip. Jetzt wollen sie es einmal wissen
hier. Warum ist die outdated? Was ist outdated? Das da. Burscht. Wir haben noch nie großartig
Go gemacht im Stream. So, wenn ich mich, wenn ich mich registrieren muss, habe ich, habe
ich gelitten. Ich habe das alles nicht hier. Activate. Okay. Easy. Da hat es mein Account
gemerkt. Alles klar. Das immer. Also mein Fake Account für letzten Stream, den ich gemacht
habe. Wie funktioniert der Kram jetzt? Habe ich noch nie verwendet. New Projekt. Lul. Was
macht das jetzt? Database Explorer. Okay, das ist glaube ich abfuck für jemand, der von
der man keine Ahnung hat. Datasource. Postgres. Postgres. Wow. Localhost. 5 4 3 2. Das ist
richtig. User Postgres. Passwort gibt es nicht. Apply. Not found. Download. Ich habe keinen
Plassen Schimmer, was ich hier überhaupt mache. Native Keychain is not available. Ja, soll
mir recht sein. Das ist eh leeres Passwort. Und hat das jetzt funktioniert? Die Musik
passt sehr gut. Und jetzt hat es jetzt funktioniert. Select. Sternchen. Ich muss doch erst noch,
ich muss doch erst noch die Datenbank auswählen, oder? Wo mache ich das? Ah hier. Cute. Cute
Chat Database. Ok. Select. Sternchen. From. Cute Chat Database. Ne. Ne. Ne. Ne. Ne. Ne.
Ah, ich bin nicht connected. Ja, wie connecte ich mich denn? Ne, doch ich bin connected.
Ah, hier Konsole. Jetzt. Select. Sternchen. From. Ah. Wow. Wie heißt denn der Krempel?
Ich habe doch das Query hier. Select. Text values. Text values. Text. Ne. Kein Schimmer?
Die Musik ist richtig spooky, passt gerade gut dazu, ja. Ähm, das erscheint mir unnötig
komplex anstatt einfach. Ich meine meine Datenbank heißt offensichtlich Text values. Oder sehe
ich das falsch? Text values. Heißt nicht so. Ja, woher weiß ich denn, wie der Krempel
da drinne heißt überhaupt? Du musst das Schema selecten. Ich habe davon überhaupt
keinen Platz zum Schema. Wo sehe ich denn, was es da überhaupt gibt drinne? Nach From
kommt die Tabelle. Ja, ich weiß ja, die Tabelle müsste ja eigentlich, sag ich doch, Text
values heißen. Macht es aber nicht. Ok, das ist mir eindeutig zu, das ist mir eindeutig
zu high IQ dieses Ding hier. Schemas, no Schemas selected. Ok. All Schemas. Und nu? Ne. Ich
hab keine Ahnung, was ich hier mache. Ich hab wirklich keinen, absolut keinen, blassen
Schimmer. Tables. Also jetzt mal ernsthaft. Laut. EF Core heißt meine Table Text values.
Warum gibt es das hier nicht? Das ist irgendwas internes, oder? Text values, da ist es doch.
Da ist es doch. Ok, ok. Verstehe. Public. New Query Konsole. Jetzt aber. Ok. Next
Sternchen, From Text. Ah, ja, ja, ja. Ok, jetzt kommen wir der Sache näher. So, wir
führen das jetzt aus. So, Control, Enter. Exzellent, da haben wir es. Da ist unser,
ist unser Kram. Ok, nice. Ok, jetzt kann man das machen, was ich vorher, was ich, was
ich eigentlich vorher machen wollte. Also select. Das ist das, das ist das, was dort net ausführt
hier. Select, das ist ST. So, like, so like muss ich ja das eintragen, was ich, was ich
Query habe, HTTP. Limit sind 10. Stimmt doch, oder? Warum, warum macht der eigentlich ST?
Ach so, dass er das where danach machen kann. So, und jetzt führen wir das mal aus. Ah,
nein, es ist like, HTTP. Sternchen, genau. Ja, das ist einfach, das ist einfach lahm.
Wo sieht man denn die Zeit, was es jetzt gebraucht hat? Ach hier, 931 Millisekunden. Limit 1.
Warum ändert das Limit was an der Zeit? Das Limit soll doch überhaupt keinen Einfluss
auf die Zeit haben in dem Fall, er findet ja nix. Explain, ja, explain, lass uns jetzt
explainen. I've had time. Und jetzt? Was, was, was willst du mir sagen? Ah, jetzt. Ah,
I've had informations. Excellent, excellent. Bitmap heap scan on text values. Check condition.
Bitmap index scan. Mhm, mhm, alles klar. Ja. Und was sagt mir das jetzt? Was sagt mir
das jetzt genau? Jetzt weißt du Bescheid, ja, aber richtig. Jetzt habe ich voll den
Plan, warum es so lange dauert. Analyse, Analyse. Also jetzt ist es obvious, jetzt ist ein klarer
Fall. Wie ging das? Postgres Analyse. Nimm mal das Pattern nach dem Raus nach Like. Nein,
das ist ja genau das, was ich machen will. Ohne das findet er nix. Da findet er genauso
wenig. Also wir können das, wir können das tatsächlich mal raus machen. Er findet genauso
wenig. Aber wir können uns die Geschwindigkeit mal angucken. Die Geschwindigkeit macht keinen
großen. Sag mal. Die Datenbank ist aber schon richtig erstellt, oder? Kann man sich irgendwie
die Infos davon anzeigen lassen, wie die erstellt wurde? Nee, ich habe keinen Index im klassischen
Sinne. Ich habe einen Tree Cram Index, der für Textsuche da ist. Und die Textsuche ist
ja auch saumäßig schnell, wenn er was findet. Aber warum ist das so langsam, wenn er nix
findet? So, wie ging das jetzt? Explain Analyse. Nee, Collect Statistics. Explain Statement.
Was sagt mir denn diese Cost, Cost dahinter denn jetzt? Explain. Wir lernen Datenbankzeug,
das ist wirklich nix, wovon ich keine Ahnung habe. Cost, Cost. Also was mich enorm stutzig
macht ist, warum ändert das Limit überhaupt was an der Zeit? Weil, wenn er nix findet,
muss er sowohl bei Limit 1 als auch bei Limit 10 die ganze Datenbank durchsuchen. Fehlt
ja nicht ein Character. Doch. Für die abschließende Sache schon. Aber ich will ja explizit die
Limit-HTTP anfangen und danach irgendwas enthalten. Die gibt es nicht, aber das ist ja ein Fall,
der passieren kann, dass es das nicht gibt. So wird das denn noch größer, wenn ich sage
Limit 100? Nee. Warum ist das so extrem? Weil dadurch, dass wir diesen Tree Cram Index
haben, sollte er das ziemlich schnell erkennen können, dass man eben, also was mich äußerst
verwirrt ist, warum Limit 1 einfach doppelt so schnell ist. Obwohl es beides in die komplette
Datenbank durchkämmt werden muss. Ja, gut Leute, ich hab keine Ahnung. Leute, ich lasse
die Datenbank nochmal neu erstellen. Irgendwie so. Weiß nicht. Vielleicht. Keine Ahnung.
So und woran erkenne ich jetzt, was da lang dauert? Cost 0. Cost 195. Was VirtualBox
denkt an Bildschirme 600 mal 400? Kann schon sein. Der Installer wird das wahrscheinlich
denken. Kannst du es nochmal mit Prozent-HTTP ausführen? Ja, das ist viel schneller, aber
das ist auch klar, warum das viel schneller ist. Weil, oh nee, ich hab mich detached.
Wie attache ich mich denn jetzt wieder? Macht das automatisch? Ah, das macht der automatisch.
Das ist viel schneller. Guck, das dauert 26 Millisekunden. Aber ist auch klar, weil der
findet halt 10 Stück und hört dann auf. Achso, ja, sowohl bei VirtualBox als auch bei, genau,
als auch bei Vmware brauchst du Guest-Vmware-Tools, also Guest-Edition-Tools, dass er das erkennt,
dass dein Desktop-Bildschirm und sowas. So, aber ich suche hier explizit. So, wir suchen
jetzt mal nach was anderem, was es nicht gibt. Ok, Leute, jetzt blick ich nicht durch. Wenn
ich was suche... Achso, das ist, weil ich keinen Prozent dahinter hab. Das ist, weil
ich keinen Prozent dahinter hab. Hä? Warum ist... Warum ist HTTP... Ist das irgendwas
mit HTTP... Ist das jetzt einfach nur Pech, dass ich HTTP suche? Escapt der da irgendwas,
weil er denkt, ich mach irgendwelche... Ist das irgendein Security-Feature, dass wenn
ich HTTP, dass einer besonders escapen muss oder so? Drück mal rechtsklick auf das Select-Statement.
Und jetzt? Explain Plan. Explain Analyze. Ok. Ah ja, jetzt ist alles klar. Natürlich,
das weiß ich Bescheid. Ja, 4,5 Billionen Dinger, das passt schon. So, ähm, wie sieht's mit
HTTPS aus? Auch langsam. Haben wir sonst noch irgendwas in der Mitte? In.NET haben
wir manchmal am Ende stehen, ne? Aber auch viel zu langsam, für dass er es nicht findet.
Nein, eine Sekunde ist kacke. Wir hatten es ja vorher schon. Vorher war das im Durchschnitt
15, war das irgendwie 300 Millisekunden oder so das Langsamste? Moment. Vorher war das
300 Millisekunden. Was hatten wir noch mal vorher? Moment, Moment, Moment, Moment. Aber
ich muss noch kurz einen Comment machen, sonst check ich, blick ich nicht mehr durch. Ähm,
sind wir hier richtig? Get in it. Get add. Oh ne, jetzt hab ich binaries gealtert. A minus
M hack W. Wunderbares Comment. Exzellent. So, ähm, und jetzt machen wir das mal rückgängig.
Moment. Kann ich mal weiter rückgängig machen? Äh, local history. History. What? History?
Ist doch local history. So, wo, also wir machen das einfach mal rückgängig, was wir heute
gemacht haben. So, hier haben wir angefangen. 13 Uhr, gib ihm. Revert. Bam. Yep. So. Ach
so, da hab ich Wildcard-Dings komplett gemacht. Dann findet er, dann findet er ja was. Okay,
dann mach ich das, dann mach ich das hier mal raus. So. Run. Und jetzt Http. Das ist
immer noch langsam. Ich fass das nicht. Okay, keine Ahnung. Aber, okay, wir suchen mal
was anderes. Hier, keine Ahnung, blub. So, blub. Tia.net. Tia wollte schon immer mal
suchen. Ja, der findet welche. Punkt.net. Punkt.net. Wunderbar. Nee. Punkt. Name. Ach, jetzt funktioniert
sie ja mit meiner Suche nicht mehr. Ja, so. Danach will ich suchen unbedingt. Das ist
das, was ich schon immer mal suchen wollte. Das sind 1,5 Millisekunden. Ist das wirklich,
ist das vielleicht echt ein Problem, weil es Http ist? War dumme Frage. Könnte das
wirklich daran liegen, dass es Http ist? Dass die Zeichenfolge Http ist? Ich mein, nee,
das wird's nicht sein. Hat keine Resultate. Ja, wie Http nicht. Aber genau, das Problem
ist Http gibt es, na doch, Tia.net gibt es auch ein paar Mal, aber Http gibt es halt
eben 4,5 Millionen Mal. Okay. Keine Ahnung. Bei Http findet er eine Menge Treffer und
muss viele Wildcards verarbeiten. Naja. Das stimmt, das wird's. Ja, das ist es. Das ist
wahrscheinlich echt so. Http ist in 4,5 Millionen Rows drinne. Und er muss gucken, ob es dort
am Anfang ist. Aber gerade das sollte eigentlich durch den Index schnell sein. Dafür gibt's
den ja. Dass der eben erkennt, dass es Http nicht am Anfang gibt. Ich lass die Datenbank
jetzt noch mal neu erstellen. Wobei das dauert wieder ewig. Dauert wieder 5 Minuten oder
10 Minuten. Ohne Limit. Ich kann das Limit mal komplett weglassen, ja. Sollte ja genauso
schnell sein von der Idee her. Ja. Http hat nix. Also von der Idee her sollte es insofern
schnell sein. Weil, Docker stellt es hier. Machen wir noch mal hier das, was wir das
letzte Mal gemacht haben. Also, der speichert ja für jedes, für jeden Text, also für
das, was man hier sieht. Also für jedes dieser Dinger. Nehmen wir mal zum Buster. Nehmen
wir hier das da. Aus den humberto.net. Das übrigens Fake-Daten, das Zeug gibt's alles
nicht. Wobei, soll ich mich trauen mal, who is humberto.net? Das sind zwar Fake-Daten,
aber Moment, ist das wirklich registriert? Das ist anscheinend wirklich registriert.
Huberto.net, alles klar. Meine Fake-Daten sind anscheinend echte Daten, sehr gut. Also,
das macht die Datenbank beim Speichern dieses Textes da raus. Eben damit die Suche schneller
geht. Der zerlegt Austin, Http, humberto.net in solche Dreierpaare. Und das speichert er
sich dann wahrscheinlich in einem sortierten Index, dass er Binary Research machen kann
oder was auch immer er dann macht. Keine Ahnung. Und deswegen sollte er ziemlich schnell
feststellen, aha, der Typ sucht nach Http. Ah, ja, natürlich, das ist ja eigentlich ganz
logisch, dass das langsam ist. Ja, ja, das funktioniert. Funktioniert, tut das. Die
anderen Queries sind sonst richtig langsam. Aber guck mal, von der Idee her, der guckt
da rein in seinen Index. Wahrscheinlich weiß der nicht so ohne weiteres, ob das am Anfang
oder in der Mitte ist. Der weiß nur, dass irgendwie in dem Index Htt drin steht. Und
dann muss der wahrscheinlich gucken, genau, und das findet er 4,5 Millionen Mal. Und dann
muss der wahrscheinlich gucken, ist es am Anfang. Der muss wahrscheinlich wirklich jeden Eintrag
durchgehen und gucken, ist es denn am Anfang. Da ist wahrscheinlich nicht direkt die, selbst
wenn die Position direkt gespeichert ist, so quasi, mal angenommen, da würde Index
off dahinter gespeichert sein, was ja nicht geht, weil das könnte ja mehrfach drinne,
was auch immer. Aber selbst wenn da direkt die Position dahinter steht, der muss ja jeden
Eintrag durchgehen und gucken, ob der nicht am Anfang steht. Das ist jetzt absolut der
Worst Case eigentlich. Ich denke in dem Fall, also wie soll ich sagen, in den normalen Daten,
die ich da habe, wäre das ja wahrscheinlich überhaupt nicht der Fall. Kann man den Index
manuell zu Http oder Https ändern? Hä, wie? Aber das ist jetzt einfach bei Design verkackt.
Meine Testdaten sind halt so ein bisschen doof, weil da Http überall drinne ist und ich suche
halt zufälligerweise direkt nach Http. Dann ist es ein ziemlich doofes Beispiel, dass
ich bereits Http rausgepickt habe. Das wird wahrscheinlich in der Art und Weise in echt
nie der Fall sein. Mal davon abgesehen, das wird auf jeden Fall definitiv nicht der Fall
sein, weil ich dort irgendwelche Prometheus Exporte reinpumpen würde und die haben zwar
sicherlich ab und zu mal Http in der Domain, aber die meisten Label Value Pairs sind sonst
was, bloß nicht Domains, die mit Http anfangen. Nice. Okay, ja, das ergibt aber Sinn, dass
es so langsam ist. Das ergibt tatsächlich Sinn. Ja. Das ergibt tatsächlich Sinn. Dann
fällt mir nichts ein, um es schneller zu machen zu dem, was ich das letzte Mal gebaut
habe. MySQL? Hä? Ich bezweifle, dass das MySQL schneller kann. Ja. Und weiter? Also
ich kenne die Hilfeseite dazu. Mit Fulltext Search sollte es schneller sein. Da habe ich
so meine Zweifel, weil das sind ja keine Wörter. Fulltext Search ist bei Wörtern schnell, aber
bei Substrings von Wörtern Elastic Search, ja, gut, so was könntest du da mit Sicherheit
drauf schießen, ja. Also die Postgres, die Postgres Fulltext Search kann zum Beispiel
keine Substrings von Wörtern, eben weil es keine Wörter sind. Und wenn MySQL das kann,
dann ist es wahrscheinlich, weil MySQL Fulltext Search plus das, was Postgres hier in dem
Fall mit diesen Drupeldingern Wörtern macht, auch macht, bloß automatisch. Die können
ja alle nicht zaubern. Das Full in Fulltext Search bezieht sich auf ganze Wörter. Das
ist kein ganzes Wort. Weil natürlich könnte man als Trainer irgendwie jetzt sagen, nicht
Leerzeichen, sondern gleich, aber das weißt du ja vorher nicht. Fulltext Search ist in
der Regel nichts für Substring, vor allem nicht für Substring mit Wildcard davor. Dafür
ist Fulltext Search kacke. Weil Fulltext Search in der Regel so funktioniert, dass du deinen
Text, ganz simpel gesagt, du nimmst deinen Text, splittest den in Wörter und dann machst
du einen Index draus. Also du machst eine Liste draus, sagen wir mal alphabetisch sortiert,
dass du in deine Liste dann per Binary Search relativ schnell finden kannst. Wo ist das?
Dann hast du das Wort gefunden und zu dem Wort hast du dann dir noch zusätzlich gespeichert,
in welchem Dokument das vorkommt, an welcher Position. Das ist so ganz grob kurz gesagt
wie Fulltext Search funktioniert. Und das Full in Fulltext bezieht sich auf komplette
Wörter. Und was Fulltext normalerweise überhaupt nicht gut kann, sind Wildcards am Anfang,
weil er dann die Liste auch komplett durchscannen muss. Ja, da muss ich mir mal was überlegen.
Ich hab gedacht, das könnte man jetzt besonders schlau machen, das so zu beschleunigen, aber
der absolute Worst Case, wenn HTTP wirklich in jedem einen Tag vorkommt und es nicht
matcht. Wobei könnte man das nicht einfach umdrehen? Nee, ich brauch ja beides, ich will
es ja nicht. Ja, da fällt mir nichts ein zu. Dann fällt mir nichts ein zu, wie man das
schneller machen kann, wobei es ja so schon saumäßig schnell ist. Der braucht ja nur
bei der Diomalessuche nur 30-40 Millisekunden. Ich will es ja nicht, ich will es ja finden,
ich will es ja finden. Wann kommt Battlefield Bad Company 3? Das musst du mal EA fragen,
was soll ich das wissen? Wahrscheinlich gar nicht, weil DICE vor einer Weile gesagt hat,
sie haben verlernt, sie haben das ein bisschen anders ausgedrückt, aber sinngemäß haben
sie gesagt, sie haben verlernt oder sie wissen nicht mehr, was an Battlefield Bad Company
den Leuten gefallen hat. Mach doch einen Präfix vor dem Wort. Ja und dann? Also das
weiß ja derjenige, der danach sucht, nicht. Der hat ja keine Ahnung. Irgendeiner tippt
im Webinterface HTTP ein, erwartet, dass er Antworten bekommt für HTTP. Das weiß man
nicht, ob alle HTTP haben. Es ist in diesem Fall mit diesen Daten so, aber das weißt du
ja nicht. Es wird in der Praxis auch nie relevant sein, gehe ich mal von aus, weil das, was
ich davor hatte, reinzupumpen, hat das definitiv nicht. Aber ich überlege gerade, ob es irgendwie
eine schlaure Variante als das gibt. Weil in dem Fall, hier macht es halt das Order
bei langsam. Fällt mir jetzt gerade nichts ein. Bin ich gerade zu low IQ für? Reicht
man eigentlich an Datenbank-Grempel jetzt schon mal? Sollen im Webinterface alle 4,5
Millionen Treffer rauskommen? Nein, nein. Im Webinterface sollen 10 Ergebnisse rauskommen,
aber der Trick ist ja, jedes Zeitproblem ist gelöst, insofern, dass ich jetzt nachvollziehen
kann, warum es langsam ist. Also ich will bloß 10 Ergebnisse haben. Aber ich möchte,
die die mit dem Query anfangen, die will ich oben haben. Wenn ich das hier rausnehme und
die random sortiert lasse, dann ist es mega schnell, aber ich habe nicht die, die mit
dem Query anfangen oben. Weil ich hätte gerne, wenn einer zum Beispiel einen gibt, dann
hätte ich gerne, dass er zuerst 10 Stück nimmt, falls es die gibt, die Plup am Anfang
haben und wenn es die halt nicht gibt, sondern sagen wir nur 3 Stück mit Plup am Anfang,
dann eben noch 7 Stück mit Wildcard auffüllt. Das funktioniert auch, aber dabei sind wir
drauf gestoßen, wenn man nicht nach Plup sucht, sondern nach HTTP, dann funktioniert es insofern
nicht richtig, es funktioniert schon, aber es funktioniert langsam. Weil er eben HTTP
potenziell findet in jedem Wort und dann 4,5 Millionenfach checken muss, ist HTTP denn
am Anfang. Das ist eigentlich relativ logisch, dass das langsam ist. Ja, da muss ich mir
irgendwas überlegen. Vielleicht fällt mir noch was ein oder ich lasse es einfach so.
Nein, Timeout ist doch doof, ich will auch ein Ergebnis haben. Zur Not gegebenenfalls
zwei Queries machen mit Wearfilter für das Startwith, dann kann der Präfix, äh, was?
Nein, nein, nein, das ist ja das, was nicht funktioniert, guck mal. Das ist ja das, was
nicht funktioniert. Das ist ja das, was ich schon gemacht habe. Guck mal, wenn du das
hier machst, wenn du hier checken willst, ist es am Anfang. Das ist ja das, was du meinst,
ne? Zwei Queries. Du machst dieses Query mit, äh, ist am Anfang und dann machst du dieses
Query mit, ist irgendwo in der Mitte. So, aber das hier ist langsam. Das ist langsam
erst fuck, wenn du das ausführst. Das braucht knapp ne Sekunde. Und warum? Weil er nachguckt,
aha, das Wort startet mit HTT. In dem Fall zerlegt er auch HTTP, weder in HTT unter anderem
und dann muss er bei jedem dieser 4,5 Millionen gefundenen Einträge gucken, ist das HTT am
Anfang. Ich kanns, im Prinzip kann ichs auch so lassen. Im Prinzip kann ichs so lassen,
wie ich die ganze Zeit schon gemacht hab, weil es ist immer noch schneller als im Worst
Case mein anderes Ding. Da fällt man manchmal in Fallen rein, wo man gar nicht gedacht hat,
dass es die gibt. Ja, das hat nen Index. Es hat zwar keinen klassischen Index, aber es
hat so ne Art Index. Interessant. Tja, ne, da fällt mir jetzt wirklich nichts Gescheites
zu ein, außer das einfach so zu lassen, wie wir es das letzte Mal schon gemacht haben.
Ein klassischer Index sollte den Präfix-Check beschleunigen können. Geht in Postgres ein
Substring-Index? Ja, das haben wir doch. Da gehts doch darum. Genau das haben wir. Wir
haben für jeden Texteintrag, so speichert Postgres so ne Kombination aus allem möglichen,
dass du Substring Search mark hast. Aber vielleicht muss man noch nen klassischen Index drauf
machen, um zu gucken, ob das Starts, das könnten wir tatsächlich mal machen, ja. Das machen
wir jetzt. Das machen wir jetzt. Wie bring ich dem dann bei, nen normalen Index zu machen
noch zusätzlich? Dann müssen wir die Datenbank nochmal neu erstellen lassen wahrscheinlich.
Also das ist der Index für Substring-Suche. Wie sag ich dem, dass er noch nen normalen
Index drauf machen soll? Nochmal Has-Index? Ne, oder? Weiß ich gar nicht, wie mach ich
das? Kein Schimmer. So hab ich das für diese Substring-Suche auf jeden Fall rausbekommen
das letzte Mal. Muss man, muss man das nicht doppelt machen? Einfach nochmal so Sachen,
Has-Index oder so? Okay. EF Core Postgres-Index. Wie geht das? Zeig her. Has-Index. Ja gut,
auf der ID ist schon mal klar. Im normalen Fall, also was mich eigentlich interessiert
ist Wildcard-Wort-Wildcard. Das ist Darkreader-Neighbor-Youblog. Aber halt eben dann die, die mit was anfangen
als erstes. Naja meine Idee war jetzt ja ursprünglich, anstatt diese Abfrage hier mit dem Order-Buy
zu machen, wir machen einfach zwei Queries. Einmal eins ohne Wildcard und wenn das schon
zehn Stück zurückgibt, dann ist alles gut. Ansonsten führen wir einfach das Query nochmal
so aus und nehmen halt noch sieben zusätzliche zum Beispiel dazu davon dann. Das Problem
ist nur, dass dieses Query, wenn man HTTP eingibt, halt übelst langsam ist. Und dieses
ist übrigens nicht langsam bei HTTP, weil er eben was findet. Und ich gehe mal davon
aus, wenn ich was suche, was er gar nicht findet, was gar nicht in diesem Index drinne
ist, dann ist es auch schnell, weil dann kann er direkt sagen, hier so nach dem Motto was
wie blub, hier gibt es kein blub, kann nicht sein. S-Index. Wie kann ich dem denn jetzt
sagen, dass ich anstatt hier in diesem Index noch einen normalen Index machen will? So
jetzt? Funktioniert das so? Keine Ahnung. Ich bin Stocher da voll im Dunkeln. S-Index.
Ah nee, der hat das schon. Nee, das passt schon. Der hat schon den Index erstellt dafür.
Guckt mal, das ist schon richtig. Der macht hier einen wie auch immer gerne GIN-Index
und dann macht er noch diese andere Geschichte obendrauf. Nee, dann habe ich wirklich keine
Ahnung mehr. Wisst ihr was? Dann lassen wir das einfach so. Das denke ich auch, ja. Ja,
ich glaube, das hat er. Ich glaube, das hat er hiermit schon. Zumindest wenn man den,
wenn man das hier dieser, dieser Doku-Seite von denen glaubt. Oder muss ich nochmal, oder
muss ich das einfach zweimal machen? Einmal so und einmal so? Kannst du irgendwie aussuchen,
welchen Index da beim aktuellen Query benutzen willst? Bestimmt irgendwie? So, wir machen
das, ich gucke mal, ob man so die Datenbank erstellen kann, ob das in irgendeiner Art
und Weise schneller ist. Wisst ihr was? Wir lassen dieses ganze Krempel, wir lassen den
mal weg. Wir lassen den mal weg und erstellen den neu und gucken, ob mit einem einfachen
Index, der startet mit schneller ist. Probieren wir das mal aus. Ja, 900 Millisekunden ist,
mir geht es nicht wirklich darum, dass das jetzt besser benutzbar wird oder so. Generell,
wenn es darum geht, müsste ich das ja gar nicht machen. Hab ich das so gemacht, dass
es funktioniert? Hoffe mal. Run. Mir geht es einfach, dass ich was lerne drum. Nicht,
dass da irgendwie was so Sinnvolles bei rauskommt. So, jetzt wird eine Runde geinsertet in den
Index bzw. nicht in die Datenbank. Das dauert jetzt 1-2 Minuten. Oder habe ich den Output
abgeschaltet? Übrigens, random Seed 1337, ganz wichtig, immer bei eurem Randomizer Seed
1337 verwenden. Ihr solltet prinzipiell nicht den Seed irgendwo reinschreiben, dann ist
es nämlich ziemlich easy, eure Secrets zu erraten, das will man nicht. Du brauchst ziemlich
sicher, wie gesagt, Guest Tools, dass es funktioniert. Du brauchst, wie heißt das mal, Virtual Box?
Virtual Box Guest Tools, wie nennt man sich der Kram? Du hast zuerst ins CD, dann musst
du starten oder zumindest die Kiste neu starten und dann musst du in der VM keine Auflösung
einstellen. Sobald die Guest Tools, Guest Editions, genau, sobald die Guest Tools funktionieren,
macht er automatisch das Ding auf die richtige Auflösung. Guck, jetzt ist es auf der richtigen
Auflösung, er macht es automatisch, siehste? Ok, Datenbank Insert dauert ein bisschen.
So, jetzt haben wir eine Datenbank gleich mit keinem Substring-Dingsgedöns-Durchsuch-Index,
aber eine mit einem stinknormalen Index auf das Textfeld. Und dann gucken wir mal, ob
das schneller ist. Open VM Tools? Nee, das bringt ja nichts, er hat Virtual Box. Und wenn
er Virtual Box hat, bringen ihm Open VM Tools nichts. Ich würde eh, ganz ehrlich, ich würde
nicht Virtual Box, ich würde Forever Workstation nehmen oder? Ach nee, Forever Player gibt's
ja nicht mehr, oder? Forever Player war früher die kostenlose Variante, ich glaube, Forever
Player kostet doch jetzt auch was. Was Open VM Tools geht auch mit Virtual Box? Echt?
Das ist nice. Das ist mir neu, weil ich immer VM mehr verwende. Gehen die auch, das ist
ja der Chat, die ganzen Prime-Subs haben sich gelohnt, der Chat ist mittlerweile absolut
hier Next-Level-IQ-Werte. Der weiß Bescheid. Das heißt, Chat, wenn ihr auch Next-Level-IQ-Werte
habt, müsst ihr mir auch einen Prime-Sub dalassen, weil das gilt für den kompletten Chat. Ist
quasi geshared jetzt zwischen 230 Leuten, aber nur, wenn ihr gerade zuguckt. Sonst geht
das nicht. So, Datenbank, inserte mal, please. Etwas schneller. Ich glaube, ich sollte mal
mein Logging ausschalten, weil mein Arbeitsspeicher ist zu 94% voll und wahrscheinlich liegt es
daran, weil mein Terminal den ganzen Text drinstehen hat. Weil ich bin ziemlich blöde
gewesen. Mein Terminal hat unlimited scrollback-Buffer. Er ist fertig, Poggers. So, diesen Krämpel
hier gleich mal wieder auskommentieren, dass er nicht jedes Mal neu die Datenbank erstellt.
Passt mal auf, ich schließe jetzt mein Terminal, mal gucken wir, wie viel Arbeitsspeicher er
gleich freigibt. Oh, Kinga, Kinga, Kinga. Wie habe ich es genannt? Search-Champ. Okay,
dann gehen wir mal hier in dieses Data-Ding wieder und machen noch mal das Gleiche. Aha,
aha, guck mal, es ist schneller, es ist schneller. Jetzt ist es bloß 317 Millisekunden, es ist
schneller. Der best case, ja den best case, ich weiß nicht, ob ich den gescheit testen
kann überhaupt. Hiermit. Ich meine, das müsste langsam, langsam sein jetzt mit dem nicht
vorhandenen Textsearch-Index. Achso, der macht automatisch einen Limit. Dann ist es
auch schneller. Aber ja, ich limite 10. Ja, das ist natürlich hier auch schnell, weil
überall HTTP drin ist. Also, suchen wir mal irgendwie emerald.org oder so. Ja, das dürfte
jetzt, das dürfte jetzt nicht so schnell sein. Ja, Mist, ja, der hat ja halt nur, das ist
ja doof, der hat halt nur 5 Domains oder so, die den Test-Ding an einträgt. 5000 Limit,
bam. Ja, jetzt braucht er schon ein bisschen länger. Ja. Also, normale Suche mit Wildcard
dauert jetzt halt deutlich länger. Es dauert jetzt 500 Millisekunden, um alles zu finden.
Und, äh, was machen wir denn mal? Was hab ich? Eleanor. Und das ist halt 300 noch was. Warum
limitiert der immer auf 500? So, macht er gar nicht. All, bam. 1500, gib ihm. Er ist
tatsächlich, wenn er am Anfang ist, ist er doch relativ, relativ geschwind. Kann er
nicht Jeanette-mäßig mal bitte hier auf All bleiben? Okay, also ich denke schon, dass
der normale Index tatsächlich was bringt. Und jetzt das andere mit einkommentieren, ja.
Ja, ja, probieren wir das mal aus. Jetzt müsste man nur noch fragen können, ob man in dem
Query irgendwie sagen kann, was er für einen Index verwenden soll. Wahrscheinlich meckert
er jetzt rum, dass das nicht funktioniert, dass das schon ein Index existiert oder sowas.
Wahrscheinlich meckert er, dass es schon ein Index gibt. Probieren wir mal aus. Ähm, ich
werde mal kurz die Output umleiten, dass mein Terminal nicht wieder abkackt. Ach so,
jetzt sehe ich die Fehlermeldung ja gar nicht. Okay, das ist ziemlich blöd. Zack. Ne, das
funktioniert. Der meckert nicht rum dabei. Und wann heißt, und wann weiß, dass er fertig
ist? Gute Frage. Gar nicht. Doch. Wartet mal. Ich stelle das Locklevel hoch. Ich stelle
das Locklevel. Wo ist das denn hier nochmal? Locklevel? Das ist immer so versteckt bei
dem Campbell. Wo waren das nochmal? App-Settings? Hier, die vollen Locklevel. Warning. Moment,
Development ist es doch. Stimmt doch gar nicht. Info-Development-Warning. Ich mache einfach
das Locklevel hoch, dann sehen wir es nicht mehr. Er erstellt nur einen GIN-Index, ist
das so? Das müssen wir uns nochmal angucken. Run. Also, was macht er hier? Zeigt mal her.
Die Datenbank Pfeiferts hier unter uns. Also, Create-Index. Tatsächlich, er macht nur einen
GIN-Index. Dann weiß ich auch nicht. Muss ich die Sachen dann doppelt in die Datenbank
schreiben oder was? Boah, keine Ahnung. Was passiert denn? Was passiert denn? Wie sieht
das aus, wenn man das weglässt? Was macht er dann? Ja, dann sagt er Create-Index. So,
das kommt jetzt auf die Reihenfolge an? Dann kann es ja nicht funktionieren, wenn es doppelt
drin ist. Okay. Das juckt ihn überhaupt nicht. Es zählt immerhin nur, das muss man bestimmt,
man muss irgendwie doppelt HESS-Index machen oder irgendwie sowas. Okay, das befragen
wir den jetzt mal. Multiple-Index-On-Same-Column, richtig? Ja, ne? Ah, Stack Overflow, alles
gut. Multi-Column, ne? Combine Multiple-Indexes. Ich will einfach nur zwei verschiedene Indextypen
haben. Stimmt, das ist... Ich wollte auch gar nicht nach Postgres suchen. Ich wollte
eigentlich auch nach Ding suchen, nach NPGSQL wollte ich eigentlich suchen, nach dem EF-Core-Ding,
nach dem Postgres-Adapter. Oh, das sind jetzt schon die absolut High-IQ-Datenbank-Dingern.
Das ist mir jetzt zu hoch, da mach ich nicht weiter. Ne, keine Ahnung, hab ich kein Bock
mehr. Ich lass es jetzt einfach so. Ich lass es jetzt einfach so. Es funktioniert ja und
es ist auch relativ schnell. Das ist halt ein dummer Worst-Case mit Hard-TDP, aber scheiß
drauf. Oh, ne, reicht spätst. Keine High-IQ-Lösung heute, aber gut, wir haben was gelernt. Und
ich hab jetzt auch mal Datacrypt verwendet. Kann ich gleich wieder zumachen, werd ich
nie mehr verwenden. Reicht genug. Genug. So Leute, ich muss jetzt was trinken, sonst
treuere Hals. Und jetzt geh ich off. Jetzt geh ich off und kreiselgrinde noch ein bisschen.
Und jetzt noch eine andere Frage an die ganzen Frontend-Experten unter euch. Was ist denn
euer Lieblings-Date-Time-Picker-Library? Auf mobile ist das einfach. Auf mobile nimmt
man den Native vom Browser. Auf dem Desktop ist es ein bisschen doof, weil der Native vom
Browser halt null in das Design der Seite passt. Light-Pi-Date-Time-Picker. Kengi, danke
für den Sub. Ach Leute, ich muss mal kurz nachgucken nach den Subscriptions hier. Die
Hälfte wieder übersehen. Ferdy Fuchs hat subscribt. Hab ich auch nicht gesehen. Dankeschön
für den Sub. Hi IQ-Subscription hier Leute. Ich war zu beschäftigt mit meinem Datenbank-Krempel.
Majorink auch. Vollkorn-Milchbrot hatte ich schon. Okay, Light-Picker. Warum ist das so
schräg? Da tut dir der Nacken weh. Ah hier. Okay, der sieht sehr viewig aus mit dem Grün,
wobei man das wahrscheinlich semen kann, wie man lustig ist. Und Date? Kann er auch time
picken? Kann er auch time picken? Ja. Oh, transparent. Wie kann man den time picken
lassen? Wo ist hier time? Ich sehe hier nichts für time. Oder ist das nur date? Der Darkreader
macht es kaputt. Ja, das wird es wahrscheinlich sein. Single date, placeholder, separator,
time. Ein Beispiel mit time? Hier ist time drin, aber ich kann keine time eintragen.
Hier ist doch time. Hier kann ich keine time auswählen. Egal, ich geh jetzt auf Leute,
wir sehen uns. Bis zum nächsten Mal. See you.
