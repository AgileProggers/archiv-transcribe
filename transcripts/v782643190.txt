Das war's für heute und wir sehen uns beim nächsten Mal wieder!
Das war's für heute und wir sehen uns beim nächsten Mal wieder!
So, exzellent! Da is er!
So, ähm...
Hört sich ein schlimmer an als das andere.
Das kannst du mir nicht geben, das ist ja eklig.
Das ist ja einschlimmer als das andere.
Ja, meinetwegen.
Moin, Leute! Jetzt sind wieder viele am Start.
Ist quasi das Gegenstück zum Subbox-Kämpfer auf YouTube.
Wir machen heute mal ein bisschen was anderes.
Wir programmieren mal wieder was.
Ich will nämlich was ausprobieren und zwar...
Was ist das hier auf Domain-Check?
Magenta.Gay! Stimmt, das hab ich ja ganz vergessen.
Ich hab Magenta.Gay übrigens nicht registriert.
So, ich muss mal kurz hier eine Runde Updates machen.
Weil ich weiß nicht, ob ich die aktuelle.NET Core-Version hab.
Danke schön für die Zaps! Wer gibt's?
KlokxHD! 13 Monate!
Massive! 13 Monate, das ist ja quasi schon.
Exzellent!
So, dann haben wir noch den Jatz...
Ach nee, JET SQL.
Ich hab doch irgendeinen Flag!
Nee, doch nicht SQL.
Ich hab nämlich genau an der Stelle einen Flag auf dem Monitor.
Ich seh jetzt nicht, ob das ein I, sondern ein L ist.
Ich muss mal kurz scrollen.
Nee, das ist doch Jatz-Key eher.
Nicht JET SQL oder so.
So, danke schön für den Sub.
Der Taser ist 16 Monate am Start.
Jetzt wird's langsam echt schon hier.
Unangenehm langsam.
Wobei eigentlich...
Also fürs Geld, ja.
Danke schön für die ganzen 16 Monate.
Massive! Big Brain Subscription.
So, das soll man updaten hier.
Machen wir mal auf.
Ich zeig euch mal, was ich gefunden habe heute.
Ich guck ab und zu mal bei GitHub, was so trendet, was so neu ist, was ihr nicht gesehen habt.
Und ihr wisst ja, ich interessier mich für...
Oder ich bastel schon eine Weile an einer Video-Streaming-Software für Überwachungskameras.
Allerdings rein für den Heimbereich.
Also sprich, die soll komplett im Browser funktionieren.
Ich hab ja auch schon was gebastelt.
Wir haben auch schon im Stream was gebastelt.
Die aktuelle Version, die ich laufen hab, ist mit.NET und mit Go.
Go für die Video-Streaming-Geschichte, weil es da für.NET nichts Gescheites gibt bis jetzt.
Und ich hab jetzt was gefunden.
So, haben wir jetzt einmal ordentlich geupdatet?
Erstmal eine Runde...
Oh, was ist denn hier alles drinne?
Ja, komm, update mal, update mal, alles gut.
So, machen wir mal kurz unsere Idee auf und ich zeig euch das jetzt mal.
Ups.
Ah!
Placer!
Was ist denn hier los?
Was ist denn hier los?
Äh, oh, 2019, das ist ja uralt.
Ok, ich muss mal kurz...
Ihr dürft jetzt nicht hingucken.
Ich muss mal kurz die Idee kaufen.
Ups, nein, ich will nicht Plant aufmachen.
Geh weg.
Ich hatte Plant noch nicht einmal auf.
Ich weiß gar nicht, was ich mit dem Müll machen soll.
Geh weg, Plant.
Yes.
So.
Evaluation Feedback, no thanks.
So, wir machen jetzt erstmal ein Update.
Hab mich die Chatbrains Toolbox...
Komm, wir machen erstmal ein Update.
Will it Plant?
Ey, die Typen machen wieder Videos.
Die machen wieder Videos.
Die haben vier Jahre keine Videos gemacht, der Dude.
Und hat letztens wieder eins hochgeladen.
Vor einer Woche.
Guck mal, die haben ewig...
Der macht so wenig Videos wie ich.
Und die sind wieder am Start.
Äh, ja, komm, mach Update.
Auf geht's.
Einmal Toolbox starten.
Toolbox startet nicht.
Exzellent.
Hallo Mom, startet meine Chatbrains...
Ach, die update gerade, deswegen startet die net.
Das ist ja okay, das ist logisch.
Ja, äh, während das Update kann ich euch ja mal erklären, um was es geht.
Und zwar, äh, wie gesagt, ich verwende ja gerade, oder ich bin ja schon seit langer Zeit dabei,
so eine Webcam, also Security-Kamera-Überwachungssoftware zu programmieren.
Allerdings nichts großartig ausgefallenes, jetzt nicht sowas wie Blue Iris oder sowas,
sondern im Prinzip einfach nur aus der Notlage heraus,
weil ich nichts Gescheites gefunden habe, was das macht, was ich, was ich machen will.
Und ich, Problem ist, ich kann's euch jetzt nicht wirklich zeigen, weil da die Kameras von mir drin sind.
Ähm, guckt grad mal.
Ob man das vielleicht sieht.
Äh, ne, dann soll ich nicht zeigen.
Ne, egal, also ihr müsst mir, ihr müsst mir das jetzt glauben, wobei doch, ich kann euch, ich kann euch den,
kann euch den oberen Teil zeigen, ne.
Also wenn man hier im Browser draufgeht auf die Webseite, dann, ähm, kriegt man halt Kameras angezeigt, wenn's lädt.
Also, oh.
Okay, das ist jetzt, das ist schlecht.
Ah, sieht man das Hoftor, sieht man hier hinten das Zimmer von der Katz, sieht man hier unten den, den Bürgersteig ein bisschen
und da unten sieht man die Treppe, aber das ist jetzt...
Ähm, genau, und da, wie gesagt, das kann auch ein bisschen was aufnehmen und zumindest ist es aus der Notlage herausgeboren,
weil ich nichts anderes gefunden hab und meine Anforderung ist, dass ich das im Browser verwenden kann.
Face League, ja, genau, also das natürlich, ich hab hier keine Kamera drin, aber definitiv Face League.
So, und das Problem ist halt, es gibt nichts Gescheites, was im Browser funktioniert.
Zumindest nichts, was im Browser Low Latency funktioniert.
Ich hab das vor einer ganzen Weile schon mal hier, wir haben sogar im Stream schon mal ein bisschen rumgebastelt.
Hast du Dezember wieder frei? Ja, ich hab kompletten, kompletten Dezember frei.
So, und, ähm, die Sache ist die, wie ich das jetzt aktuell gemacht hab, ist folgendes,
dass das Late, also Latency-Frei bedeutet bei mir, ich will im Browser, sag mal so, nicht wirklich mehr als eine Sekunde durch Verarbeitung drauf kriegen,
was bei Security-Kameras irgendwo ein wichtiger, oder generell bei Kameras generell ein wichtiger Aspekt ist.
Dezember-Frei, das gibt's doch, klar, wenn man sich Urlaub nimmt, gibt's das.
Und, so, genau, also, ähm, es gibt verschiedene Varianten, wie man Video-Streams im Browser kriegt.
So, die bekannteste ist, glaub ich, äh, hier MJPEG, aber das suckt.
Das kann so gut wie jede Kamera in irgendeiner Art und Weise, und das sind einfach Snapshots,
also der macht einfach Bilder, einzelne Bilder, und überträgt die dann.
Das ist erstens ziemlich groß, von der Bandbreite, das ist lokal nicht so schlimm,
das ist sehr ressourcenintensiv, und es ist lahm, und es suckt, also, MJPEG ist übelster Crap.
So, das nächste, was es gibt, um Sachen in Browser zu streamen, ist HTS.
Das ist das, was Twitch früher gemacht hat.
Mittlerweile macht Twitch da moderneres HTS.
Das, äh, ne, genau, das ist, hat Sache, die ursprünglich sich Apple ausgedacht hat,
HTS-Live-Streaming, das ist eigentlich was total Simples.
Das besteht aus einer Playlist und aus kleinen Schnipseln Video.
Und man kriegt einfach immer eine aktualisierte Playlist geschickt,
mit so zwei bis drei Sekunden Videoschnipsel.
Vielleicht habt ihr euch schon mal gefragt, warum, wenn ihr Twitch reloadet, die Seite,
ihr manchmal ein bisschen hinten dran seid und das noch mal seht, was ihr gerade schon gesehen habt.
Und das liegt an diesen kleinen Schnipseln von HTS.
Also sprich, ihr bekommt eine Playlist, da ist ein 3-Sekunden-Schnipsel drin,
oder ein 4-, oder ein 5-Sekunden-, oder ein 0-, oder ein 0-, 500-millisekunden-Schnipsel,
das kann man sich aussuchen.
Und, ähm, sagen wir mal, ihr bekommt einen 3-Sekunden-Videoschnipsel geschickt,
und ihr, äh, nicht HTS, ich meine HLS, ich komme nicht auf HTS, Schwachsinn.
So, und ihr kriegt einen Videoschnipsel geschickt,
so, und dann guckt ihr den Videoschnipsel, zwei Sekunden, refreshed,
und dann bekommt ihr, weil das noch kein neues Videoschnipsel ist,
weil das gerade noch aktuell ist, bekommt ihr das gleiche noch mal,
und dann guckt ihr euch die zwei Sekunden, die ihr schon gesehen habt, noch mal an.
So, äh, so, das ist eine Sache, die funktioniert äußerst zuverlässig mittlerweile,
das ist ziemlich gut.
Ähm, allerdings, sagt das, auch, weil es hat Latency,
ihr müsst euch überlegen, so eine Playlist hat vielleicht 5 Einträge,
und jeweils 2-Sekunden-Schnipsel,
und selbst wenn man das runterdreht auf 500-millisekunden-Schnipsel,
sehen wir noch mal 5, man hat ordentlich Latency.
So, das Beste, was man machen kann, ist,
also, Neba, Neba HTTP 2 Live-Streaming und Geschütz, was Twitch mittlerweile macht,
das Beste, das Beste, was man machen kann, ist WebRTC.
Und, äh, meine aktuelle Software, das war ich euch gerade gezeigt im Browser,
die macht das Ganze auch per WebRTC,
die ist, äh, funktioniert ungefähr so,
ich habe einen FFmpeg laufen, also,
FFmpeg als Library, kein Kommando-Zeilen-Programm.
Und, äh, übrigens, weil ich im Chat jetzt ein paar Mal WebRTC gelesen habe,
WebRTC ist ziemlich beliebt für so Videokonferenz-Calls,
die meisten Videokonferenz-Sachen werden über WebRTC gehen,
WebRTC ist auch ziemlich easy, wenn man von Browser zu Browser das Ganze machen will,
weil die Implementierung gut ist.
Wenn man von einem Server-Backend zu einem Browser streamen will,
ist das schon ein bisschen komplizierter,
und glaubt mir, ich spreche aus Erfahrung, ich habe den Gramm selbst programmiert.
Also, ich, das ist nicht so schön.
So, es gibt auch nicht so viele Libraries zur Auswahl.
Weil die ursprünglichen WebRTC-Bindings von Chrome,
das ist irgendwie, fragt mich nicht, 50 Milliarden Zeilen C++-Code,
und das gebe ich mir nicht.
Aber WebRTC ist so ziemlich die beste Übertragungssache,
wenn man Low-Latency im Browser haben will.
So, und, ähm, aktuell verwende ich
diese WebRTC-Library, das ist in Go programmiert.
Allerdings ist meine Anwendung in sich in.NET Core,
und, ähm, deswegen suche ich die ganze Zeit schon nach einer.NET Core-Library,
die das Ganze machen kann.
Aber das ist so ziemlich die beste WebRTC-Library, die ich kenne,
äh, deswegen habe ich die halt verwendet.
Aber muss halt sagen, dass es ein bisschen eklig ist,
Go und.NET zusammen zu bringen.
Das geht nur über den Umweg von irgendwelchen C-Export-Geschichten und so.
Es geht, ich meine, sonst hättet ihr das Video eben im Browser nicht gesehen,
aber schön ist das Ganze nicht.
Deswegen war ich die ganze Zeit auf einer Suche nach einer.NET-Library,
die das kann, und ich habe vorhin, äh,
was entdeckt auf GitHub, das muss ich unbedingt mal ausprobieren,
nämlich den ganzen Kram hier, Moment, den da.
ZIP-Sorcery heißt ZIP, kann ZIP, interessiert mich aber nicht,
kann auch WebRTC, und WebRTC ist eigentlich das Interessante.
So, und wie das aktuell funktioniert, wie ich das mache mit der aktuellen Software,
ist folgendermaßen, ich nehme FFmpeg als Library,
ruf RTSP von den Kameras ab, das machen wir jetzt auch gleich im Stream.
Insgesamt wird das heute vielleicht 1-200 Zeilen, das wird nicht viel.
Einfach so mal testen, ob's geht, wenn's geht, ist gut, wenn's nicht geht, hab ich Pech.
Das ruft den Stream von den Webcams ab und decoded den Stream aber nicht.
Das ist grad der Witz an dem, was ich gebastelt hab.
Die ganzen anderen Video-Streaming-Lösungen, die machen erstens nix über WebRTC oder die wenigsten,
und die decoden und encoden den ganzen scheiß Bild rum.
Was heißt, du kannst da gar nicht mal wirklich viele Kameras auf so was wie einen Raspberry Pi laufen lassen.
Sondern was ich mache ist, ich nehm den Stream von der Kamera,
empfange den mit FFmpeg, aber ich decode den Stream nicht.
Ich kopiere mir einfach nur die einzelnen Pakete und schreib die dann quasi über WebRTC in den Browser rein.
Das setzt natürlich zwei Dinger voraus, dass die Kamera einen Codec verwendet, den der Browser versteht.
Und umgedreht, dass der Browser einen Codec unterstützt, den die Kamera verwendet.
Okay, so war's, wie es aktuell funktioniert.
Und mir geht's halt auf den Keks, dass ich so eine übelste Hybridgeschichte hab aus relativ viel Go und.NET Core, ASP.NET für die Web-Anwendung.
Das ist nicht schön, macht auch ab und zu mal irgendwelche MemoryLeak-Probleme.
Ich glaube, ich hab bei dieser Geschichte mehr MemoryLeaks gesucht, als die letzten zehn Jahre zusammen.
Weil gerade Go an sich ist ja kein Problem,.NET an sich ist auch kein Problem.
Aber wenn man da in Top macht, gibt's ein paar Problemchen ab und zu mal.
Manchmal crasht's auch random und man weiß nicht warum.
Das hab ich jetzt soweit alles hingekriegt, das läuft jetzt ziemlich stabil.
Aber es wär natürlich schön, wenn ich.NET Library verwende.
So, was ist eigentlich der Unterschied zwischen WebRTC und WebSockets?
Das sind zwei komplett unterschiedliche Paar Schuhe.
WebSockets ist... ist quasi... da muss ich jetzt erstmal...
Also normalerweise ist HTTP ist ja Response.
Also du schickst was hin und kriegst eine Antwort, fertig.
Also HTTP ist nicht... hat kein State in dem Sinn.
So, und da haben sie sich gedacht, okay, es wäre ja auch nicht schlecht,
wenn man quasi eine konstante Verbindung vom Server zum Client haben könnte.
Nicht nur Client Request Server antwortet, sondern auch,
dass der Server den Client benachrichtigen könnte, wenn sich was ändert.
So, irgendwelche Live-Notifications oder sowas.
So, und dafür ist WebSocket da. WebSocket ist eigentlich nur so ein Message-Protokoll,
was über lang laufende TCP-Sessions unter der Haube, die quasi ermöglicht,
dass du vom Server den Client benachrichtigen kannst, wenn sich was getan hat.
Das ermöglicht... das geht HTTP nicht.
Hat Max seinen WebSock schon gehört? Nee, was?
Das funktioniert... das ist so nicht gedacht mit HTTP.
Und mit WebSockets geht das Ganze.
So, und WebRTC ist noch was anderes. WebRTC ist in der Hauptsache
ein Protokoll für Audio-Video-Übertragung mit relativ geringer Latenz
vom Browser zu einem anderen Browser. Oder von einem Client zum anderen Client.
WebRTC kann zwar auch Messages übertragen,
das ist aber ziemlich große Überschneidung mit WebSockets,
wenn man da einfach nur Data-Channel-Text überträgt.
Dafür würde ich auch kein WebRTC verwenden. WebRTC ist eigentlich hauptsächlich für Audio-Video-Kram.
DollyJoker, fünf Monate. Dankeschön. Excellent Subscription.
Hast du schon mal was mit XMPP? Das ist Dings, wie heißt es?
Jabber, ne? XMPP. Nee, habe ich schon nichts gemacht.
Also, ich habe schon welche benutzt, aber nicht verwendet.
Genau, und das ist die Library, die ich aktuell benutze für WebRTC-Kram.
Das, was ich euch gerade im Browser gezeigt habe. Für die Kameras.
Und Interop sagt halt go.net. Deswegen habe ich mich sehr gefreut,
vorhin, als ich diesen Kollege hier entdeckt habe.
Nämlich, die Library scheint es noch gar nicht so lange zu geben, ehrlich gesagt.
Zumindest nicht mit WebRTC-Support, weil die ganzen Beispiele sind doch erst ein paar Tage alt.
So, und das ist wieder so ein komischer Livestream an Musik,
der sich nicht entscheiden kann, wie laut was ist.
Ich mache jetzt irgendwie mal sowas da an.
Okay, das wäre fast ein bisschen viel gechillert.
Okay, guck mal, ob das was taugt.
Deswegen habe ich mich echt gefreut, als ich vorhin die Library gefunden habe.
Die hat seit noch nicht allzu langer Zeit, würde ich sagen, WebRTC-Support.
Das sieht man nämlich daran, dass, wenn man sich die Beispiele anguckt,
die sind teilweise nur 5 oder 4 Tage alt.
So, und es gibt wirklich nur ziemlich wenig WebRTC-Libraries, mit denen man das machen kann.
Die besten sind im Browser eingebaut. Die funktioniert nämlich auch.
So, dann gibt es die eigentliche Chrome WebRTC-Implementierung.
Das ist, was weiß ich, eine Millionenzeile C++ oder sowas.
Dann gibt es noch das hier.
Es gibt irgendeine Python-Implementierung, die aber total viele Probleme hat mit H.264-encoded-Videos.
Und es gibt das hier. Ansonsten gibt es nicht allzu viel.
Also das ist wirklich nice.
Wenn ihr mal was anderes kennt, sagt Pride, ich kenne nur diese paar.
Und das hier ist mit Abstand die beste Implementierung.
Diese haben auch am einfachsten zu benutzen.
Aber wenn man nicht komplett alles in Go macht, ist es ein bisschen eklig.
Dazu kommt, dass man für Audio-Video-Zeug sich Go an sich gar nicht so sehr anbietet,
weil Go ziemlich mies ist, wenn es um Zusammenarbeit mit C-Libraries geht.
Und wenn man Audio-Video-Zeug macht, gibt es zwei Sachen.
Es gibt G-Streamer und es gibt FFmpeg. Und das ist beides in C.
Das heißt, wenn ich Go benutze für Audio-Video, muss ich permanent VLC...
Ja, VLC ist was eigenes, aber mit FFmpeg dabei.
Also die haben FFmpeg noch zusätzlich dabei für das, was sie nicht selbst können.
Aber hauptsächlich ist es G-Streamer und FFmpeg.
Ich glaube mir, außer VLC fällt mir ehrlich gesagt keine Software an, die VLC als Library verwendet.
G-Streamer ist tatsächlich im Profi-Umfeld recht beliebt, habe ich mir sagen lassen.
Keine Ahnung, kann ich weder bestätigen noch was dagegen sagen.
Aber FFmpeg ist ansonsten in so ziemlich jeder Software, die Videos abspielt
und die nicht unter Only-Windows läuft, ist FFmpeg am Werk für Videos.
Oder G-Streamer.
Genau, und der Interop zwischen Go und C ist halt ein bisschen lahm und auch eklig.
Deswegen ist Audio-Video in Go halt doof, weil die größten Libraries eben in C sind.
Excellent, aber bevor ich jetzt lange labere, wir fangen jetzt mal an.
Da wird es glaube ich relativ klar, was ich mache.
Ich brauche wieder mal ein Test-Video.
Wo ist das Test-RTSP hier, den da?
Den verwenden wir wieder zum Testen, den Stream.
RTSP-Stream.
Huge-Quali-Stream, aber ist egal, wenn das Video läuft, dann läuft es.
Also, Go ist eine super Sprache im 079.
Also, bis auf ein paar Sachen, die mir echt auf den Keks gehen.
Aber sicher ist Go cool.
Wenn man aber Interop zu anderen Sprachen braucht, ist Go nicht so gut.
Also, wenn man in Go Libraries verwenden will, die es eben nicht in Go gibt, dann ist es nicht so schön.
Dann ist es sogar in Python theoretisch schneller, wenn du C-Interop machen willst.
Dafür ist der Rest nicht sonderlich gespint.
So, also.
Ach nee, Moment, ich wollte ja noch die IDEs aktualisieren.
Coolbox.
Oh, excellent.
Excellent. 1KS, was ist das jetzt?
Warum startet meine Jetplanes Toolbox nicht? Was ist denn das?
Hallo? Toolbox starten, please.
Ich bin verwirrt, warum geht das nicht?
Ich will einfach nur mein Zeug updaten.
Weil ich, what?
Und, ah, ich habe bestimmt Kernel updaten. Ich reboote mal. Reboot hilft immer.
Excellent, Reboot.
Das ist fast schon Windows-Taktik. Geht es nicht dran, Rebooten für eine Runde?
Ich glaube, ich habe ein Kernel-Update gemacht, ja.
Deswegen meckert er auch wegen irgendwelchen Modulen.
Also, ich muss dir ehrlich sagen, also das, was ich, ich muss mal den Chat aufmachen,
dass ich dann zwischenzeitlich mal ein paar Sachen besprechen kann.
Also, das, was der Imp schreibt, ist auch eine Sache, da steht man öfters mal davor.
Wenn man eine Weile aktiv ist, hat man sich so die einzelnen Sachen schon zusammengescriptet,
die man öfters braucht. Da steht man auch öfters mal davor und muss sich überlegen,
programmiert man das irgendwie mal ordentlich neu in einer anderen Programmiersprache.
Und ich bin für mich bisher zu dem Schluss gekommen, nee, ich lasse alles, wie es ist.
Weil ich habe schon viele Sachen versucht, neu zu basteln und bis die neu gebastelten Sachen so gut sind wie die alten Sachen,
der Aufwand lohnt sich meistens nicht.
Deswegen lasse ich meine eklichen, gehackten Sachen auch ekliche, alte, gehackte Sachen sein
und mache manche Sachen vielleicht mal neu, aber nur, wenn mir neue Ansätze zu einfallen, sonst lasse ich es dann.
Außerdem ist das schöne an Bash, du kannst halt überall drauf ausführen.
Alles Geschmackssache. So, mal gucken, ob jetzt das mit der Toolbox geht,
ob ich jetzt updaten kann. Ah, jetzt, jetzt. Java, geht.
So. Die können sich nicht entscheiden, wie laut der Stream ist hier.
Ich lasse es jetzt einfach mal so.
Browser Extension, nein. Also wir aktualisieren mal die ganzen Ideen.
Und dann legen wir los, weil es ist schon 22 und 22.
Aber wie gesagt, es gibt nicht viel. Also es gibt nicht viel Code da.
Ich denke mal, es gibt am Ende vielleicht, was weiß ich, 50 Zeilen HTML und irgendwie 200 Zeilen.NET.
Mal gucken, mal gucken. Schauen wir mal.
Guck mal bitte im Discord unter Memes, da hat hier mal ein Beat unter einen Soundschwipsel von dir gepackt.
Okay, das gucken wir gerade nochmal kurz.
Aber Chat, ich muss euch schnell ausmachen, nicht, dass ich im falschen Channel bin.
Man weiß ja nie. Und Discord geht ja immer in den Channel.
Nicht, dass ich da oft gucken würde oder so, aber ja, man weiß nie.
Man weiß nie. Okay, also ich bin im richtigen Channel.
What the fuck ist denn das hier? Warum ist hier Pokémon am Start?
So, wo muss ich hin?
Das mache ich mal kurz zu hier. Wie kann man das nicht zu machen?
Wo muss ich hin? Memes?
Memes?
Das hier?
What the fuck ist das?
So schnell? Oh Gott.
Ein wahres Meisterwerk.
Oh Mann, kommt da noch was anderes?
Kommt da noch was anderes? Ja, das ist ja nice. Ein wahres Meisterwerk.
So, wir haben geupdated. Gut, jetzt können wir loslegen.
Oh, das ist doch so bescheuert. Evaluate, wir evaluieren.
Zum Glück, zum Glück kann ich meine, meine Trial fortsetzen.
Okay, also, what?
What?.NET Core Web Application. Eine Web API Application. Die nennen wir, wie nennen wir die jetzt? Monac-S.
Oh, komm wursch, wieder Kram-HR-Store, bla, bla, bla, bla, noch Authentification, alles gut, alles richtig.
Anlegen, Terminal mal aufmachen, hier ohnehin schieben. So, zack.
Warum ist der Schrift so klein? Das ist ja, da sieht es ja gar nichts. Hat er meine, hat er meine Settings vergessen oder so?
Font? Wo ging das nochmal? Font, Appearance, Font Size?
Ich finde das voll versteckt. Editor Font?
Font? Ah ja, hier. Ich finde das übelst versteckt bei diesen JetBrains Sachen, immer die für Farben und Schriftgröße und so.
Hack brauchen wir. Hack 16. Hack 18? Hack 18, Hack 18, ist gut. Ja, okay.
Warte mal, bitte. Ja, exzellent. Wir können es nochmal, wir können es nochmal eine Stufe größer machen.
Und mal 19. Ja, okay, ja, jetzt erkennt man es doch eigentlich ganz gut. So, Rider Projects Monarchs.net Watch Run.
Ach so. So, jetzt machen wir mal hier einen Browser auf. Ich mache mal einen Chrome auf und gucke, ob die Seite da ist.
Local Host 5000. Ach, das hat Redirect auf, hat SSL. Okay, das müssen wir erstmal alles abstellen. Also, Authorization weg, KTPS Redirection weg. Brauche ich keinen Mensch.
Dann legen wir noch einen Ordner für die Webseite an und machen schon mal eine leere Webseite rein. Dann können wir loslegen.
Directory www root. So, dass der die Fileserver, dass er die Webseite ausliefert, aus dem, statische Webseite aus dem Ordner ausliefert.
Gibt es denn was zu den Grafikkarten von AMD? Ich weiß nicht, ob sich, ich meine, soll ich? Ich meine, kann ich machen.
Ich weiß nicht, ob das so spannend wird, ehrlich gesagt. Kann ich, ich meine, kann ich machen. Wann ist denn das? Donner, Mittwoch? Der Stream? AMD?
AMD? AMD gerade ein bisschen blablabla. Radiant Reveal. Da, 28.10. Um wie viel Uhr? 17 Uhr. Ja, können wir machen, aber ich weiß nicht, ob es so spannend ist.
Ich habe da nicht so große Hoffnung, ehrlich gesagt, drin, dass die bei AMD da was vorstellen, was Nvidia Konkurrenz macht. Aber man weiß ja nicht.
So, legen wir erstmal eine Webseite an. Irgendwas. Index html. Und da schreiben wir jetzt drauf. Test 0w. So, und gucken, ob das funktioniert.
Live Server starten. Da ist er. Eine Runde 0w. Beste hübscheste Seite aller Zeiten. So, da können wir einmal anfangen.
Ich würde sagen, als erstes müssen wir die Library einbinden, dass wir das ausprobieren können. Also wir brauchen als Library einmal das da. Das brauchen wir nämlich für WebRTC und wir brauchen FFmpeg für die Webcam Videos.
Exzellent. Da. Jawoll. Aktuelle Testversion. Von was lesen die? Testversion? Releases? Wo stehen Releases? Manchmal finde ich mich auf GitHub irgendwie nicht zurecht.
Sollten nicht die Releases drunter stehen? Hier, guck mal. Also die sind wohl gerade ganz aktuell dabei, was das angeht. Wenn es die letzte Testversion vor 5 Tagen gegeben hat, dann ist auch der WebRTC Support noch relativ neu.
Ich bin auch übelst verwirrt. Wisst ihr, was mich bei GitHub, bei dem GitHub, die es sein am meisten verwirrt? Das Releases manchmal rechts stehen und manchmal unten.
Früher war das relativ einfach, da hast du Releases immer hier oben in der Leiste gehabt. Musstest du früher noch auf Code klicken? Ich weiß, du hast die Releases immer in der Leiste gehabt. Die hast du einfacher gefunden.
So, also installieren wir mal die Library. Install. Das ist die, die ich ausprobieren will. So, und dann brauchen wir noch FFmpeg. Ohne FFmpeg geht nichts, was Video, Audio und Webcam angeht.
Zack, FFmpeg. Gut, da haben wir unsere Abhängigkeiten dabei. Die Murke ist gut, na dann. Ich habe die mal auf gut Glück angemacht, das ist hier der Stream.
Ich hoffe, ich komme jetzt nicht gleich hier DMC, Dingsbums, Takedowns oder so, weil ich irgendeinen Stream laufen habe. Aber ich glaube, das ist Musik, die ist nicht so im Fokus der Stonks anwältend.
So, also wir machen jetzt erstmal die Webseite, soweit, dass ich was sehen würde. Also wir brauchen einen Videoplayer ohne Stonks, weil die Stonks setzen wir später aus dem JavaScript raus.
Da kann ich wieder meine Huge Massive JavaScript Skills walten lassen. Übrigens, das hier wird sich wahrscheinlich jeder JavaScript Mensch, wird sich sagen, Max, was macht er da? Aber ich kenne keinen besseren Weg, wie ich in JavaScript, in meinem Script Tag eine Assungfunktion verwenden kann.
Wenn da einer von euch eine Ahnung hat, dann sagt mir Bescheid, ich weiß nix besseres. Ich weiß, dass das nicht sonderlich JavaScript Style ist.
So, also, wir haben einen Videoplayer, der macht Autoplay, der kriegt Controls und ist standardmäßig Muted. Wenn ihr mal eine Anwendung, oder wenn ihr mal was programmieren solltet, mit dem Videoplayer Element, und ihr wundert euch, dass ihr, par auf, Leute, jetzt kommt Massive Tip, das Problem hatte ich nämlich auch schon öfters.
Und ihr wundert euch, dass auf mobilen Geräten euer Video nicht funktioniert, dann liegt das daran, dass ihr es nicht gemuted habt.
Weil die ganz alle Mobile Browser, oder mir fällt jetzt kein Mobile Browser an und weder Android noch IOS macht das so. Die spielen nur Videos ab, wenn sie gemuted sind. Wenn Videos nicht, also wenn Video Element nicht gemuted ist, spielt es weder Android noch IOS ab. Also wenn ihr mal was bastelt und ihr fragt euch, warum irgendwelche Sachen nicht abgespielt werden, dann weil ihr es nicht gemuted habt.
Ansonsten funktioniert's, aber ist ja auch verständlich, weil keiner will auf eine Webseite gehen, erst mal angeschrien werden von 30 Werbesachen.
SQL WebSockets Lego, was soll denn SQL WebSockets sein? Also SQL ja, WebSockets ja, aber WebSockets haben doch mit SQL gar nichts zu tun.
Wie gesagt, wenn ihr keine Library findet, um direkt auf eure Datenbank zugreifen zu kommen, macht GraphQL davor, das ist das einfachste, was du machen kannst mit Webrequests.
Aber WebSockets ist für Kommunikation vom Server zum Client gedacht, um dass der Server den Client benachrichtigen kann. Inwieweit das jetzt was bringt bei eurer Datenbank, kann ich schlecht beurteilen.
Oh, der Tanzer hat BigBrain. Leute, ich hab mir übrigens was überlegt für den Chat. Wir haben ja manchmal schon richtig krasse BigBrain Antworten im Chat gehabt.
Und ich werd das jetzt so machen, wenn es irgendwelche exquisite BigBrain Antworten gibt. Es gibt jetzt so einen VIP-Tag, hab ich gesehen, auf Twitch.
Da hab ich mir überlegt, dass ich für einen Monat einfach den BigBrain Antwort Leuten einen VIP-Tag gebe. Man hat da nix von, aber es sieht cool aus.
Und vielleicht hat man ja Glück und man kann diesen VIP-Tag sogar customisieren, dann kriegen die einen BigBrain Emote.
So, also Moment, der Chat hat gerade Folgendes geschrieben, ich soll das hier machen.
Ok, das klingt logisch, dass das funktioniert. Das klingt, es sieht zwar ein bisschen hässlich aus, aber das sollte funktionieren. Guck mal mal in die Konsole rein, ob das, ja das funktioniert.
Also ich versuch jetzt mal zu erklären, was das macht und dann sagt ihr mir, ob ich richtig liege.
Also das da ist einfach nur ein Block quasi in JavaScript, der keine tiefere Funktion hat.
Also wahrscheinlich brauch ich das, um das zu gruppieren irgendwie, oder geht das auch so? Nee, das geht nicht.
Also das ist irgendwie so eine Blockgeschichte in JavaScript oder sowas, was auch immer.
So, das hier ist der Async-Keyword. Das da ist, dass das eine Funktion ist, die keine Parameter kriegt.
Das hier ist ganz normales Lambda-Arrow-Dingsgedöns. Das ist der Body von der Funktion.
Und der macht Log 1, 2, 3, Kappa 1, 2, 3 in Chat auf die Konsole. Und das hier ist, dass die Anonyme Funktion direkt ausgeführt wird, wenn ich das richtig verstehe.
Wenn ich das richtig verstehe.
Es sieht aber nicht gerade schön aus, muss man sagen.
Ist korrekt.
Nice.
Liko, dafür ist WebSockets das Beste, was ihr machen könnt. Ich kann dir noch was, je nachdem, was ihr als Backend verwendet.
Solltet ihr mal.NET verwenden als Backend, würde ich euch empfehlen, anstatt WebSockets gleich das dazu verwenden.
Das ist quasi der Microsoft-Aufsatz auf WebSockets. Die ein paar Sachen abnimmt. Aber ansonsten ist WebSockets absolut Standard und funktioniert wunderbar.
Unsere Webseite ist schön hässlich und funktioniert. Eine Sache machen wir nochmal. Style für das Videotag. Höhe 100, Breite 100. Das reicht.
Das reicht. Exzellent. Fullscreen Video-Player. Vielleicht soll ich die Höhe mal weg, gleich mal nur die Breite. Nee, das geht gar nicht. Die Höhe. Nur die Höhe.
Na ja, was auch immer.
Das wird schon passen. Was? WV habe ich doch. Ah, VW. Jaja, richtig.
Ah ja, jetzt passt es. Jetzt ist es auch nicht breiter. Okay, exzellent. Jetzt haben wir unsere Videoplayer da.
Ja, also mit Blazer, da bin ich ja mal gespannt. Wir haben das mal ausprobiert vor einem Jahr oder so. Da gab es noch richtig viele Probleme.
So mit JavaScript aufrufen und sonst was. Mittlerweile gibt es weniger Probleme. Ich habe letztens erst einen Webcast drüber gesehen.
Aber die haben immer noch das Problem, dass halt die.NET Runtime runtergeladen werden muss. Und das ist halt irgendwie 8 MB.
Und wenn du 8 MB runterladen willst, dann ist es ja schon quasi wie als letzter Halb Facebook inklusive einem JavaScript runter.
Was möchtest du programmieren? Also ich habe ja aktuell so eine Videoüberwachungssoftware gebastelt mit WebRTC,.NET und Go zusammen.
Go, weil die einzig sinnvolle WebRTC Library, die gut funktioniert hat, in Go programmiert ist..NET und Go Interop suckt allerdings.
Und ich habe heute eine Library entdeckt, die WebRTC in.NET macht. Und da bin ich aber echt gespannt drauf.
So, jetzt müssen wir folgendes machen. Als erstes machen wir mal den FFmpeg-Teil, weil der FFmpeg-Teil ist easy.
Den FFmpeg-Teil habe ich schon oft gemacht, da weiß ich, wie es funktioniert. Wir brauchen unseren RTSP-Teststream, den da.
Normalerweise, by the way, macht man das nicht so. Ich sage es gleich. Normalerweise macht man nicht hier in diesem Startup-File von der Web-Anwendung irgendwelche großartigen Background-Io-Audio-Video-Geschichten.
Da machst du normalerweise einen eigenen Background-Dienst, den du hier nur startest.
Kann ich auf die Test-Seite? Das können wir tatsächlich machen. Ich habe doch noch irgendwo einen Hetzner-Server rumstehen, da kann ich das mal draufpushen.
Da könnt ihr dann drauf gehen und gucken, wie toll Latency-Free das funktioniert.
So, also. Wir machen mal eine Funktion hier für FFmpeg.
Wieso ist Kappa Gold? Oh, das ist ein ganz schlechter Chebat.
Ich glaube, das ist eine FFZ-Geschichte, oder?
Dass Kappa Gold ist.
Mein Kappa ist wirklich Gold. Warum ist... Warum ist der...
Also, es gibt ja manchmal einen goldenen Kappa, aber ich glaube nicht, dass ich den abkriege.
Es gibt ja manchmal goldenen Kappa, random in irgendwelchen Channels, aber ich glaube nicht, dass der bei mir gerade im Channel wirklich ist.
Golden Kappa.
Der ist gerade überall, ja. What? Okay, wir müssen jetzt mal hier loslegen.
Okay, also wir machen jetzt erstmal den FFmpeg-Part. Den FFmpeg-Part weiß ich, wie es halbwegs funktioniert.
Ich sage halt nur dabei, normalerweise macht man einen Background-Service. Ich mache es jetzt testweise hier einfach mal im Start-up.
Also, wir starten den Hintergrund-Thread, weil diese Audio-Video-Geschichte, die muss natürlich im Hintergrund laufen.
Ich kann jetzt nicht einfach hier in meinem Programm nebenbei Webcams abrufen.
Also, wir starten jetzt hier mit irgendwas. Wobei, nee, wir machen es ganz anders.
Wir machen hier unten irgendeine Funktion. Public... Public...
Cube. Bester Name aller Zeiten.
Loop. So, und dann starten wir das hier in einem eigenen Thread und gut ist Loop. Bester Name.
Also, wenn das nicht mal hier Expressive hoch 10 ist, dann weiß ich auch nicht.
Was? Enter Completed Insert Newline.
Ja, okay, was auch immer. Also, ich finde Loop ist ein sehr guter Name dafür.
Excellent. Exquisite Name. So, und den müssen wir den mal mal Private und den mal mal Unsave, weil...
Unsave. Wir müssen das Ganze Unsave machen, weil das ist C-Code und C-Code aufrufen ist Unsave.
Und damit das Ganze funktioniert, müssen wir dem hier sagen, irgendwo hier... Oh, wo ist das denn Rider versteckt?
Hier Allow Unsave Code. Excellent.
Normalerweise erlaubt das C-Sharp nicht, weil da kann es ja alles Mögliche machen und Sachen kaputt machen und Speicher kaputt machen und sonst was machen im Hintergrund.
Aber das muss halt einschalten. Normalerweise ist es so gedacht, dass man Unsave nicht in seinem Hauptprogramm verwendet, sondern dass man Unsave quasi in der eigenen Library rappt.
Aber gut, wir müssen FFmpeg verwenden, da bleibt einem nichts anderes übrig.
Also, jetzt legen wir... Das ist die Adresse zum Stream.
Wie ich es noch im Clipboard-Manager habe.
So, also das ist die Uhr von unserer Testwebcam. Ich sag mal stellvertretend Webcam. Es ist zwar ein Video-Stream, aber es ist ein RTSP-Video-Stream. Das ist das, worauf es ankommt.
Ich hab doch irgendwo was, wo ich ein bisschen abgucken kann. Da muss ich den Kram nicht neu machen, weil FFmpeg hab ich schon öfters gemacht.
Genau, ha, ich hab was, ich hab was gefunden. Exquisite, da kann ich jetzt abkopieren. Nice.
Ich cheat jetzt, ich kopiere was aus einem anderen Projekt. Bam.
Da weiß ich nämlich, dass es funktioniert mit Video-Abrufen.
So, also das Ganze müssen wir starten, das haben wir gestartet.
FFmpeg, Context. So, also ich erklär auch gleich, was es macht.
Also, FFmpeg kennen die meisten von euch wahrscheinlich.
Das kennen die meisten von euch wahrscheinlich als Kommando-Zeilen-Tool, FFmpeg.
Alternativ kennen vielleicht manche auch FFplay oder FFprobe, aber das ist alles FFmpeg.
Und viele Formate, die VLC abspielen kann, kann VLC auch nur wegen FFmpeg.
Äh, übrigens, ich muss die Einrückung ändern, das ist viel zu viel Einrückung hier.
Wie macht man das im Rider nochmal? Tabs? Tabs? Nee.
Indent? Hier? Nee.
Unten rechts? Ah, exellent, exellent.
Hier, also. Indent, Intent, in zwei und zwei. Zack.
Und jetzt sagen wir Reformat. Haha.
Gleich, oh, das ist doch schon ein FFmpeg.
Und jetzt sagen wir Reformat. Haha. Gleich, oh, das ist doch schon viel besser.
Wie ist bei euch? Vier Spaces oder zwei Spaces?
Aber unabhängig von der Sprache, was ist euch lieber?
Vier? Zwei? Vier? Okay, viel mehr machen vier, hätte ich jetzt gar nicht gedacht.
Aber gerade in so Sprachen wie C-Sharp, wo halt auch öfters mal mit Curly Braces um sich geschmissen wird,
dann spart das unglaublich Einrückungstiefe. Also ich finde zwei viel praktischer.
Fünf? Okay, fünf ist exotisch. Oder vielleicht war es auch G-Bait.
Oder wir machen einfach alles in eine Zeile.
Genau, keine Zeile. So, also was das hier macht, ist Folgendes.
Das ist die Uhrl zu unserer Webcam. Zu unserem Testvideo in dem Fall.
Das hier setzt ein Timeout. Wenn fünf Sekunden lang keine Antwort mehr kommt,
dann bricht er das Ganze ab, weil sonst haben wir, bleiben wir hängen.
Sackt. So, das ist FFmpeg-Intent.
Das braucht man nicht. Und das hier startet den Stream von dieser Uhrl.
AV-Format Open Input, da übergibt man einen Kontext.
Das ist so ein internes FFmpeg-Ding und die Uhrl für den Stream.
Und das war es im Endeffekt, was man in FFmpeg machen muss, um Stream zu öffnen.
Jetzt muss man, das war natürlich jetzt ein bisschen zu spät.
Man muss natürlich den Stream noch auslesen.
Brauchst du noch Rainbow-Prakets? Gibt es das für Ryder?
Also in Visual Studio Code habe ich Rainbow-Prakets.
Ich habe keine Ahnung, ob es hier Rainbow-Prakets gibt, aber wahrscheinlich als Addon.
Aber brauche ich nicht unbedingt.
So, okay. Was der macht, ist, der guckt, ob er den Stream öffnen kann.
Wenn er den Stream öffnen kann, dann kann er den Stream öffnen.
Wenn er den Stream nicht öffnen kann, dann wirft er einen Fehler.
So, next.
Jetzt gucken wir erstmal, ob das ein gültiger Stream ist.
Ich copy-paste, das ist nicht so, dass ich hier der ultra-mega-schnell-Hackster bin.
Ich copy-paste das gerade aus einem anderen Projekt, weil ich bilde mir ein, das hat funktioniert.
So, weiter.
Jetzt gucken wir erstmal, ob der irgendwelche Metadaten vom Stream lesen kann.
Wunderbar, ich glaube, das brauchen wir gar nicht.
So, und jetzt kommt was, was ich immer gerne vergesse, wenn ich das neu bastle.
Und zwar, man muss schauen, ob es einen Videostream überhaupt gibt.
Weil es gibt ja durchaus RTSP-Streams, die audio-only sind.
Deswegen muss man gucken, ob es einen Videostream gibt.
Und das hier guckt, ob es einen Videostream gibt.
Der loopt alle Streams durch, die es gibt, und guckt, ob der Media-Type Video ist.
Und wenn es einen Videostream gefunden hat, dann setzt den, und ansonsten sagt er, no Videostream-Forten geht raus.
Was wird das?
Ich probiere eine Web-RTC-Library aus, die ich heute auf GitHub gefunden habe,
mit der man zum Beispiel Webcams oder Überwachungskameras sich mit ziemlich niedriger Latenz in den Browser streamen kann.
Ich habe sowas schon mal gebaut, allerdings in.NET und das Web-RTC-Zeugs in Go.
Und nachdem der Interop zwischen Go und.NET nicht so schön ist, wollte ich mal so eine.NET-only-Lösung ausprobieren.
Mal gucken, wie gut das funktioniert.
Ok, also Videostream haben wir. Jetzt muss man das da machen.
Alles klar. Also wir gucken jetzt, ob es in dem RTSP-Stream einen Videostream gibt.
Wenn es einen Videostream gibt, machen wir weiter.
FFPlay, ich glaube, das kann man sich an der Stelle auch sparen, wenn man Open gemacht hat, aber machen wir mal.
So, und jetzt sagt er mir Connected zur URL von der Webcam oder zum Videostream.
Und jetzt kommt das eigentliche Auslesen dran.
Da braucht man nämlich eine... Ups, ich habe etwas vergessen.
Und hier unten muss ich noch Unref machen, dass es wieder weg ist.
Und hier ist dann Zeug machen mit Videoframes.
So, genau, also hier öffnet er den Stream und sucht sich den Videostream raus aus dem RTSP-Stream.
Und hier macht er eine Endlosschleife, die immer wieder ein neues Paket anlegt.
Das kann man übrigens auch optimierter machen, man muss das gar nicht immer neu initialisieren, kann es darüber schreiben.
Und hier liest er jetzt quasi ein Frame nach dem anderen von der Quelle.
Ist es eigentlich irgendwie möglich Twitch-Streams als RTC oder ähnliches zu bekommen?
Direkt wahrscheinlich nicht, aber ich meine, du kannst... Kann FFmpeg Twitch?
Müssen wir mal schauen. Kann FFmpeg Twitch? Wahrscheinlich nicht.
Ich meine, Twitch war mal HLS, aber ich glaube mittlerweile ist Twitch irgendein HTTP2-Streaming.
Nein, okay, FFplay kann kein Twitch. Wenn FFmpeg das gekonnt hätte, dann hätte es das umwandeln können.
So, und der liest jetzt endlos lang diesen Input hier von diesem Stream, von diesem Test-Video.
Und liest quasi ein Frame nach dem anderen aus und wirft ihn wieder weg.
Und hier kann ich dann später den Kram... Guck mal, es funktioniert! Habt ihr das gesehen?
Ganz nebenbei, das Connecten zum Stream funktioniert schon mal.
Ich kann euch ja sogar mal beweisen, dass es funktioniert.
Wir lesen jetzt mal ein paar Sachen aus den einzelnen Video-Frames aus.
Zum Beispiel... PTS.
Übrigens, Audio-Video-Sachen ist wirklich eine richtige Wissenschaft für sich.
WTF? PTS sollten niemals negativ sein?
Und wie geht das? Ich guck doch, ob es kleiner Null ist und wenn es... Ach nee, oder muss ich hier machen.
Das ist ja schon erst ein Bug gefunden.
Aber der Timestamp sollte immer positiv sein. WTF?
Okay, der buggt einfach nur am Anfang ein bisschen rum, glaube ich.
Aber... Also, um immer ein bisschen Licht ins Dunkel zu bringen, wie das unter der Haube mit Videos funktioniert.
Jeder Video-Frame hat zwei Timestamps drin.
Es ist jetzt Big Brain und muss man wahrscheinlich eigentlich gar nicht wissen, es sei denn, man macht was mit Audio-Video-Kram.
Jeder Frame von einem Video hat zwei Timestamps. PTS, DTS.
Meine Frage an den Big Brain Chat, hat irgendjemand eine Ahnung, was der Unterschied ist?
Ich werde es auch gleich erzählen. Aber nur, man würde mich interessieren, ob vielleicht irgendwelche Leute haben, die das zufälligerweise wissen.
Also, wenn du Audio- und Video-Coding studierst, dann musst du das wissen.
Oder sollte man das wissen? Müsstest du das wissen, was der Unterschied ist zwischen PTS und DTS?
Also, P steht für Presentation Timestamp und DTS steht für Decoding Timestamp.
Das bedeutet, es kann sein, dass Frames decoded werden, zu einer Zeit, wo sie noch nicht angezeigt werden sollen.
Wenn das der Fall ist, muss man irgendwie einen eigenen Buffer konstruieren.
Von, sagen wir mal, 2-30 Sekunden oder von, was weiß ich, 100 Frames oder was auch immer, wie viel man braucht.
Und dann muss man quasi decoden. Also, DTS muss eigentlich immer fortlaufen sein.
Aber es kann durchaus sein, dass man Frames decoded, bevor sie angezeigt werden sollen, in der unterschiedlichen Reihenfolge.
Das heißt, man muss dann quasi erstmal ein bisschen buffern und gucken, dass man quasi die Timestamps bekommt für die Presentation-Time.
Also, PTS-Presentation-Timestamps ist das, was der Videoplayer anzeigen soll und DTS ist, was der Decoder decoden muss.
So, und meistens ist das das Gleiche, aber das muss nicht so sein.
Wieso heißt das Projekt Startup? Nein, das Projekt heißt nicht Startup.
Das ist das Standard ASP.NET Core-Template. Die Datei heißt halt einfach so.
Und wir können mal gucken, ob die hier bei dem Video immer gleich sind. Wir machen mal tolles Printline-Debugging.
Und schauen wir mal, ob die Presentation-Decoding-Timestamps immer gleich sind hier.
Ja, guck, hier sind die immer gleich.
Aber das muss nicht so sein. Das hier heißt im Prinzip nur, dass sobald ich den Frame decoden bekomme, kann ich ihn auch weiter schicken, weil der ist dann schon in der richtigen Reihenfolge.
Sollte Decoding-Timestamp und Presentation-Timestamp abweichen, dann muss ich erstmal ein bisschen sammeln, bis ich alles beisammen habe, was ich brauche, um es in der richtigen Reihenfolge anzuzeigen.
Aber das soll heute nicht unser Problem sein. Ich mach das auch mal wieder raus.
So, also Video Decoding funktioniert schon nochmal. Jetzt kommt das nächste.
Muss ich mal kurz abgucken, wie man so einen komischen ASP.NET Controller genau macht.
Also, jetzt müssen wir eine WebRTC-Verbindung aufbauen vom Browser zu meinem Backend hier.
Was macht eigentlich deine Heizungssteuerung? Der geht's gut.
Ich weiß, ich hab euch auch noch nichts von meiner Heizungssteuerung erzählt, aber versprochen, das mach ich nächstes Mal.
So, lass mal überlegen, was brauchen wir denn sonst noch?
Wir machen mal eine Sache. Ich will mal gucken, ob ich Memory Leaks hab. Leute, verwendet jemand von euch Rider und hat irgendeine Ahnung, wie man dort anzeigen lassen kann, während man hier ein Programm drüber laufen lässt, wie viel Speicher das gerade verwendet?
In Virtual Studio ist das immer rechts oben. In Rider hab ich keine Ahnung, wo das steht.
Wenn ich hier zum Beispiel Debuggen anmache, ich bin zu doof für den Speicherverbrauch zu sehen.
Keine Ahnung, wo der ist. Deswegen machen wir einfach mal was anderes.
Ich mach mir einfach nen Task, der mir alle 5 Sekunden den Speicherverbrauch ausgibt.
Aber das ist bestimmt nicht Sinn und Zweck, da sag ich, ich bin bloß einfach zu dumm, zu wissen, wo das im Rider ist.
Übrigens kann ich das auch mal rauskopieren, das hab ich ja auch schon zufälligerweise.
Ach nee, Mist. Wunderbar.
Was macht der Rider? Memory? Ja, der zeigt, wenn du Breakpoints hast, zeigt der Variablen an.
So, jetzt krieg ich alle 5 Sekunden mein, okay, Programm braucht 149 MB. Das ist für ne Web-Anwendung backend okay.
Stand da nicht rechts beim Debug-Fenster? Was? Echt? Moment, wo?
Hier, das? Nee, also da ist nix drin.
Ich seh, also ich seh hier wirklich, in Visual Studio ist es hier rechts oben immer, aber in Rider, keine Ahnung.
Letztendlich ist auch wurscht, ich lass es einfach hier unten ausgeben. Printline, also wir haben jetzt hier 148 MB.
Ist ein extra Plugin, den sich dottrace, ernsthaft, er braucht ein extra Plugin für? Aber das reicht jetzt erst mal.
So, gut, jetzt kommen wir nämlich mal zur eigentlichen Geschichte. Wir müssen eine WebRTC-Verbindung aufbauen, um das Video zu übertragen.
Ich überleg grad, ich glaube, wir haben alles, was wir brauchen, erst mal eingerichtet. Ach nee, eine Sache, ich sehs hier nämlich grad in meinem, in meinem anderen Projekt, das ist ne Sache, die mach ich immer gerne.
Die haben es ja so gemacht, früher haben die für ASP.NET immer diese Newtonsoft-JSON Library verwendet, die haben sie nicht mehr drinne, sie haben jetzt ne eigene, die schneller ist, aber irgendwie verwende ich die trotzdem noch lieber, deswegen füg ich die jetzt einfach mal wieder hinzu.
Da kann ich auch einstellen, dass E-Names keine Zahlen sind, sondern richtige Namen und sowas, das mach ich immer gerne. Und ich glaub, die Performance, da kommt's jetzt echt nicht drauf an.
Oh, was hat er für Schmerzen? Ach genau, ich muss ja erst mal adden. Äh, Moment.
Ja, auf JSON. Nee, Moment, was, was muss ich adden? Äh, ähm, MVC, JSON, das da muss ich glaub ich adden, aber keine Testversion, sondern ne echte.
Ne echte. Okay, exellent. Gut, jetzt können wir loslegen. Also, wir missbrauchen mal diesen Standard-Wetter-Vorhersage-Controller und benennen den um.
Den nennen wir mal ein Signal-Controller und machen diesen ganzen anderen Schmodder hier unten weg. Wetter-Vorhersage löschen wir auch, braucht kein Mensch. So, und das machen wir auch leer.
So. Also, das funktioniert folgendermaßen, eine WebRTC-Verbindung aufzubauen. Das ist ja was, da kenn ich mich ein bisschen mit aus, weil das hab ich jetzt schon ein paar Mal gemacht.
Also, ich krieg das ungefähr gebacken, wie man eine WebRTC-Verbindung aufbaut aus dem Browser.
Das erste, was man machen muss, ist, das hier ist quasi unser Main in die AVA-Skript. Also, unser Ziel ist jetzt, wir bauen eine Verbindung zum Backend auf.
Ähm, und das Backend schickt uns dann die Videoframes von der Kamera, die es hier unten abruft, in den Browser. Soweit die Theorie, wenn alles funktioniert.
Ich, ich hab ja meine Zweifel, weil ich weiß noch, was es für ein unglaublich ekliges Rumgefuddel war, bis ich das das erste Mal zum Laufen gebracht habe.
Aber ein Vorteil hat's, ich weiß jetzt, was man machen muss, so ungefähr. Vielleicht krieg ich das hier besser, krieg ich das besser hin.
Aber krieg ich das besser hin. So, was ist der Unterschied, was ist der Unterschied in AVA-Skript, ob ich var, let oder gar nichts verwende oder const.
Mein const kann ich mir vorstellen, const kann ich nicht mehr ändern. Let und var. Das eine ist lokal, das andere ist irgendwie global.
Aber guck mal, ich kann den AVA-Skript, ich kann die Variablen so anlegen. Ich kann sagen l gleich das da. Ich kann sagen let l gleich das da.
Ich kann sagen var l gleich das da oder ich kann sagen const l gleich das da. Warum gibt's in AVA-Skript denn eigentlich vier Varianten, wie ich Variablen anlegen kann?
Man kann's auch kompliziert machen. Allerdings, wenn man's richtig kompliziert machen will, macht man's in C++. Dann versteht's keiner mehr. Selbst die Standardersteller verstehen's da nicht mehr.
Okay, also um eine WebRTC-Verbindung aufzubauen, muss man Folgendes machen. Als erstes brauch ich auf der Gegenstelle irgendeine Möglichkeit Informationen mit meinem Client auszutauschen.
Das mach ich über normale HTTP-Requests, machen wir das einfach. Weil WebRTC ist zwar ein Protokoll, das geht in beide Richtungen.
Ich kann Videos von einem Client zum anderen schicken und der Client zu mir. Das ist beidseitig. Aber für den Verbindungsaufbau brauche ich irgendeinen anderen Kommunikationskanal, weil die bidirektionale Verbindung gibt's ja noch nicht.
Deswegen muss ich das einmalig von Hand machen. Das heißt, ich mach jetzt einen Request, so stelle ich mir das so vor, nach Slash Signal. Dieser Controller heißt der so. Und wenn der Controller so heißt, dann registriert ASP.NET Core automatisch eine Uhrl, die Slash Signal signaligen oder wie auch immer heißt.
Also mach ich mal einen Fetch da drauf. Await, wie es sallt oder so. So, das gibt's ja noch nicht. Achso, Moment, Moment mal. Ich bin ja auch ganz falsch. Ich muss ja, das ist ja der Proxy, äh, Sekunde.
Local Host 5000. Okay. Die Sound-Lautstärke kann sich auch nicht entscheiden, oder? Ob's jetzt mal laut oder leise wird.
Jetzt wieder leise. Let ist Block Scope nicht kompatibel mit allem ECMAScript 6. Ah. Ha. Ich hab nix verstanden. Also ECMAScript sind die JavaScript-Standardisierungsleute.
Was, es leckt? Oh, Vodafone wieder am Start. Nö, leckt nix. Ah, leckt nix. Okay, also, ähm, ich schick jetzt dort nen, wie mach ich denn das jetzt am besten?
Ich muss jetzt ne WebRTC-Verbindung aufbauen. Genau, ich muss erst mal, ich muss erst mal ne WebRTC-Connection anlegen. Also, so, das Ding ist gleich RTC Peer, irgendwas Peer-Connection.
So, und dann, wie ging das jetzt nochmal weiter? Genau, jetzt muss ich mir, genau, jetzt muss ich mir vom Server abholen, was der Server für Video-Formate unterstützt.
Genau, das muss ich hier drüber machen, das muss ich jetzt hier auf dem Server programmieren. Also, lock, await, result, JSON. Kommt noch kein JSON zurück, aber das programmieren wir jetzt.
Warum reloadet das nicht mehr? Warum reloadet das nicht mehr? Ah, weil ich den Proxy nicht drin hab, ich hab die Erweiterung nicht. Beste Browser-Erweiterung, beste Visual Studio Code-Extension.
Weil, wenn man das installiert hat, ich zeig's euch mal, ist Massive Brained. Your Server Address ist Local Host. Hä, warum wird das nicht angezeigt? Und Live Server Address ist ja Standard. Geht das jetzt schon?
The Live Server Address is 52. Äh, wohl auch nicht. Was hab ich verkehrt gemacht? Was hab ich verkehrt gemacht?
Warum reloadet das nicht? Hab ich irgendwas falsch gemacht?
Äh, nee, warte, das hat mit SIP nichts zu tun, das heißt nur so. Hab ich was vergessen? Ach, ich hab Live Reload nicht angemacht, null. So, jetzt funktioniert's. So, und jetzt ist der Vorteil, guck mal, wenn ich das angeschaltet hab, wenn ich jetzt hier was reinschreibe und speichere, bäm, reloadet der automatisch die Seite. Das ist exzellent.
Ich hab Live Reload vergessen. Äh, gute Frage im Chat kommt öfters. Und zwar, wo ist es? Wo ist es?
Kannst du mir helfen? Was kann ich für einen Anfänger lernen? Also mit welcher Programmiersprache man anfangen kann? Hast du irgendwelche Videos oder kennst du einen YouTube, der echt gut erzählt? Äh, gut, da gibt's jede Menge, aber es ist halt die Frage, was du verwenden willst.
Ja, äh, dankeschön, Kid Ivar, Twitch Prime, huge sub, dankeschön, nice. Also wenn du dich, wie heißt das Plugin-Live-Server? Also wenn du dich in irgendeiner Art und Weise für Web-Entwicklung begeistern kannst, also sprich Webseiten erstellen und Backends für Webseiten, finde ich, ist das der beste Einstieg, weil man visuell sieht, was passiert.
Wenn das nicht so dein Fall ist, ist halt die Frage, wo so deine Interessen liegen. Möchtest du Windows-Anwendung machen, vielleicht sogar Windows-Desktop-Anwendung, da kommst du an.NET nicht vorbei, C-Sharp.net.
Willst du vielleicht ein bisschen in Richtung so Cloud-Geschichten gehen, da ist viel in Go programmiert. Und ansonsten, was auch recht hip ist, wenn's Richtung Machine Learning und irgendwelche wissenschaftlichen Sachen gehen soll, dann ist Python übelst angesagt.
Also, ist halt die Frage, wo so deine Interessen liegen. Da kann ich dir da auch besser was sagen.
Cobol, Cobol geht immer, Cobol geht immer. Okay, also, wir fragen den Server, was er alles für Video-Formate unterstützt. Das müssen wir jetzt dem Server erstmal beibringen, dass der da drauf antwortet. Ähm, erstmal überlegen.
Tja, da muss ich jetzt in die Hilfe gucken, da muss ich jetzt in die Hilfe gucken von diesem, von dieser Library, oder?
Würde ich mal sagen, da muss ich in die Hilfe von der Library gucken, wie das funktioniert.
Machine oder Web, aber mehr für Maschine. Was verstehst du unter Maschine?
Meinst du irgendwelche Low-Level-Geschichten? Oder meinst du Microcontroller?
Also, wenn du irgendwelche, wenn du gerne Microcontroller-Sachen machst, dann nimm deine ESP32 mit Platform-IO. Beste Kombination.
Also, wenn du so ein bisschen Microcontroller basteln willst, irgendwie so ein bisschen Elektronik-Gramm machen willst, dann ist eine ESP32 mit Arduino-Platform-IO das beste, was du machen kannst.
Oder meinst du mit Maschine für Desktop? Also Desktop-Anwendung. Also sprich, irgendwelche grafischen Desktop-Anwendungen.
Also, wenn du grafische Desktop-Anwendungen machen willst, dann ist die nächste Frage, für welches Betriebssystem?
Windows only, Windows Mac Linux, Cross-Platform. Das ist tatsächlich ein ziemlich kompliziertes Feld, wenn man Cross-Platform-Anwendungen machen will.
Allerdings, wenn du ein bisschen Web gelernt hast, gibt es Möglichkeiten, dass du das auch auf Desktop überträgst.
Deswegen gibt es in letzter Zeit so viele Elektron-Anwendungen und Browser in einem eigenen Fenster, die viel RAM fressen, weil das alles Web-Entwickler sind, die jetzt meinen, sie machen Desktop-Anwendungen.
Hab ich doch eigentlich ganz treffend beschrieben, oder? So, FFmpeg2-WebRTC. Gucken wir jetzt mal, was die hier machen.
Programmen. Das müssen wir jetzt nachbauen. Also, was machen die hier? WebSocket interessiert uns gar nicht. WebSocket brauchen wir nicht. Machen wir das ohne WebSockets.
WebSockets, alles egal. WebSockets juckt uns nicht. FFmpeg.
FFmpeg. Ja, das jetzt kommt das Interessante. Also, was?
Was?
Okay, keine Ahnung.
Ah, hier. Create. Das ist interessant. Das kenne ich. Das kenne ich. Das sind so die Standard-WebRTC-Geschichten. Okay, Create Offer. Sehr schön.
Also, was muss ich machen? RTC Peer Connection. Die scheinen sich ziemlich gut an der Web-ARP zu orientieren, was gut ist, weil die Web-ARP kann ich. Die SIP Sorcery-ARP kann ich nämlich nicht.
Also, dann machen wir das doch mal. Also, ja. War PC gleich New. New. Hallo. Import New RTC Connection. Configuration. Brauchen wir da eine Configuration? Was machen die hier?
Null. Okay, exellent. Null. Ich weiß jetzt nicht genau, was ich da gerade mache, aber mal gucken, ob es funktioniert.
By the way, ich nehme mal kurz hier aus dem Startup den Start von der Webcam raus, weil sonst blocken die mich noch, wenn ich laufend auf ihren Stream zugreife.
Das will ich nicht, dass wenn ich dann testen will, dass die auf einmal mich irgendwie IP-Band haben oder sowas. Mein Domain-Anbieter hat mich ja schon IP-Band. Will ich noch mehr IP-Band werden?
Electron ist das Docker der Frontend-Entwickler. Ich entdecke gewisse Parallelen. Ist beides was, wo jeder meint, das ist das Ding schlechthin, was man benutzen muss.
Geht Node Share nicht auch mit TypeScript? Doch, doch, klar.
Also, ich habe es noch nie verwendet, aber es müsste gehen. Ansonsten geht Deno.
Ich brauche NordExpressVPN, ganz genau. Okay, also Per Connection RTC. So, wie geht es weiter? Ich muss mich ein bisschen beeilen hier.
Also, Create Offer. Okay, das kenne ich. Das macht man im Browser ganz genauso. Create Offer. Zack. So, das generiert mir jetzt eine Liste mit Codecs, die mein Backend unterstützt.
Jetzt muss ich dem irgendwie noch sagen, dass ich nur H264 unterstützen will. H264 ist so der Codec, der zu 99% verwendet wird.
Also, wenn ihr Videos anguckt, ist das zu... na, wobei, kann man gar nicht sagen. YouTube ist mittlerweile, wenn es nicht geforst wird, nicht mehr H264.
Aber zu 90% wenn ihr Videos anguckt, ist das H264. Und die meisten Kameras liefern ihr Videos auch in H264 aus. Deswegen muss ich sagen, hallo Browser, ich unterstütze nur H264.
Das ist natürlich die Frage, wie mache ich denn das? Create Offer. Track, gibt es hier was mit Track? Ah, Videotrack. Exzellent, das brauche ich.
Das brauche ich. Also, Create Offer. Okay, das machen wir jetzt mal. Also Videotrack, ich Copy Paste mir das einfach mal, ohne dass ich weiß, was ich mache.
Track, Videotrack. Types, Video, Remote, was auch immer. Das ist False. Und hier muss ich jetzt reintragen, was für Videoformate unterstützt werden anscheinend. Okay, machen wir das mal. Wir programmieren das einfach nach, wie die das gebastelt haben.
Und dann sage ich Add Videotrack. So, ich muss ihm jetzt sagen, ich unterstütze nur H264. Hat Max eine Lizenz? Natürlich. Was meinst du denn?
Meinst du, ich würde dir was ohne Lizenz verwenden? Das glaubst du doch nicht wirklich. Meinst du jetzt den Codec? Meinst du jetzt den Codec oder meinst du jetzt die IDE?
By the way, ich sollte das mal umbenennen vom Default Namen. Signal Controller. Das ist hier der. Wo ist denn hier? Rename immer versteckt. Da. Bam. Exzellent.
Also. Okay, was? Wie sage ich denn jetzt, dass ich nur H264 Video machen will? Aha, Videoformat. Videoformat, Videoformat. Okay, was gibt es denn Videoformat?
Videoformat. Videoformat. Mal gucken, ob man hier. Weil ich weiß, welche Daten ich angeben muss. Das kann ich aus der anderen Software, die ich ja schon gebastelt habe, abgucken. Ich muss nur gucken, wie ich das hier mit der Library mache.
Moin, da Twinkos auch am Start. Poggers. So, also. Damit kann ich sogar jetzt was anfangen. Was wird gebaut? Ich habe ja vor einer Weile schon mal für meine Überwachungskameras was gebaut, was die RTSP Streams von den Überwachungskameras abruft mit FFMPEG.
Und dann über WebRTC in den Browser schickt. Das habe ich aus der Not heraus gemacht, weil ich keine ordentliche Videoüberwachungssoftware gefunden habe, die erstens gescheit auf dem Raspberry Pi läuft, zweitens wenig Latenz hat und drittens nicht alles reencoded.
So, das habe ich gebastelt. Die allererste Variante war eine Mischung aus C und Go. C, weil FFMPEG und Go, weil die einzig sinnvolle WebRTC Library, die man benutzen kann, das hier war.
Und dann habe ich das irgendwann nochmal neu gebaut in.NET mit Go, weil ich am liebsten.NET programmiere. Allerdings ist Interop zwischen.NET und Go abgrundtief kacke. Deswegen habe ich mich heute gefreut, dass ich eine Library gefunden habe, die WebRTC angeblich in.NET macht.
Das wollte ich jetzt gerade mal ausprobieren. Also das Ziel ist, dass ich in 45 Minuten irgendwie es hingekriegt habe, dass ich ein Video, ein Testvideo in den Browser über WebRTC übertrage. Mal gucken, ob das funktioniert. Ich habe nämlich nicht mal allzu viel Zeit.
So, also.
Video Format. Gut, da kann ich hier kann ich ja was mit anfangen. Da weiß ich ja, was da rein muss. So, also das Video Codex hat 264. Hat eigentlich derjenige geantwortet mit den mit den Einsteiger, Programmier, Geschichten nochmal?
Nee, das letzte Mal Maschine oder Web. Auf die andere Sachen nicht. Da kann ich auch nicht mehr sozusagen. Ist das Website Backend eigentlich der direkte Quellcode? Ist das Source auf GitHub? Nee.
Ich habe, ich habe mal eine Testversion hier im Stream. Wir haben das hier im Stream mal ein bisschen gebastelt. Ich habe meine Testversion irgendwo auf frag mich nicht auf Pastebin oder so hochgeladen vor zwei Jahren oder einem Jahr.
Nee, ist nicht. Okay, also wir wollen nur 264 Video unterstützen. Format. Da weiß ich glücklicherweise, was man eintragen muss, weil das kann ich jetzt aus meinem anderen abgucken. 102.
Frag mich bitte nicht, warum 102. Ich habe keine Ahnung, warum 102. Ich weiß nur, dass es mit 102 funktioniert, weil beim anderen steht 102 drinne und das geht.
Ansonsten habe ich keine Ahnung, warum die Format ID 102 ist. Wahrscheinlich steht das im Standard irgendwo drin. Keine Ahnung. Ich tippe das einfach nur ab, was ich bei der anderen Geschichte drin stehen habe. 102. Weil klar, 264 sieht auch so nach 102 aus.
Okay, Format. Was, was, was braucht man jetzt noch? Warte mal, das hier hat doch einfach in Format gefressen noch, oder? Format. Okay, das funktioniert. Exzellent. Sehr gut, sehr gut.
So, und jetzt können wir sagen Create Offer. Und nun gucken wir mal, ob ich im Browser, jetzt ist der Moment der Wahrheit, ob ich im Browser was ordentliches zurückkriege. Moment hier, was? Null, oder? Nochmal. Ja.
Ja. So. Also ich muss keinen Lizenzcode, ich muss keinen Lizenz für H264 bezahlen, wenn ich das verwende. Irgendwelche Hardware Hersteller müssen das bezahlen oder so. So ist das gemeint mit, dass das nicht Lizenz war. Ich muss da nichts für bezahlen. Ich kann das, es kann ja auch jeder ein Video encoden in H264 mit FFmpeg. Das ist kein Ding.
Aber wenn du eine Hardware verkaufst, die das benutzt, da musst du Lizenzgebühren irgendwie bezahlen. So. Also. H264 gleich 2 plus 6, 2 plus 6 plus 4 gleich 2 plus 10 gleich 102. Ach so. Ja, deshalb gibt das alles Sinn.
Exzellenter Chat ist mal wieder Next Level angekommen. So und jetzt schicke ich das hier zurück. Return. Ja Offer. Und jetzt gucken wir, ob es im Browser ankommt und ob der Browser das frisst. Das ist ja noch viel. Ach so. Moment, was geben wir hier zurück?
Ich mache es jetzt wirklich eklig. Object. Scheiß drauf. Hauptsache es geht. Kommt was zurück. So. Browser. Await. Console. Ok, wir kriegen was zurück. Das schaut mal gut. Jetzt müssen wir nur gucken, ob der Browser das ganze frisst.
Wie machen wir das jetzt irgendwie? Set Remote. Also man muss dem jetzt sagen, ok, das sind die Sachen, die der Server unterstützt. Und dann muss ich quasi noch eine Antwort generieren, wo drinne steht, das sind die Videoformate, die der Client unterstützt. Und wenn die sich beide einig wären, dann kann ich Video übertragen.
Ok, Set Remote Description. Geht das einfach so jetzt? Ach, das funktioniert jetzt? Das hätte ich jetzt gar nicht gedacht. Exzellent. So. Set Remote Description und jetzt muss ich den Antwort generieren, den ich an den Server zurückschicke, wo drinne steht, was mein Browser für Videos unterstützt.
Also, wir nennen das mal ein kleines bisschen ordentlicher. Wir nennen das mal irgendwie.
Die Confidence Jason ist schon. Ok, das mach ich irgendwie. Und äh. Tja. Passt schon. So, und jetzt muss ich ne Antwort generieren, was der Browser für Videos, Formate unterstützt. So, das geht so.
Dann sagt man Create Answer. Das sagt, ok, das sind meine lokalen Videoformate. Ach so. Let Await. Irgendwie so. Wird doch eh kein Schöner als Preis gewinnen. So. Also, das passt. Jetzt geb ich das mal aus und schau mal, ob der Browser irgendwie was Sinnvolles da generiert überhaupt.
Ja, ich hab keine Ahnung, ob das sinnvoll ist, aber das sieht so aus, als kackt das zumindest nicht ab. Ich hab Traffic verwenden für den Docker Reboot as Proxy. Ja. So. Das muss ich jetzt zurück an Server schicken, dass das funktioniert. Await. Fetch.
An. Ach so. Ha. Ok, ich brauch auf dem Server ne zweite Funktion, die Sachen annimmt. Also. Atttp. Post. Und das wird Bigpray Name. Das heißt jetzt einfach nur Post. Und ähm. Brauch jetzt. Ach so. Oh. Oh. Äh. Jetzt gibt's ein kleines Problem.
Hier. Oh, da hab ich jetzt gar nicht dran gedacht. Hier erstelle ich quasi die Server-seitige, äh, Server-seitige Ende dieser Verbindung und füge auch den Videotrack hinzu und schicke das dem Client. Das Problem ist aber, äh, wenn ich jetzt dem Server schicken möchte, was mein Browser alles unterstützt, dann weiß ich nicht mehr, zu welcher Verbindung das Ganze gehört.
Also, deswegen machen wir mal ein Private Static, äh, äh, Private Static, was weiß ich, äh, Dictionary aus irgendeiner ID und einer, äh, Connection. Dass ich das irgendwie zuordnen kann. Das ist jetzt quasi so, irgendwie so ein bisschen Brain Dump. Keine Ahnung, ob das dann tut. So.
Connections. Jetzt brauchen wir noch irgendeine ID, die ich hochzähle. Private. Äh, ID. Ja, Uint-ID. So, jeder Client kriegt quasi eine neue ID zugewiesen. Das könnte, das könnte tatsächlich funktionieren.
Okay, äh, mal kurz nebenbei abgucken, ob man welche anonymen Dinger returnen kann. Also, das heißt, neuer Client connectet sich, wir zählen die ID eins hoch. So, und jetzt darf ich nicht, jetzt, okay, okay, ich weiß, was ich mache.
Ich darf jetzt dem Client nicht einfach nur die Information zurückgeben, welche Videokodex ich unterstütze, sondern ich muss dem Client noch zurückgeben die ID.
Genau, ID, die eine einzigartige ID durch den Client wieder erkenne. So, das, das muss, und jetzt hier Offer. Okay, und hier übergebe ich ihm jetzt, mal gucken was, weiß ich auch nicht genau.
Jetzt muss ich das hier neu basteln, dass das klappt. Jason Offer, dann machen wir hier die ID. Die ID müsste jetzt hier drin stehen.
Ja, oh, oh, ach so. Aha, okay, okay, es scheint, es scheint noch zu funktionieren. Okay, jetzt schicken wir die Information an den Server zurück, was der Browser für Videokodex unterstützt.
Also, das schicken wir wieder an Signal zurück. Allerdings, diesmal mit einem Postrequest, irgendwie Method gleich Post, Body gleich hier meine, meine Antwort.
Exzellent. Wie das funktioniert? Ernsthaft? Einfach so? Okay. Ach so, wie kriege ich das jetzt rein? Komm, Dynamic. Hauptsache es geht.
Kommt da jetzt irgendeine Antwort? Klappt das jetzt? Kommt da jetzt irgendwas auf dem Server an? Oh, Unsupported Media Type.
Ach so, ich muss ihm noch sagen, dass es Jason ist. Fetch API, wie macht man das? Fetch API Post Jason, wie geht das? Das kann sich doch kein Mensch aus dem Kopf merken.
Header. Exzellent. Das brauchen wir. Header. Ich gebe dir einen Header, Alter. So, wunderbar. Bad Request. Warum? Warum ist das ein Bad Request?
Also, ich finde nicht, dass der schlecht ist. Chat wollen wir abstimmen, ist der Request wirklich schlecht? Also, ich finde den eigentlich ganz gut.
Warum ist das? Ah, ich weiß, ich weiß. Weil ich ja kein JavaScript Objekt an den Server schicken kann, sondern. Ah, viel besser. Okay. Also, ich kriege jetzt schon mal die Antwort vom Browser, was der unterstützt.
Sehr gut. So. Okay, da ist Type drinne. Ach nee, ich muss die ID noch mit zurückschicken, dass ich weiß, welcher Klein sich connectet.
Also schicke ich nicht die Antwort zurück, sondern schicke eine ID zurück. Das ist die ID und dann schicke ich die Antwort zurück.
Okay, das scheint zu funktionieren. Ich kriege die ID wieder zurück. Das heißt, ich mache hier sowas wie int id oder client id gleich Antwort id.
Und was haben wir dann sonst noch? String oder nennen wir es, nennen wir es irgendwie. Antwort gleich. Ah nee, das habe ich ja schon belegt.
Temp, immer besser Name, wenn einem sonst nix einfällt. Antwort. Antwort. Ach du große Geil. Stimmt das jetzt, was ich hier mache? Ich muss das mal kurz ausgeben, ob da überhaupt was sinnvolles ankommt, was ich hier schicke.
Ich schicke. So, zack. Oh, internal. Okay, nein, das hat schon mal nicht funktioniert. Warum? Aha.
Ah, deswegen vielleicht. ToString? ToString gibt es bestimmt auch. Das sieht besser aus. Excellent. Okay, Antwort. Antwort. Ach du große Scheiße.
Nee, StPetus. Ich brauche hier nur die SessionDescription, das reicht. So, okay. Gibt es hier SessionDescription? Jawoll. New SessionDescription. Keine Parameter.
Äh, Session, was haben wir denn sonst noch? SessionDescription? Init? Was ist Session? Ah, ich kenne die API von dem Zeug nicht. Wie machen die das denn hier? SessionDescription. New? Ah, hier, guckt mal. New Session.
Okay, das brauche ich. Das, das muss ich machen. Excellent. Das da. Das, das brauche ich jetzt. Das und sonst nichts.
Okay. So, jetzt muss ich mir erstmal die Connections zum Client hier oben wieder aus meinem Dictionary rausholen, weil das ist ja Stateless und das lasse ich mal Temp. Temp ist prinzipiell immer der beste Name für alles.
So, Connections und zwar die ID. So. Und jetzt da. Was hat er für Schmerzen? Int is not assignable to par uint. Ach so. Ja, das ist richtig. Dann ist es einfach hier oben jetzt mal ein uint.
Ansonsten, wenn es kein unsite int ist, dann crash es einfach und gut ist. So, also PC, Set, Set, Set. Hab ich hier die Create Offer? Und muss ich noch einstellen, dass der sich das merkt, welche Videoformate er selbst unterstützt?
Okay. Und jetzt muss ich ihm sagen, welche Videoformate der an die andere Seite unterstützt.
Schon mal GRPC ausprobiert. Nein, habe ich nicht. So, es ist gleich Temp. Ich hoffe, das funktioniert jetzt. Okay, es kackt schon mal nicht ab. Das ist schon mal nice.
So, ich muss mich jetzt ein bisschen beeilen, dass ich das bis 22.00 Uhr alles hinkriege. So, Set, Remote Description. Blablabla. Temp. Gucken wir mal, ob es nicht crash, selbst wenn ich hier...
The given key 1 was not present in the dictionary. Was? 1? Äh, warum nicht? Ach so, ich kack nur, ich füge das gar nicht hinzu da oben.
Ja, dann kann es ja auch da nicht drinstehen. All die... Das ist übrigens wahnsinnig multithreaded safe, was ich hier alles mache. Also das wird nie kaputt gehen.
Die connection. Okay, mal gucken, ob es jetzt funktioniert. Ah, ja. Okay, okay, okay. Gut, gut, gut, gut, gut. Set Remote Description. Ich würde sagen, das ist alles, was wir brauchen. Und jetzt können wir ein Video senden.
Oder? Die settings sind richtig hier, diese Dinger. Die kenne ich von dem anderen Programm, also das passt. So, und jetzt kann ich ein Video senden. Kann ich jetzt... Muss ich noch irgendwas machen?
Ich setze das hier. Set Description. Also Leute, wenn das klappt, gifte ich 5 subs. Aber ich kann es mir nicht vorstellen, dass es einfach so geht.
So. Eigentlich... Also mir fällt jetzt erstmal nichts mehr ein, was ich zum Verbindungsaufbau machen muss. Doch, natürlich. Die wichtigste Sache habe ich wieder vergessen, Chat. Die wichtigste Sache habe ich vergessen.
Also ich habe zwei Sachen vergessen. Erstens müssen wir den empfangenen Stream noch an den Videoplayer übergeben, also dem Videoplayer sagen, dass er das abspielen soll. Und zweitens muss ich den Videostream senden.
Den Videostream sende ich ja noch gar nicht. Das machen wir jetzt hier. Zeug machen mit den Videoframes. Wir machen jetzt Zeug mit den Videoframes. Und zwar Signal... Das ist übrigens absolut nicht best practice oder sonst was, bevor mir jetzt hier irgendjemand eine ankommt.
Also man greift normalerweise... Also man macht sowas im Startup schon mal gar nicht. Man greift im Startup nicht auf jeden Fall Static-Controller-mäßiges zu. Was übrigens gar nicht Static ist. Und man hat auch nicht unsafe code direkt im Startup. Aber who cares. Wir gucken einfach, dass das jetzt geht.
So, Public. Man macht auch nicht Sachen zwischendrin. Einfach mal Public, weil man woanders drauf zugreifen will. Aber hier bleibt jetzt gar nichts anderes übrig. So, Connections. Bar. Und dann hier alle Values. Alle WebITC Connections.
Prime1994. Dankeschön. Big Brain. Massive Sub. So, und PC. Things Connection. Ach nee, ich brauch den Track. Ich brauch den... Nee, guck mal, was ist das? Send JPEG Frame.
Oh, das ist ja cool. Ey, das ist nice. Ich wusste gar nicht, dass man über WebRTC JPEG Frames übertragen kann. Das ist richtig nice, wenn das funktioniert. Weil dann kann ich auch Motion JPEG unterstützen. Das ist nice.
So, Send Audio Video. Was haben wir denn? Send H264 Frame. Duration Payload. Keine Ahnung. Duration RTP Units. Was sind Duration RTP Units?
Sind das Timestamps? Sind das einfach nur Timestamps? Duration Add. Oder ist das wie lang ein einzelnes Schnipsel ist?
Was ja im Endeffekt... Letzter Timestamp minus aktueller Timestamp. Ich hab keine Ahnung. Ich übergebe da einfach mal den Timestamp und hoffe, dass es funktioniert. Und zwar den Presentation Timestamp.
Pts. Vielleicht wäre es besser, wenn ich den DTS nehme. Äh, warum geht das nicht? Was ist das? Ein Long? Long. Ah, komm, easy. Uint. Wir casten das einfach mal ein gutes.
So, Bites. Ok. Jetzt wird es kriminell. Wie mein Opa gesagt hätte. Der übrigens nicht kriminell war. Aber das war so eine Standardredewendung von ihm. Dann immer gesagt, jetzt wird es kriminell.
Ähm. Data. Ich kann jetzt ja nicht einfach einen Raw-C-Pointer an diese Funktion übergeben. Das funktioniert ja nicht. Ähm. Ich muss dieses Raw-Pointer-Ding... War mein Opa auch Programmierer? Nein. Mein Opa war Elektrotechniker.
Also der hätte das hier mit Steckdosen garantiert besser hingekriegt, wie ich daheim. Wir müssen dieses Raw-Bite-Array in ein.NET-Array konvertieren.
Wir haben hier, es gibt hier die Size davon. Wir können, wir können ein neues.NET, wir können ein neues.NET-Feature verwenden. Und zwar, die haben jetzt in einer letzten, letzten.NET-Version sowas hier eingeführt. Das ist quasi ein Managed, so eine Art, wenn ich das richtig verstanden habe, so eine Art Managed-Pointer auf Raw-Memory.
Ich hab's noch in keinem Projekt bisher verwendet. Aber dem kann man, ach guck mal, dem kann man einen Pointer übergeben und eine Size. Wunderbar. Genau das brauchen wir. Pointer-Size. Ähm. Mem. Wie auch immer, ich's anders nennen soll.
So, und kann man daraus jetzt ein Byte-Array machen? Jawoll. Da. Manchmal lohnt sich Webcasts angucken. Excellent. So. Jetzt ist die Frage, ob es crashed. Gucken wir mal. Gucken wir mal, ob es crashed.
Ähm. Ich muss gucken, dass es noch läuft. Wie guck ich denn, dass es läuft am besten? Ich, ich geb einfach, ich geb, okay, wir machen hier irgendwie mal sowas wie, so keine Ahnung. Und die, bröh, geht sofort. Wir machen irgendwie Cent oder so, schreiben wir mal rein.
Moment, was ja nicht funktionieren wird, weil, okay. Cent eins und Cent zwei. Okay. Weil die Schleife läuft ja erst, wenn ich mich mit dem Browser registriert hab. Okay. Cent eins funktioniert.
Äh, wir, wir, okay, wir geben nicht Cent aus, wir geben den Presentation Timestamp aus. Excellent Logging. Ja, richtig. Das ist Next Level Logging hier, was man hier sieht.
Ah, yes. Ähm, choose my name. Deswegen finde ich, ist C-Sharp eines der besten Sprachen überhaupt. Nicht nur, weil ich die Sprache an sich gut finde, sondern weil die es konstant schaffen seit 15 Jahren, nicht so eine Scheiße zu bauen, wie der C++ Standard, sondern neue Sachen auch zu verbessern und nicht einfach zu sagen, ah ja gut, wir haben jetzt 30 Mal das Gleiche drin.
Neue Sachen zu verbessern und die, die schaffen seit 15 Jahren sinnvolle Sachen in die Sprache einzubauen, die gut zu der Sprache passen und die Sprache ergänzen. Also da müsste sich das C++ Gremium echt mal eine Scheibe von abschneiden.
Aber wisst ihr was das Gute ist? Noch crasht nichts. Noch crasht nichts. Aber noch hab ich ja auch den Browser nicht aktualisiert. Also von der Idee her, ich aktualisiere jetzt den Browser. Wenn ich den Browser aktualisiere, registriert er eine neue Verbindung und er sollte was an diese Verbindung schicken, was aber noch nicht funktionieren kann.
Okay, okay, aber er sendet schon mal, er sendet schon mal Sachen theoretisch an den Browser. Der Browser empfängt aber noch nichts. Auch nicht, weil ich hab das noch nicht verknüpft. Aber er kriegt das zumindest schon mal mit.
Okay, das heißt jetzt muss ich doch eigentlich nur noch den Videoplayer mit dem Stream verknüpfen. Geht der RAM-Verbrauch hoch? Das ist eine gute Frage, das sieht man nicht so ohne weiteres, weil ich mich voll spamme mit. Wo ist der RAM-Verbrauch?
Wo ist der RAM-Verbrauch? Wo ist der RAM-Verbrauch? Da! Nee, der RAM-Verbrauch scheint konstant zu bleiben. Okay, schauen wir mal. Also, jetzt verknüpfe ich mal den Videoplayer mit meinem WebRTC-Backend.
Also, wenn das gehen würde, erstens verschenke ich ein paar Subs, weil ich nicht davon ausgehe. Und zweitens wäre das richtig geil, weil das hier ist mega übersichtlicher kurzer Code für das ganze WebRTC-Zeug. Ich hab allein 400 Zeilen Go für den ganzen WebRTC-Krempel.
Okay, das macht auch noch ein bisschen mehr, das Go-Gedöns. Aber allein schon das Handling für Verbindungsaufbau und hin und her schicken sind schon wahrscheinlich 200 Zeilen.
So, also, jetzt muss ich ihm noch sagen, dass er den Videostream an den Videoplayer attachen soll. Also, das ging, wenn ich das...
Das machen wir ganz hier oben. Man musste dem in Callback einstellen, und zwar Track, irgendwas mit Track. On Track, genau.
Äh, äh, im Moment, wie ging das Track so? Nee, im Moment, wie macht man das in JavaScript? Event, sagt man, event. Oder das ist wahrscheinlich schon gleich der Track. Wir gucken mal, ob da überhaupt irgendwas ankommt.
Ja, Track-Event. Okay, Track-Event. Source-Element, Stream.
Äh, das muss ich jetzt mal kurz abgucken, wie man das, wie man das, äh, attacht. So, okay, also, wir brauchen, wir brauchen auf jeden Fall schon mal das Player-Element. Also, Document, Get-Element, Player.
So, und jetzt weiß ich nicht, wie ich dort irgendwas attache. Player, sowas wie Source, äh, nee, url, url bringt nichts, ähm, wie, wie übergebe ich einem HTML, wie übergebe ich einem HTML-Player-Element das Source?
Ich könnte nachgucken, wie ich das bei dem anderen gemacht hab. Aber ich glaube, Google ist schneller. Video, HTML, äh, Source, irgendwie so.
Okay, gibt's da ein Beispiel? Video, Player, Player, Source, nee, das Kackseite.
What? Source-Object, Stream. Okay, Player, Source, Ob, gibt's net. Naja, einfach mal dran zur, und jetzt einfach minus Track oder Streams?
Genau, das kenn ich noch. Genau, Streams Null musste man machen. Jaja, genau. So.
WTF? Loll, das kam jetzt unerwartet. Das kam jetzt unerwartet. Das funktioniert. Easy, easy as fuck.
Easy as fuck? Ich wusste von Anfang an, dass das klappt. Mir war das direkt klar, dass das direkt funktioniert.
Das geht einfach. Wisst ihr, wie lang ich mich abgemüht habe mit dieser Go-Lösung bis, bis ein einfaches, ihr könnt euch vielleicht an den Stream erinnern, bis ein einfaches Test, oh, es ruckelt.
Es ruckelt, Leute, es ruckelt. Das Video freest. Oh, oh je, MonkaS. Das Video freest zwischendurch. Ja, gut, scheiß drauf, man kann nicht alles haben.
Was sagt denn der RAM-Verbrauch? Äh, da sind bestimmt, schau mal das Memory, ich würd mir das Memory gerne anschauen, aber äh, ja, ich hab zu viel D-Bank-Ausgabe.
Wo ist das Memory? Warte, wo ist das Memory, easy? Wo ist das Memory, wo ist die Memory aus? Ich mach mal die D-Bank-Ausgabe kurz aus, das ist ein bisschen viel.
Äh, beste Antwort, ihr wollt, ich mach den ganzen Krams mal aus. Ähm, Moment, wo sind wir denn hier, da? Ah, es kommt, es kommt mal alles weg, alles weg.
Alles weg, alles weg. Oh, ich starten. Neko Rock, 14 Monate, Dankeschön. Die Subs gibt's übrigens gleich, Leute.
Neko Rock. Big Brain Subscription. Gleich gibt's die Subs. So, 149 MB Verbrauch. Jetzt erst mal neu laden, das Video. Das funktioniert einfach, ich fass es nicht.
Ich fass es nicht. Das funktioniert einfach, das Videostream. Äh, aber wir können auch gar nicht so viel Memory leaken, das ist ein, keine Ahnung, 360 x 240 Video oder so, das kann, selbst wenn das Memory leakt, merk ich das erst in einer halben Stunde wirklich nennenswert.
Nennenswert. So, ja nice, nice, nice, nice, nice, das funktioniert. Extrem poggers ist das. Da reicht poggers, da muss der französische poggers ran.
First Mal 4K Videos anmachen. Ihr hat einen RTSP Test Stream? Meine Kameras will ich nicht reinmachen. Erstens liege ich dann vielleicht was. Doch, ich weiß, was ich mach. Die iPhone Kamera. Ich mach die iPhone Kamera an.
Äh, oh Moment, wo hab ich mein iPhone? iPhone? Wo hab ich mein iPhone? Ah, hier. Ich mach die iPhone Kamera an, die ich immer oben rechts in der Ecke hab. Die guck mal, Moment, das mach ich jetzt mal schnell.
iPhone Kamera oben, iPhone Kamera einschalten. Mal gucken, ob das das frisst. Kamera, zack.
Okay. Also wenn jetzt alles funktioniert, müsstet ihr gleich mal den Raspberry Pi sehen. Gucken wir mal. Äh, aber da brauchen wir eine andere, andere Ural RTSP.
Mein iPhone ist 122161.110. 554 ist die Fallport RTSP. So, mal gucken.
Oh, aber Connected, Connected ist das schonmal. So, das ist die iPhone Kamera. Da ist einfach, da ist einfach der Raspberry Pi. Oh, einfach, zwar übel schlechte Beleuchtung und in der letzten Ecke wieder, wo die Kamera hängt, aber da ist einfach mal der Raspberry Pi da.
Äh, wir gucken mal, wie viel Verzögerung das Ganze hat. Übrigens, ich weiß auch, ich hab's hochgekannt, ist egal. Moment, ich mach mal kurz die Hand hin und her. Was ist denn das?
Was ist denn das? Oh, äh, was ist das?
Das sieht nicht gut aus, aber nachdem ich schon ein bisschen was mit Audio und Video gemacht hab, sieht das für mich so aus. Das ist nicht so viel für die VF1. Es werden nur die Keyframes angezeigt.
Das sieht für mich aus, als wären es nur die Keyframes, die angezeigt werden und die dazwischen nicht. Wisst ihr, was das ist? Wisst ihr, was das ist? Das ist genau das, was ich vorhin erzählt hab. Wollen wir mal wetten, das ist genau das.
Wollen wir mal wetten, das ist genau das. Okay Leute, noch mal, also fünf Gifted-Sub sind schon mal sicher für die ganze Geschichte, die ich hier jetzt, äh, dass es einfach so funktioniert hat. Aber ich gifte noch mal, ich gifte noch mal ein paar, wenn das jetzt stimmt, weil ich vermute, nämlich, ich glaube, jetzt kommt genau das klei, jetzt ist wirklich genau das Problem, was ich vorher angesprochen habe, das ist gut, dass ich das drin gelassen hab, in weißer Voraussicht schon.
Ich glaube, die Frames kommen in der falschen Reihenfolge. Also was heißt in der falschen Reihenfolge? Die Frames, wie sie decoded werden und wie ich sie anzeigen muss, kommen, also die muss ich erst noch selbst in die richtige Reihenfolge sortieren, wahrscheinlich, weil die iPhone-Kamera-App scheiße ist. Gucken wir mal, ob das stimmt.
Was? Ja, guckt. Die, die Coding und Presentation Timestamps sind anders. Manchmal, manchmal sind sie gleich, das ist wahrscheinlich ein Keyframe oder so, wenn die gleich sind. Das heißt, ich müsste diese
sortieren. Oh nee, da habe ich jetzt keinen Bock drauf. Da habe ich jetzt, da habe ich jetzt keinen Bock drauf. Oder ich nehme die Coding, ich nehme einfach die Coding Timestamps und gucke mal, ob es dann funktioniert. DTS.
Beträgst du das über W-Lan? Klar. Mit DTS könnte es sogar sein, dass es schon funktioniert, weil die sind ja immer aufsteigend.
Ey, das ruckelt immer noch, Leute, das ruckelt immer noch. Guck mal hier.
Es ruckelt immer noch. Okay, nee, da bin ich zu low-brain heute Abend dafür, das zu fixen.
Also das Problem ist tatsächlich, dass die Coding Timestamps und die Presentation Timestamps, die stimmen nicht überein. Das heißt, also von der Theorie her, was ich machen müsste, wäre, ich müsste mir so einen
Buffer, ich müsste mir einen Buffer anlegen, indem ich die Frames speichere für, sagen wir mal, 2 Sekunden. Und solange warte ich halt, bis ich den nächsten passenden Presentation Frame habe oder so.
Mach doch ein einfaches If, wo du die größeren ausgibst. Okay, dann ruckelt es aber wahrscheinlich immer noch. Hast du das auf GitHub? Nee, das habe ich gerade hier im Stream erstellt.
Dann habe ich Delay, doch, doch, doch. Nee, das mache ich jetzt, ich kann das, wir machen im nächsten Stream da mal ein bisschen weiter dran, dann kann ich es auf GitHub pushen.
Oder, oder, Kengin, willst du jetzt irgendwie da dran mitwursten? Ich mache es nicht auf GitHub, weil das komplett random zusammengewurstet ist, ich kann es dir auf Pastebin machen.
So, das ist eine gute Idee, probieren wir jetzt mal kurz aus, was hier jemand vorgeschlagen hat, und zwar.
Also ich kann es, nee, ich würde es sogar auf GitHub machen, aber ich kann es nicht auf GitHub von hier pushen. Ich bin ja gar nicht eingeloggt auf GitHub.
So, aber wir können die Billig-Variante wirklich mal ausprobieren, irgendwie. Was machen wir da? Last TS oder so, Null.
So, und jetzt sagen wir, wenn, was machen wir da jetzt, was machen wir da jetzt, also wenn, PTS, if, if, Moment, Package, PTS kleiner, gleich dem, ups, dem letzten ist.
Dann machen wir nicht weiter. So. So, und jetzt müssen wir noch das setzen. Sagt mir, wenn ich Mist bastle. So. Ah nee, das muss ein Uint sein.
Aber das wird auch nicht dazu führen, dass es besser funktioniert, weil er überspringt ja immer noch Frames. Ah nee, long muss das sein. So, ergibt das hier irgendwie Sinn?
Wollen wir hier nochmal abbrechen? Wo habe ich denn diese Ausgabe mit den Timestamps? Moment. Oh, wo habe ich es denn hier? Da. Brauche ich noch mal.
Jetzt gucken wir mal. Stimmt, ich könnte es nochmal als Release kompilieren. Ich glaube nicht, dass es einen großen Unterschied macht.
So, jetzt stimmt der Kram zwar immer noch nicht miteinander, aber es sind nur die größeren. Nee, ich glaube nicht, dass es einen Unterschied macht, weil das ist ja kein Performance Problem.
Das ist ja ein Problem, dass die Frames in der unterschiedlichen Reihenfolge geschickt werden. Wenn es schneller ist, ist es vielleicht sogar noch mehr kaputt.
Das war eine sehr gute Idee, Chat. Das war eine sehr gute Idee. Es ist immer noch nicht ganz flüssig, es fehlen immer noch Frames. Nee, nee, es fehlen immer noch Frames.
Aber, okay, wir gucken mal, wie die Verzögerung ist. Moment. Es ist wirklich verdammt wenig Verzögerung. Ich muss euch, wie zeige ich euch am besten, wie die Verzögerung ist.
Ich mache mal irgendein Geräusch, ich mache mal irgendein Geräusch, so hier. Irgendwie, so, Moment. Ich lege euch mal kurz das Handy neben dran, das Mikrofon hier so neben dran.
So. Und jetzt mal muss ich mal irgendwie krach machen, so, keine Ahnung. Na, kaum Verzögerung, Leute. Habt ihr es gehört?
Ja, wenigstens 200 Millisekunden. Leute, wollt ihr mich verarschen? Was interessieren mich 200 Millisekunden? 200 Millisekunden ist nichts für den Übertragungsweg, den das Ganze nimmt.
200 Millisekunden ist Pock. Ihr werdet kein Video schneller jemals im Browser gesehen haben wie das. Ach so, weniger als, ach ja, sorry. Ich hab mich verguckt.
Ich hab so gelesen, wie ja, wenigstens 200 Millisekunden, so als wäre das jetzt viel gewesen. Dabei ist das überhaupt nicht viel, aber das ist richtig, richtig nice. Ja, also, äh, Elsa hab ich falsch gelesen.
Aber exzellent, wie gut das funktioniert. Jetzt mal ordentlich in Go. Nee, warum ich es nicht in Go mache, unter anderem liegt daran, weil C und Go Interop nicht so dolle ist.
Gerade mit Callbacks aus C raus, das ist richtig eklig. Und, ähm, weil ich Web-Anwendungen am einfachsten in ASP.NET mit dem Backend machen kann, weil ich mich damit am besten auskenne.
Ich bau da mal was. Mach, mach du mal. Vielleicht, also, vielleicht haben wir ja Glück. Vielleicht krieg ich ja diesmal wirklich was lauffähiges raus, was ich, ähm, auch mal auf Githa pushen kann.
Und vielleicht haben wir dann Glück und die ein oder andere Leute aus dem Chat beteiligen sich daran, dort was ordentliches dran zu bauen. Also, zusammen, so.
Okay, ich gucke mal, wie ich das jetzt, ich bin, ich bin hier nicht, bin ich hier irgendwie auf Github eingeloggt? Ich glaube nicht. Kein Github login. Bin ich hier auf Github eingeloggt?
Kein Github login. Okay, wie krieg ich denn das jetzt auf Github? Ich bin auch am zweiten Rechner in Github eingeloggt. Github Sealer, ich hab doch keinen Account hier drauf.
Okay, wir machen erstmal einen Commit. Es ist aber halt so eklig, Alter. Eigentlich will ich das gar nicht pushen. Hast du den Key hinterlegt?
Nee, nee, wahrscheinlich nicht. Ich hab auf dem Streaming-Rechner nix drauf, weil ich nicht aus Versehen irgendwelche Sachen leaken will oder so.
Okay, ich gucke mal, wie ich das auf Github irgendwie kriege.
Hast du einen lokalen Git-Server? Ja, hab ich. Okay, aber ist aber so, ich hab jetzt hier auf jeden Fall nichts geleaktes in irgendeiner Art und Weise drinne. Ich mach mal, ich mach erstmal einen Git-Commit.
Ja, Twinker, ist klar. Erstmal schön alle private Keys raushauen. Git-Init, Git-Status, wir machen mal ein schönes Git-Commit. Achso, Moment.
Gap's da nicht ne coole Seite für Git-Ignore? Da gab's doch so nen Web-Service, wo man Git-Ignore Sachen... Nee, nee, ich mach nicht Minus-A. Ich will mal ein Projektfolder raus und die Binaries raus und sowas.
Git-Ignore.io, was? Git-Ignore.io. Äh, C-Sharp. Nee, Moment.
Was? Was macht das? Ah. Ah ja. Nee, das ist für Rider nicht... Ich mach's mal kurz von Hand. Also, Git-Ignore. Also, ähm, der da kommt raus. Ups.
Äh.
Wenn man es im richtigen... Git-Ignore, so. Der da kommt raus und, ähm, und der Bildordner kommt raus. Monarch-S, Bin und Objects können wir noch raus machen, ne?
Bin und Objects raus. So, ich glaub, das reicht.
Ja, ja, ja. Äh.
So, ich hoffe, das ist jetzt richtig, dass ich nicht zu viel einchecke. Also, Git-Add, Git-Status, was hat er jetzt alles einge... Genau, ok, der hat den ganzen Müll rausgelassen. Alles klar, sehr gut.
Git-Commit, A-M-Init, Git-Git-Log. Ok, ich versuche mal nebenbei, äh, ich leg mal bei GitHub ein neues Projekt an. Hoffentlich bin ich hier noch eingeloggt. Auf dem anderen Pro... Oh fuck, ich bin hier auch nicht eingeloggt.
Äh. Ähm. Ok. Hab ich GitHub, zwei Faktor-Authentifizierung? Dann log ich mich jetzt hier mal ein. Ich guck mal kurz nebenbei in mein Keypass, was mein GitHub für einen Account hat.
Git-Hoop. Also. Wir haben Wubblons.
At gmx.de. Das ist keine geheime Adresse, die steht sogar im Profil. Ach ne, Moment, äh, äh, Sign-In.
Äh, Passwort. Kacke. Chat, ich mach euch mal kurz aus, da muss ich nicht so viel gucken, ob ich jetzt irgendwas leake oder nicht.
Ich glaube, ich hab mittlerweile eh zwei Faktor-Authentifizierung. Ja, two Factor-Authentifizierung. Das heißt, es ist eh egal, ob ich was leake. Lul.
Verify. Ok. Alles klar.
Mal die Vice-Capture wieder an. Gut, äh, Create. New repo. So, wie nennen wir's? Monarch-S passt wunderbar. Description.
Check-W-Tests. Nur gepusht, weil mich der Chat sonst geflamed hätte. So. Ai, ai, ai.
So, ähm, Public. Read me. Alles klar. Choose. Create. So, das da. Äh, Moment, hier, da sind wir.
Get add. Äh, Main. Geh mal fort. Zu, Lul. Nein, nein, nein, nein. Das Ding, also, Inclusiveness hin oder her. Das Ding heißt bei mir weiter Master.
Nicht Main. Nein, nein, nein. Master. Ok, also.
Bobloids. Add gmx.de. Passwort. Wollen mal kurz ins Fullscreen machen wieder.
Fuck. Was? Bei mir verschrieben. Hä?
Ist das ohne Adresse? Moment, ist, ist Username? Ach nee, ist das, ah, Moment. Ah, es ist ohne E-Mail-Adresse.
Es ist ohne E-Mail-Adresse. Siehst du mal, wie oft ich mich da einlogge? Ich logge mich eigentlich so gut wie nie ein über, über HTTP-Authentifizierung. Bobloids ist es. Genau. Das ist richtig. Genau.
What the fuck? Äh. Geht das nicht wegen Zwei-Faktor-Authentifizierung?
Kann das sein, dass es wegen Zwei-Faktor-Authentifizierung nicht geht? Mit, mit Login hier. Muss ich über SSH Key machen?
Ok, Moment. Ich adde mal mein SSH Key von AVM. Dann mach ich euch mal kurz aus, weil ich nicht aus Versehen irgendwelche Sachen leaken will.
Äh, your profile? Äh, SSH, Moment. Wo waren die Edit Profiles? Nee, wo waren nochmal die SSH Keys versteckt? Settings irgendwo, ne? Settings, SSH Keys, genau.
Ich hab den Key sogar schon hinterlegt. Passt. Ich hab den Key schon hinterlegt. Was im Endeffekt heißt, ich müsste das eigentlich pushen können, aber ich hab das falsche Remote dafür drinne.
Ähm, gut, dann ändern wir das Remote nochmal. Rider ONAK-S. Remote. Ok, Git, Remote. Äh, konnte man das irgendwie umbenennen?
Rename Z-Ul. Genau. Nee, da muss man Remote Z-Ul und da muss man glaub ich den Name machen. Origin und dann die neue Ul. Ähm, die neue Ul ist Git-Doppelpunkter.
Ah, hier guck mal da. So. Ok, push. Yes. Ah, yes. Exzellent. Da sind wir. Leute, also, nur gepusht, weil mich sonst der Chat geflamed hätte. Ah, ja, ja.
Da ist es. Exquisite high quality HTML und äh, state of the art best practice, ähm, ASP.NET Core Anwendung mit unsafe code und ähm,
irgendwelchen komischen Background-Tasks im Startup. Beste. So, so solltet ihr das machen. Ist da Tommy K. eigentlich da? Wie lief's da mit der Bewerbung?
Ich hab irgendwas im Discord gesehen, aber ich würde mir interessieren, was da rausgekommen ist. So, Chat. Also, wir haben noch einen Bug.
Also, vielleicht ist ja einer Big Brain von euch und kann hier irgendwie das Reordering programmieren. Also, hier an der Stelle,
man, wie konnte man, konnte man so kommentieren oder konnte man nur mit einem Issue kommentieren? Nee, einfach so kommentieren geht nicht, ne?
Ähm, Frames sind in falscher Reihenfolge. ETS, PTS. So. Wenn, wir machen's mal auf Deutsch.
Genau. So. Excellent. Da ist es. Okay, ähm, ja, vielleicht, vielleicht hat ja einer Zeit
und Muße, sich da Sachen mal zu widmen. Der beste Projektname übrigens hier wieder, ne?
Erstmal, Monarch S. Ich kenn mich, ich werd das nie umbenennen. Also, Chat, vielleicht kriegen wir's echt gebacken.
Also, wenn, wenn von euch ein paar Leute Interesse haben, daran mitzubasteln, das Ziel der ganzen Sache ist, erstens, dass man,
relativ Latency-free, ich könnte hier, also, wenn wirklich ein paar mitmachen, weil ich kann da ne ReadMe erstellen,
also, ähm, das soll Latency-free Video in Browser kriegen und auf lange Sicht will ich damit halt mal ne halbwegs benutzbare
Video-, also, Überwachungskamera-Software basteln. Ja, ne, es ist 2114, ich geh jetzt gleich ins Bett.
Also sprich, ähm, Recorden ins File, das kann meine andere schon, äh, und eine der wichtigsten Sachen ist kein Re-encoding.
Kein Re-encoding. Schau mal in GRPC rein, ich weiß, was es ist, ich wüsste jetzt nicht, was es mir hier bringt.
Ähm, kein Re-encoding, also sprich, ich will den Stream von der Kamera nehmen, in den Browser pumpen oder vielleicht in ein File schreiben.
Kein Re-encoding. Re-encoding ist so ein optionales Ding, da würde ich drüber nachdenken, wenn wir mal irgendwas haben, was stabil funktioniert.
Weil eines der Features, die ich hier haben will, ist, ich will nichts re-encoden.
Ich will einfach nur den Stream nehmen, von der Kamera und in den Browser packen.
Das hat den Vorteil, man braucht überhaupt keine Leistung, ich mein, guckt euch das mal an.
Ähm, ich, ich, ich starte das Kart noch mal, hier, Run.
Ich starte das Kart noch mal.
So, Run, hier, anmachen.
Ups, ah.
Ja, gut, ähm.
Das bringt jetzt nicht viel, zu gucken.
Ähm, aber, wenn ich jetzt, ah, warte.
Das braucht nix.
Ups, drottnet.
Boah, das ist, das braucht, das braucht nichts an CPU-Leistung.
Um das zu streamen.
Würde der re-encoden, wäre das ein bisschen mehr.
Und das ist grad der Sinn und der Zweck der Sache, der re-encoded nix.
Ähm, was dann richtig pro wäre, wenn wir irgendwann es schaffen würden.
Das habe ich ja schon überlegt und auch schon mal angefangen vor einer Weile so was zu bauen.
Ähm, man könnte, wenn man eben möchte, der Vorteil davon, wenn man nicht re-encoded ist,
du kannst auf dem Raspberry Pi das laufen lassen, auf dem Raspberry Pi mit, keine Ahnung, 30 Videokameras.
Überhaupt kein Problem, weil es eben nicht re-encoded.
Wenn ihr Software verwendet, die die Sachen decoded, encoded, da ist mit 2, 3 Kameras auf dem Raspberry Pi spätestens Schluss.
Selbst wenn man die Raspberry Pi Hardware-encoding, Decoding-Geschichte verwendet.
So, was man noch machen könnte ist, man könnte hergehen und wenn man sagt, okay, man möchte ein bisschen Leistung opfern,
man könnte jeden Keyframe decoden, so alle 2 Sekunden an ein Frame, schadet nix, jeden Keyframe decoden
und dort drauf dann Object-Erkennung machen oder sowas.
Aber das ist Zukunftsmusik.
Also wer sich dazu berufen fühlt, ein bisschen mit rumzubasteln, äh, wäre nice, jetzt wo ich schon hochgeladen habe,
denn vielleicht ist das ja für mich die Motivation, diese Software endlich mal ordentlich fertig nutzbar zu bauen,
über den Status hinaus, dass ich sie bei mir einfach, also wisst ihr, ich benutze bei mir lokal auch unfertiges Zeug,
was genauso viel enthält, wie was ich brauche.
Aber für jemand anderes benutzbar ist es nicht.
Bestes Beispiel ist hier mein Memboard für Bildchen und sowas, das funktioniert für mich wunderbar,
aber in die Version könnte niemand anderes ordentlich bedienen.
So und vielleicht, vielleicht wenn die ein oder andere mitmachen, habe ich die Motivation, endlich mal was Gescheites draus zu basteln.
Mal gucken.
Also Chat, machen wir Schluss, ich gehe ins Bett, ein nicer Stream heute, richtig viele da gewesen, für Programmer Stream, sehr nice.
Ähm, wir sehen uns.
Gifts, ach ne, wir sehen uns nicht, ich muss Saps giften, ich muss Saps giften, stimmt, Leute, das hätte ich ja fast vergessen.
Ich gifte Saps, easy, wie ging das nochmal?
Äh, Abos verschenken.
So, hier 5 Stück, bam.
Zwar, ich überweise quasi 12 Euro an Amazon, wenn man so will.
So, mal Chat, mal Chat, mal gucken wer Glück hat.
Aber ich bin der Meinung, Moment, fuck, aber ich bin der Meinung, das hätte sogar noch ein paar Prime Saps verdient heute.
Any Primers, das hat so gut funktioniert und es ist echt ein Thema, wo es so gut wie nichts an Beispielprojekten gibt.
Und das ist auch ein BigBrain Thema.
Da könnte man schon mal den einen oder anderen Prime Sub noch dalassen, wenn man noch einen Prime Sub übrig hat.
Nur mal so zur Information für alle, die es noch nicht mitgekriegt haben, wenn ihr einen Amazon Prime Account habt,
könnt ihr das mit eurem Twitch-Account verknüpfen und dann könnt ihr einen Streamer einer Wahl einmal im Monat kostenlos mit einem Prime Sub unterstützen.
So, wer hat denn was gekriegt?
Captain Falcon, Ponky, MB-Dealer, Robot Town und Business Raster, exquisite.
Wer hat schon Amazon Prime? Wahrscheinlich 90% der Leute, die zugucken am Amazon Prime.
Sehr schön, sehr schön.
Äh, Moment, was wollte ich jetzt nachgucken? Irgendetwas wollte ich gerade nachgucken. Achso.
Achso. Hier. Hier ist es. Monarch S. Exzellent. Gut, wunderbar.
Ah, nee, das ist, ich hab mich schon gefreut, das ist das Projekt-File. Ja klar, das braucht man.
Man muss sich mal überlegen, das ist echt nicht übel. Wir haben hier insgesamt, das ist alles Müll, das braucht man nicht.
Guck mal, wir haben 60 Zeilen HTML, 150 Zeilen C-Sharp. Das ist alles. Ach, nee. Und, okay, für 200 Zeilen C-Sharp, 60 Zeilen HTML.
Also das ist wirklich top, da kann man echt nichts sagen. Also die Library scheint ihre Sache gut zu machen.
Chat, wir sehen uns, nächster Stream, machts gut, bis dann, wir sehen uns, CU.
