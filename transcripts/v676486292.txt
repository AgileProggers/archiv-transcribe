Das war's für heute.
Bis zum nächsten Mal.
Das war's für heute.
Beconnect!
Das war's für heute.
Das war's für heute.
Das war's für heute.
Das war's für heute.
Und hat meine Statistiken angeguckt
Guck dich das mal an
Es sind Leute unfollowed, das geht aber nicht, da geht direkt die Abmahnung raus
Richt bebägers alles hier, kann man da unfollowen
In your face genau face gesicht sieben monate excellent subscription
Ich gehe jetzt einfach mal von aus das ist ein aufräum algorithmus der halt ein zuma drüber läuft in aktive accounts löscht
Vielleicht
Unfollowed ja auch wirklich der ein oder andere kann sein aber ich sehe das konstant immer die gleichen leute oft also oft oftmals
oft mal nicht immer aber oftmals die gleichen leute am start sind das ist schon mal echt nice muss man sagen
das ist mir auch viel lieber als auf youtube alles
zumal wir hier natürlich den
Ja
Ja also was machen wir heute ich habe es ja schon im letzten stream angekündigt
Ich wollte mir mal seit einer ganzen weile schon wieder zappix angucken
Also ich muss dazu sagen historie mit zappix
Habe ich ein bisschen ja ich habe vor jahren mal daheim versucht bissel zappix zu verwenden hat nicht funktioniert
Was war viel zu viel zu un
unübersichtlich und und durch
Kaum durchgeblickt
allerdings
Wir haben auf der arbeit zappix und zwar ziemlich großen zappix mit zig datenbanken und zig monaten history und teilweise
auch timescale
Timescale nicht timescale
Timeseries zeug jetzt drin seit der vierer version also auf der arbeit haben wir riesengroßen zappix und ich muss sagen
Es gibt ja so ein paar tools die findet man von anfang an scheiße
und umso mehr man sie benutzt
Um umso gleich scheiße bleiben sie
Und so war das bisher bei mir und zappix auch immer ich habe immer mal ein bisschen reingeguckt
Und habe gedacht na ok neue versionen die sind ja nicht schlecht und features sind auch nicht verkehrt und war was können wir da machen
Und ich habe ich habe mir zappix immer mal wieder angeguckt
Zuletzt glaube ich als die vierer version rausgekommen ist oder so ich fand es immer noch nicht gut und ich habe die doofe vermutung
Ich finde die fünfer version jetzt auch nicht besser
Aber man muss dem ganzen zeug ja mal eine chance geben
Und wir gucken uns das heute mal an. Wer nicht weiß was zappix ist ich probiere es mal kurz kurz zu erklären
Das ist eine software fürs
Infrastruktur und server monitoring also sprich damit kann man zum beispiel überprüfen wobei wir können wir lesen uns mal den
Werbetext von zappix durch
By the way das bild gehört nicht zur zappix webseite das kann man nämlich denken weil mein memeboard ist mittlerweile so
Perfekt integriert mit transparenz man könnte fast meinen es wäre echt
Wir gucken mal was die selber sagen so solutions ach du scheiße blickt ja keiner mehr durch mittlerweile
Da steht nicht einfach nur was ist es about about us
Das sind die kommen aus russland glaube ich
Also hier hardcore
Explore what's new ja das war mal gleich so ok wo wo sagen sie denn was es ist product
Zappix features bringt die richtig coolen leute die richtig coolen leute sprechen es auch nicht nicht zappix aus sondern
zappix also wer richtig richtig
Nice ist da sagt zappix
Aber ich sag nicht zappix ich sag zappix gibt genauso die leute
die
die
Das ist ja auch so eine sache wo sich drüber gestritten wird heißt es jetzt knippex oder heißt es knippex offiziell
offiziell heißt es knippex aber
Alle die ich kenne sagen knippex ist so ein bisschen klaubsfrage
Wobei eigentlich eigentlich bei knippex ist es gar keine klaubsfrage der hersteller selbst sagt er heißt knippex
Aber trotzdem sagt jeder knippex aber so ja
So also was was sagen wir denn was ist zappix also
Ich wollte es euch ja in meinen worten erklären aber das ist natürlich viel besser das ist die ultimate
enterprise level
Software designed for real-time monitoring of millions of matrix collected from tens of thousands of servers virtual machines and network devices
Also big brain software zumindest wenn man das der ganzen sache hier klaubt also ums war unter bestricht zusammen
sagen zappix ist ein software mit der ich meine server und meine infrastruktur
Monitoren kann und gucken quasi ob die server verfügbar sind
Ob die dienste auf den servern laufen ob die festplatte voll läuft ob der ram ausgeht ob
Irgendwelche container abgekackt sind neugestanden solche sachen also im heimbereich jetzt mal für ein heimbereich gesagt
ähm was man damit zum beispiel machen kann ist wenn man paar raspberry pies hat vielleicht ein paar esp32
sachen ein haus mit ein paar containern drauf also so im heimbereich ist die die einfachen geschichten dann kann man zum beispiel mit zappix gucken
Ist der raspberry pie im keller ist ja noch an also sprich pink das ding noch
So und wenn das ding nicht mehr pink kann ich dann sogar darauf reagieren also zappix kann actions das heißt wenn zappix
auffällt dass der
raspberry pie im
Keller nicht mehr pink dann könnte ich eine action machen die quasi meine
Wlan steckdose ein und ausschalten bis und dann fünf minuten warten und guckt aber wieder da ist und so was in der richtung also das
Zappix kann relativ viel dann könnte man zum beispiel noch schauen ok ich hab nen
Nextcloud laufen da kann ich zum beispiel zappix auf nextcloud auf dem solver gucken ok wie sieht es mit der festplatte aus ist die langsam voll
oder läuft überhaupt nextcloud drauf ist nextcloud erreichbar ist das ausgefallen kann ich mir eine
SMS schicken lassen discord nachrichten lassen eine teamsnachricht mich nur mich benachrichtigen lassen dass quasi gerade mein nextcloud ausgefallen ist
kann auch versuchen nextcloud neu starten zu lassen
oder sowas in der richtung ich glaube ich glaube die idee die idee hinter der monitoring software
ist eigentlich relativ einleuchtend so und so eine der
Uhr monitoring software schlechthin für die ich ja persönlich immer noch so eine schwäche habe ich weiß ganz viele leute sagen gehen wir mal weg
also ich muss das hier mal ganz groß machen jetzt was ich hier gleich in die suchmaschine eingebe also so eine der
Uhr monitoring software ist ja nach wie vor nageos
So und ich weiß viele leute finden nageos total eklig ich muss sagen nachdem ich mich mal
am anfang meiner ausbildung relativ lange um eine zappix installation gekümmert habe
seitdem mag ich persönlich nageos ich kann verstehen wenn man heutzutage nageos nicht mehr verwenden möchte es sieht auch
echt aus wie von 1995 ich gucke mal ob es nageos demo irgendwo gibt
Nageos admin okay probieren wir das mal aus gucken ob das immer noch so altbacken aussieht ja genau das sieht der nageos sieht immer noch
genauso kacke aus wie 1995
oder nee was ist das?
Nageos ist immer noch so kacke aus wie 1995
oder nee was ist das?
Nageos ist immer noch so kacke aus wie 1995
oder nee weil ich weiß nicht von wann das ist 1999 okay ich hab nix gesagt ja also
zappix äh nicht zappix nageos sieht immer noch genauso kacke aus und damit hab ich
so meine ersten geguckt euch das mal an das sieht wirklich ab abgrundlich schlecht schlecht aus
all wirklich wie eine sache von 1995
das war so die ursprüngliche monitoring geschichte die ich damals als ich mit meiner ausbildung angefangen hab benutzt hab und ich muss ehrlich sagen ich mag nageos immer noch
aber nageos zumindest die äh die core-variante oder die source-variante ist so in der reinen
in der klassischen variante schon im handling ein bisschen eklig vor allem die nageos konfig dateien sind auch so eine sache für sich deswegen
benutzen viele firmen kein reines nageos mehr
sondern irgendwelche nageos forks oder irgendwelche andere monitoring geschichten ich muss übrigens mal den chat aufmachen sonst
äh übersehe ich die hälfte
irgendjemand hat im chat gefragt
einen moment ich hab doch mal mein fragen log tool an
wollen wir hier reingucken
so
das war von gestern, das machen wir mal weg
hast du zufällig eine erklärung
wieso ich mein g-force toys nicht aktualisieren kann tippe irgendwie auf open sense obwohl du es nicht kennengelernt hast
also ich hab jetzt mal ein bisschen was gesagt
zufällig eine erklärung wieso ich mein g-force toys nicht aktualisieren kann tippe irgendwie auf open sense obwohl die harte tp
äh also solange du halt nicht irgendwelche proxy-geschichten machst keine ahnung
proxy ist im heimbereich also ausgehend der proxy ist eh meistens komplett useless
das einzige was ich mir gefallen lasse proxymäßig ist vielleicht so ein windows update server oder sowas
dass daheim brauchst du es eigentlich weniger nee hab ich keine ahnung ehrlich gesagt kein schauber
kann ich jetzt auch schlecht was zu sagen wenn ich nicht weiß wie es bei dir aufgebaut ist
mit was für monitoring system hast du mich jetzt erfahrungen gemacht also das kann ich euch mal zeigen
also wie gesagt hab ich auch gerade gesagt nagios kenne ich mich eigentlich ganz gut mit aus
äh weil das das erste system war was ich hier verwendet hab ich mach mal kurz den dark reader off
es ist mein es ist 14.45 da halten wir es mal kurz ohne dark reader aus
so dann hab ich erfahrungen mit grafana und prometoys das ist eigentlich eine ziemlich gute kombination
da hab ich zum beispiel mein dashboard für die heizung mitgemacht
also das hab ich jetzt ja schon ein paar mal gezeigt das ist ein dashboard von meiner wiesmann heizung im keller
wo man sehen kann welche temperatur der brenner gerade hat ob das ding fehler ausgeht
welche kessel temperatur ob der brenner arbeitet ob die pumpe was macht ob wie die abgas temperatur ist und sowas
das ist eine kombination aus grafana und prometoys und das ist ehrlich gesagt für den heimbereich
auch aktuell meine bevorzugte variante weil es halt super einfach ist einzurichten und irgendwo auch modern ausschaut
ja und auch modern benutzbar ist was man von nagios nicht unbedingt sagen kann
es ist allerdings auch gleichermaßen im enterprise umfeld verbreitet also prometoys monitoring grafana
in kombination ist mittlerweile mainstream angekommen ja und es taugt auch wir haben auf der arbeit auch
wir haben so eine 24-7 support haben so eine fette monitoring wand vorne hängen gesagt ich habe ja erzählt
ich sitze da mittlerweile öfters also ich bin nicht im 24-7 support aber ich sitze dabei ich sitze ja gar nicht
bei dem team wo ich wo ich wo ich eigentlich im team bin damit die auch ansprechpartner haben wenn mal
irgendwas kaputt ist dass man dann aus dem verstehe ich mich mit denen ganz gut zumindest dort haben wir so eine fette
monitoring wand hängen mit irgendwie zwei mal zehn fetten monitoren also das ist ein riesen ding wir haben uns schon
überlegt ob wir den nicht nicht mal ausprobieren sollen ob man da irgendwie einen zug durchfahren lassen
könnte über die monitore aber bis jetzt ist es da noch nichts eingefallen monitor wand
man irgendwie so was man schönes beispielbild sieht von ja ja ungefähr so sieht das da vorne aus ja
zwei rein und so was hier und da haben wir auch ein paar grafana sachen drauf die über prometoys
eingesammelt werden dann gibt es mittlerweile was auch sehr angesagt ist ist die ganze kombination
aus elastic surge und lockstash kibana da habe ich aber persönlich noch nicht so viel mit gemacht
aber das ist gerade sehr angesagt ja lassen wir überlegen monitoring system mit ich was gemacht
wie gesagt nagios zabbix grafana prometoys das habe ich was habe ich sonst noch gemacht dieser prometoys
auch mit mit eigenen exportern und so was also komplett eigenen exportern also wie gesagt das
ganze heizungszeug ist ein eigener prometoys exporter also sachen wie ab time robot zählen
wir jetzt mal nicht zu monitoring was übrigens ganz praktisch was was übrigens ganz cool ist
wer das ich glaube die seite war das wenn es die free gibt free pricing free free das ist eigentlich
ganz cool wenn man eine webseite hatten einfach nur wissen will ob die webseite oben ist kriegt man
sogar ein benachrichtigung aufs handy geschickt das ganz nützlich wenn man sonst nichts braucht
außer gucken dass eine webseite oben ist ja ich glaube das war so viel mehr fällt mir da jetzt
nicht ein ach so kakti kakti hatten wir noch netzwerk gedöns und ein bisschen libre nms habe
ich auch rumgespielt genau das war ein design habe ich ganz vergessen für netzwerk geschichten
eigenen exporter in go nee der export in haben wir die haben wir sogar im stream programmiert
der exporter ist übrigens gerade nebenbei maß gesagt so süßling fragt ist wim besser als nano
also von der einstiegshürde nicht von den funktionen eindeutig ja archiv hier geht es zur
neuen archivseite die neue archivseite geht immer noch nicht oder mit also immer noch nicht das
ist ja komplett freiwillig ja also ich will euch jetzt eigentlich vorschreiben dass ihr das machen
müsst aber die geht immer noch nicht mit suchen oder also ich kann jetzt nicht irgendwie nach
heizung suchen und und da findet er keine streams ok weil wir haben den stream gemacht für was mit
prometheus ja das hier guck mal gasheizung überwachen smart home grafana prometheus
rfp c sharp dotnet also wir haben einen prometheus exporter in dotnet programmiert was das archiv
ist brauchen warum ist das brauchen ich habe das nicht programmiert das ist nicht mein archiv warum
was ist da dran procken das geht kukier da archiv ja ich weiß dass es mit watts nicht geht das
neue archiv scheint ja auch kaputt zu sein du musst über den google drive ordner gehen das
ist in dem fall eigentlich ganz einfach so und das haben wir gemacht am 2.2020 am 2.2020
gasheizung irgendwas heizung hier also nachdem jemand gerade gefragt hat wie man das gemacht
haben wir haben ein prometheus exporter programmiert damals in mit kogas in dotnet
und anscheinend funktioniert er hier schon ich bin jetzt gar nicht sicher wo ich den
kran programmiert habe ehrlich gesagt irgendwo hier im stream habe ich den kran programmiert
kogas hier die letzten paar minuten bin ich da am rumwürsten drin
wie auch immer also ich glaube ich habe danach noch einen stream gemacht wo wir das fertig
programmiert haben so ich glaube es sind zwei watts es kann sein dass man dem ein wort nicht
fertig gefertigt geworden sind also haben ein prometheus exporter ich kann es dir auch mal
zeigen 1 2 2 1 6 8 1 punkt 5 1 slash matrix ich hatte tps hallo warum g bait mich mein browser
hallo ein what the fuck aber moment weiter für den doppelpunkt moment was ist was geht
hier gerade ab moment habe ich die falsche habe ich die falsche ip 1 9 2 1 6 8 1 1 5
1 moment what n map 1 2 3 4 5 aha ok 1 2 3 4 5 excellent port genau
also hier sieht man die sachen die damals vom prometheus exporter die die die exportiert
werden und live ausgelesen werden von der heizung also bla bla bla das ist dort nett gedöns
sind richtig hier abgas temperatur fehler brenner wasserkessel kocht gedöns temperatur pumpe
und und die zieltemperatur ja so sieht ein prometheus exporter aus nämlich das coole
ist am prometheus an prometheus monitoring dass der zabbix um mal wieder zum eigentlichen
thema zurückzukommen dass das zabbix zeug mittlerweile angeblich auch das habe ich noch
nicht ausprobiert das probieren wir heute nehme ich mal aus angeblich auch prometheus
zeug kann und ich will es einfach mal ausprobieren ob mich jetzt mittlerweile überzeugt ich meine
persönliche vermutung ist nein weil es mich bisher nicht überzeugt hat weil zabbix ist
von der konfiguration her eines der ekligsten tools die ich kenne aber wir werden uns das
ganze jetzt mal der reihe nach der reihe nach angucken also es ist eine der der unintuitivsten
sachen erklärt was zabbix ist habe ich wie gesagt hier hier labern sie noch ein bisschen
drumherum das coole an zabbix ist und da gibt es finde ich auch zumindest kenne ich nichts
nichts vergleichbares was so viel unter einer oberfläche kann zabbix kann history zabbix
kann trends zabbix kann grafen zabbix kann quasi so grafana mäßig grafen screens zusammen
stellen die unterschiedlichsten eingebauten checks erweiterbar über so eine art plugin
store was kein store ist wohl einfach vorgefertigte sachen drin sind also zabbix kann eigentlich
mehr oder weniger alles was es gibt es gibt ich würde mal sagen monitoring technisch
gibt es fast nichts was man nicht irgendwie mit zabbix machen kann die sache ist bloß
die dass die konfig davon und das interface dass das interface fühlt sich sehr altbacken
an nicht ganz so altbacken wie nagios aber altbacken und die konfig ist wirklich eklig
so das gucken wir uns jetzt mal an also als erstes fangen wir mal an ähm wir machen uns
mal nen ubuntu 20.04 container und installieren zabbix drin wir haben jetzt zwei varianten
entweder wir nehmen das offizielle das offizielle zabbix docker compose oder ich installiere
es selbst und ich installiere es in dem fall mal selbst weil ich habe bei denen gelesen
dass die installation vereinfacht wurde mal gucken das letzte mal wo ich das installiert
habe war ein bisschen ekliges rumgewurstet mal gucken ob das jetzt immer noch so ekliges
rumgewurstet ist müssen wir mal gucken also als erstes machen wir uns mal nen container
mit ubuntu 20.04 also lxc lounge ubuntu 20.04 ja ist wurscht wie das ding heißt excellent
ja er möge starten starten ah ok was auch immer der verschmerzen hat das smart gorilla
excellent big brain harambe am start äh ja das diese downloadgeschwindigkeiten hier
würde ich jetzt mal mit vorsicht genießen was der da macht wahrscheinlich hatten wir
den container schon zum größten teil da das ist das ist blödsinn ah wir haben ein
lokales interface wann funktioniert das überhaupt dann ich glaube das muss sich ändern und auch
nicht wir probieren es mal äh mal mal ne bash so und jetzt haben wir unseren ubuntu ubuntu
20.04 haben wir am start da können wir jetzt den subx drauf inszenen erst mal update neueste
pakete ich mache das aus dem grund in einem lxc container weil lxc container ist relativ
ähnlich zu einem eigenen installierten zu einer eigenen installierten vm ohne ne vm
zu sein und ähm ich schmeiße den container weg und es ist danach auch alles wieder fort
klar kanns mit docker auch machen aber wenn man es von hand installieren will ist es viel
einfacher in lxc weil man hat halt mehr oder weniger nen fertiges betriebssystem was man
benutzen kann also mit shell mit paketmanager und allem das ist ja bei docker nicht so der
witz hinter docker ist ja gerade dass nichts dabei ist außer die anwendung welche distro
benutzt du das ist benutze ich seit jahren schon seit 5 6 jahren oder vielleicht sogar
schon länger das ist man jaro mit i3 als des als als display manager äh nicht display manager
window manager so ab upgrade
reboot das schöne ist so containers sind halt sau schnell wieder gestartet so komme ich
auf die kiste überhaupt drauf aber irgendwie 8000 äh moment äh minus l war das 8000 ja
funktioniert ok übrigens wir haben das jetzt das ist auch eine sache kann ich vielleicht
mal kurz zeigen wenn ihr wissen wollt ob ne verbindung funktioniert von einem rechner
zum anderen ähm ihr könnt mit also ihr könnt entweder nc oder netcat machen minus l für
listen port 8000 dann macht ihr auf dem server ähm also auf dem auf dem äh host macht ihr
nen tcp port auf auf port 8000 und da läuft zwar nichts dahinter außer in dem fall netcat
was nicht antwortet aber wenn ihr mit dem browser da drauf geht seht ihr hier den request
vom browser das heißt wenn der request vom browser ankommt könnt ihr euch sicher sein
die connection hat funktioniert von einer zum anderen netcat ist eh absolutes big brain
tool ich glaube netcat ist die ähm die linux implementierung nc nee nc war nc nicht die
linux implementierung netcat die bsd implementations eins von beiden oder vielleicht ist es sogar
gealias jetzt ja ähm aber das ist absolutes big brain tool damit kann man ziemlich viel
ziemlich viel machen ziemlich viel ausspringen man kann damit sogar wenn man richtig big
brain ist kann man mit netcat sogar dateien übertragen von einem rechner zum anderen
also man kann in man kann in netcat kann man ich versuch das jetzt mal ich versuch das
mal zu zeigen also wir machen jetzt hier echo 1 2 3 äh nach ähm nee wir machen netcat
minus listen auf port 8000 dann in in die datei blub.txt schreiben wir den output rein und
jetzt machen wir echo 1 2 3 pipe nach netcat minus äh port 8000 ich glaube das ging jetzt
so bin ich mehr aus dem kopf aber nehmen wir sicher äh was wie hab ich nicht drauf was
warum nicht ja was nehmen wir das oh was nehmen wir das knu das knu netcat oder das bsd wir
nehmen das bsd netcat so jetzt jetzt pass auf big big brain wenn ich das richtig gemacht
hab äh missing port number war es minus p ne ja ja ja aber leerzeichen yep so äh hab
ich das jetzt richtig gemacht und wenn ich jetzt hier in die datei reingucke blub.txt
wie sehen wir da steht 1 2 3 drin excellent also das heißt man kann da drüber dateien
übertragen das ist die die die die rohste form von datei übertragung die man irgendwie
also alles andere ist bits abtippen oder bytes abtippen besser gesagt also viel lowleveliger
kann man das nicht mal machen als mit netcat das ist eine nackige tcp verbindung über
die plaintext der ganze kram drüber läuft ist aber manchmal echt praktisch zum beispiel
wenn man auf irgendeinem datenbank cluster node ist und einen datenbank backup machen
will mysql dump auf irgendeinen anderen server dann ist das mit netcat sehr praktisch weil
da machst du hier vorne einfach dein mysql machst du hier vorne dein mysql dump hin schiebst
nach netcat auf dem anderen server gut ist ist praktisch zum beispiel wenn man keinen
platz auf dem eigentlichen server hat es gibt noch 100.000 andere varianten wie man das
machen kann man kann den ssh fs machen man kann das ganze auch über ssh rüberpipen
ne scp geht nicht scp geht nicht scp geht nur wenn du die datei deinen dampf vorher lokal
ablegst auf dem server wo du es machst und da hast ja nicht genug speicherplatz aber
was man machen kann ist man kann das über ssh rüberpipen das funktioniert man kann
es aber auch über netcat machen netcat dürfte einen ticken schneller sein am ende scp geht
nicht scp geht nur auf datei ja so jetzt mal am rande ich muss ja hier meinem moment wo
ist es netcat ist aber nicht sicher nö ich sag ja auch plaintext wer will schon einen
datenbank dampf verschlüsseln übertragen habe ich noch nie gehört dass das jemand machen
will warum sollte man sowas denn machen so und zwar was hier fehlt ist was hier nicht
angezeigt wird ist das ist das ist fail dass es nicht angezeigt wird hier steht normalerweise
noch educational dabei das ist irgendwie irgendwie irgendwie ist das untergegangen
lehrreich steht da noch dabei normalerweise lehrreich aber man sieht das jetzt nicht
steht bei dir okay bei mir steht das könnten nicht man weiß nicht warum ich weiß nicht
warum es bei euch steht bei mir steht es nicht das kann man mit netcat machen genau bei mir
steht bei mir steht deutsch programmierung und softwareentwicklung der ganze andere kram
steht da nicht dabei wie dem auch sei ja aber also erst mal ihr steht dabei ihr kann man
nicht raus machen frag mich nicht warum keine ahnung das steht automatisch drin das kann
ich nicht löschen so und wenn man es über netcat macht dann ist das ganze nicht verschlüsselt
das muss einem klar sein so ganz große big brain datei löschen ja kannst du ich würde
ich ich mache die meisten sachen auch über ssh aber ich wollte sie an der stelle nur
mal zeigen mir netcat geht das auch wunderbar so also wir wollen es ab ins installen zeig
mal wie sagen sie denn offiziell dass es funktioniert download aha install packages from 5.0 lts
für ubuntu so 2004 postgres nginx also mysql plus apache ich weiß nicht warum das der default
ist also wer sich wer sich mit unleserlicher aufgeblähter konfig rumschlagen will da kann
das ruhig mit apache machen ob man jetzt mysql oder postgres nimmt man es einmal dahingestellt
wenn man time series sachen speichern will ist das mit postgres sinnvoller weil es für
postgres gibt es timescale db und ich weiß nicht ob es für mysql was gibt allerdings
nichts was zapix unterstützt ja es macht switch geht mir genauso also apache konfig
ist abgrundtief eklig wir haben noch jede menge apache konfig auf der arbeit rumliegen
und ich drück mich da seit jahren davor was dran zu machen entweder evade ich das immer
geschickt dass es dann jemand anderes machen muss oder ich rede mich raus mit euch da keine
ahnung von hab oder dass es nicht mehr supported ist das system irgendwie also ich hab schon
die letzten fünf jahre nichts mehr an apache konfig gemacht und ich hab es auch nicht vor
also da ist nginx auch nicht gerade jetzt irgendwie ein musterbeispiel für super lesbare
konfig aber im vergleich zu apache konfig ist es viel besser so so so gern ich so gern
ich traffic mag für docker und docker compose container setups als reverse proxy mit ein
bisschen webserver muss ich sagen die traffic konfig seit version zwei ist auch absolut
eklig meine lieblings konfig was webserver und proxy angeht ist das hier nicht das aussieht
ist der hier das ist von der konfig her der mit abstand am angenehmste also wer den webserver
mit reverse proxy und sonstige sachen da drin braucht und einfacher konfig sucht ist der
mit abstand der beste finde ich also wir wollen das ganze auf postgres machen mit dem nginx
stuff for install topics ok also erstmal ein paar sachen runterladen von denen alles klar
machen wir easy soweit kein problem easy ab montag wird sich dann in der haft ab das
seinem chef gemeldet ja alles klar glaube ich dir sofort chat kommt ja ohne apache aus
ja anscheinend das ist eben php php geschwuppel topics was c2 ho sagt zu meiner frage vorhin
hab den pc mit dem iphone hotspot verbunden und da kann ich geforce zeugs runterladen
im laden blockt mich die open sense die anfragen auch block deine open sense dinger nach in
video hast du irgendeine dns dns werbefilter drinne und nvidia ist irgendwie drauf gelandet
warum nicht jetzt ja kann man auch nehmen ich zinger ich zinger wie man das ausspricht
kann man auch nehmen aber wenn ich was nagios basiertes nehme leute sollte ich jemals wieder
was nagios basiertes machen dann nehme ich den richtig oldschool klassischen nagios mit
text konfig so ne doch update das war es schon das war jetzt einfach gewesen und jetzt kommt
ja jetzt kommt ja eigentlich erst das interessante so was haben wir hier install zappix server
install zappix frontend php php 74 postgres zappix nginx konfig zappix agent hört an
auf gehts also wenn dein open sense einfach nur ein bisschen router mit nutt macht dann
wird mich das sehr wundern wenn das nvidia zeug blockt ich hatte es ja auch eine weile
aber man weiß ja nie so genau wo ich was mir bei open sense nicht gefallen hat ist dass
die updates öfters in die hose gegangen äh was hat er da für schmerzen gehabt gerade
also immer ok was ich weiß nicht was er uns da acht es ist einfach nur status ausgabe
nix nix bildes so also haben wir das gemacht creating initial database ok sudo brauchen
wir nicht postgres create user postcray haben die sich verschrieben
das stimmt doch gar nicht das richtige kommando ist doch pgsq ne psql psql ist das doch psql
ich bin ja auch blöd in dem fall hat es sogar einen sinn dass der sudo davor steht
der wechselt erst mal in den user postgres und führt dort dann dieses kommando aus ok
dann dann ergibt das sinn was der hier macht alles klar vielleicht sollte ich einfach die
anleitung sind sinnlos brain dead kopieren anstatt da versucht mitzudenken
also operation permitted juckt uns nicht auf root braucht er auch gar keine permissions
dampf korn brandwein abonnieren twitch prime dankeschön excellent subscription big brain
chat iq geht heute wieder durch die decke so viele subs stonk subscriptions ok password
123456 excellent password da kommt nie einer drauf so dann will der eine datenbank anlegen
hast du ab auf manjaro nein das ist ein ubuntu 2004 wo ich gerade eingeloggt bin so hat das
jetzt funktioniert er meckert hier irgendwie was von wegen root ich nehme das jetzt einfach
mal dahinten so hin dass das jetzt funktioniert hat so an dem topics house import initial
schemas und daten you will prompted to enter newly created password ok machen wir ich würde
es einfach mal brain dead aus alles klar ok insert no lines na alles klar sieht ja ganz
toll aus was der da in meine datenbank einfügt ganz viele nuller und einser ist eine binary
datenbank die kann ich mehr doch hier oben ja es passiert noch ein bisschen was ja der
macht tatsächlich dinger ok juckt mich nicht hat funktioniert ist ohne fehler durchgelaufen
konfigure database vor zubik server ich möchte aber die time series datenbank verwenden noch
die haben jetzt nämlich was neues habe ich gelesen time scale db wie funktioniert das
denn oh what the fuck weiß ich ob sich das lohnt überhaupt wie installiert man das time
scale db 20 04 ubuntu habe ich noch nie verwendet soweit ich weiß ist time scale db eine post
crest extension eine eine pot post crest extension die optimiert ist auch time series datenbank
abzulegen also quasi mehr oder weniger wie viel kann man time series beschreiben mehr
oder weniger key value mit einem time stamp als als key trifft es das halbwegs wie kann
man time series am besten beschreiben ok big brain alles klar so leute ich hoffe jetzt
ist jetzt jetzt braucht es keine erklärung mehr oder ich glaube jetzt ist alles erklärt
ne time series database will ich gucken dann eine schöne erklärung für auf englisch dann
muss ich jetzt auch noch also in flux db ist so das bekannteste davon waren es gerade die
amerikanischen korona zahlen kann durchaus sein ne eher nicht wie findet ihr fedora
ich mag es nicht so also wie gesagt in flux db prometor sind so die bekanntesten sachen
zumindest wenn man halt viele daten kriegt mit einem mit einem time stamp als als key
das ist was wo sich so eine traditionelle relationale datenbank nicht so gut eignet
da hast keine verknüpfung großartig oder sonst was aber dafür unglaublich viel daten
mit zeit stempeln und dafür ist so was wie eine time series database ganz gut nachdem
es jetzt auch support dafür hat kann man dieses timescales db die timescales db extension verwendet
das probieren wir jetzt nämlich mal aus wie installiert man timescale db auf ne ubuntu
ok die haben das schon mal ein eigenes repo für das schon mal das schon mal gut zu wissen
ja update und dann install postgres 12 ich bin mir gar nicht sicher ob wir hier unter
überhaupt postgres 12 installiert haben abt search postgres guck mal was wir da für
ne version haben äh äh hat das ding nicht nen filter wo man nach install filtern kann
weil wir können die billig variante machen installt ähm wir haben postgres 12 was ist
xabbix xabbix das ist eine software mit der du deine infrastruktur und server monitoren
kannst und prüfen kannst ob die server laufen ob services laufen und sogar actions durchführen
kannst wenn sie nicht mehr laufen aber ich mag xabbix nicht und mal gucken ob sich das
mit version 5 geändert hat ok also installieren wir das mal mit version 12 yes configuring
time timescale db tune ah yes dann tunen wir das jetzt mal auf gehts leute wird getunt
also was wollen die wollen die haben von uns postgres 12 ist this correct yes alles klar
ist yes ich hab keine ahnung was ich da mache übrigens tunen memory yes ah ja alles klar
easy also ich würd sagen es ist ja komplett offensichtlich dass diese settings richtig
sind anders kann man das jetzt auch gar nicht sehen ich mein random page coast 1.1 ja natürlich
was denn sonst was äh was wäre denn die alternative zu xabbix also die klassische alternative
zu xabbix wäre sowas wie nagios beziehungsweise einer der 30 milliarden nagios forks oder
vielleicht so ein bisschen was wie libre nms wenn es so eine klassische monitoren sache
sein soll bisschen moderner ist die kombination aus prometheus krafana oder aber auch kibana
elastic surge log stash und sowas ich persönlich mag ja krafana und prometheus allerdings es
gibt ein paar sachen die sind in krafana also der unterschied ist eigentlich hauptsächlich
mal also ursprünglich gewesen mittlerweile verschwimmt das auch immer mehr xabbix ist
eine klassische monitoren lösung das heißt du hast irgendwo einen zentralen server wir
gehen jetzt mal von der reinen lehre aus ja du hast irgendwo einen zentralen server dort
hast du eine ein inventory wo drinnen steht welche host mit welcher ip adresse existieren
und dann definierst du darin was du checken willst und diese checks werden dann ausgeführt
quasi so blackbox mäßig gegen den gegen das system was du einträgst die nächste stufe
ist es gibt einen agent den installierst du auf dem system dann kann der zabbix server
zum agent gehen und der agent führt die checks aus aber es ist alles zentral gesteuert so
dementsprechend ist es auch ziemlich schwierig von anwendungen laufzeit informationen raus
zu bekommen also hast du zum beispiel also was damit super funktioniert ist du willst
checken ob eine webseite erreichbar ist gar kein problem du willst checken ob ein server
von dir erreichbar ist ob dort gewisse ports offen sind ob ssh erreichbar ist ob eine webseite
antwortet und gewissen regex enthält das ist zabbix oder nagios oder libre nms ist ganz
ganz toll das kann auch snmp geschichten um netzwerk infos abzufragen oder ipme um irgendwelche
infos vom management interface abzufragen also wenn man einen zentralen server haben
möchte der für einen das monitor übernimmt dann ist zabbix wunderbar das ist die klassische
variante was sind zabbix ein bisschen schwieriger ist traditionell ist es halt wenn sich umgebung
schnell ändern also wenn man zum beispiel jetzt in den container basierte deployment
geschichte hat und sagt ok morgens habe ich relativ wenig user und mittags habe ich ganz
viele user morgens sind es dann quasi nur vier container abends sind es dann 30 container
das geht mit zabbix mittlerweile auch alles wird aber schon ein bisschen komplizierter
ist wo zabbix traditionell so ein bisschen probleme hat sind eben metriken beziehungsweise
laufzeit infos von anwendungen rauszubekommen also mal angenommen ihr programmiert eine
anwendung eine web anwendung so und diese web anwendung hat intern sammelt ein paar
statistiken zum beispiel wie ihr habt eine web anwendung ihr habt einen forum programmiert
ja und dieses forum zählt wieviel aktive user gerade sessions connected sind wie soll
zabbix an diese informationen kommen das ist was was man vielleicht gerne in seinem
monitoring drinne hätte weil man ja wissen will wieviel user benutzen gerade das system
wieviel user sind gerade eingeloggt weil es vielleicht ja auch dafür relevant ist was
weiß ich lizenzgebühren oder einfach nur weil man wissen will wieviel die software
ab kann ab einem gewissen schwellwert wird es kritisch wie auch immer so das ist recht
schwierig rauszubekommen es sei denn man exportiert aus der anwendung raus diese metric und da
kommt halt prometheus ins spiel das geht mit zabbix auch alles ja also man kann die anwendung
aufs feilsystem statistiken schreiben lassen man kann die anwendung an den zabbix server
auch statistiken pushen lassen man kann auch es ähnlich machen wie es prometheus macht
quasi dass man eine webseite macht und dann die daten rauspasst von der statistik webseite
geht alles aber das ist bisschen umständlich in traditionellen monitoring lösungen und
auch zabbix zabbix muss man sagen macht viel die haben auch sehr viel angepasst auch in
version 5 da geht es auch immer mehr Richtung cloud und container deployment geschichten
die unterstützt werden aber das ist so traditionell das wo nicht gerade die stärken von nagios
und zabbix und libre nms und solche geschichten liegen so und da kommt es prometheus ins spiel
prometheus ist zwei sachen einmal ein monitoring tool und eine datenbank für history also sprich
für eine datenbank eine time series datenbank wo man monitoring werte metriken drin abspeichern
kann und das schöne an prometheus ist prometheus gibt es also libraries gibt es für nahezu
alle programmiersprachen sei es dort net java python go alles und man kann quasi die das
metric exportieren ziemlich einfach in seine anwendung einbauen und ich habe es ja gerade
gezeigt zum beispiel wir haben einen eigenen metric exporter programmiert für meine heizung
unten das ist dotnet programm wenn man hier abfragt sieht man auch interne werte von diesem
dotnet programm hat zum beispiel wie groß ist der ram verbrauch gerade wie lang läuft
die software schon und halt auch die sachen von der heizung und dementsprechend ist es
ziemlich easy die metriken zugänglich zu machen mit irgendeiner prometheus client library
so und dann hast du den prometheus server der geht einfach nur hin und fragt die metriken
ab aber nachdem das format halt definiert ist wie das funktioniert wie das aufgebaut ist
es für prometheus möglich die sachen ziemlich schnell und effizient in einer eigenen datenbank
zu speichern das heißt man kann mit prometheus ziemlich viele also ziemlich viele sachen und
auch schnell unterschiedlichste anwendungs statistiken abfragen da ist jetzt nicht so
toll drin wie gesagt es wächst immer mehr zusammen da sind so die die bis bis also die
größten unterschiede die immer weiter auch als jetzt verschmelzen ja so und dann braucht
man ja damit prometheus noch in irgendeiner art und weise nützlich ist noch ein frontend
weil was bringt einem ein programm was metriken einsammelt und sie in der datenbank speichert
wenn man sich die werte nicht anzeigen lassen kann und dafür benutzen die meisten leute
grafana und da kommt dann so was hier raus da kommt dann so was hier raus also sprich
das ist ein prometheus exporter bzw prometheus der die daten von meiner heizung einsammelt
und grafana zeigt die sachen an was man jetzt daran schon sieht ist das prometheus mehr
wert legt auf quasi inhalt also auf metriken weniger auf so die klassischen sachen wie
der host ist ab der host ist daun das kann man mit prometheus auch alles machen aber
dafür ist es nicht gedacht man kann mit prometheus auch so blackbox checks machen so nach dem
motto ich will einfach nur gucken ist webseite xy verfügbar das geht damit auch aber nicht
so schön also prometheus setzt ein bisschen drauf dass die daten die man abfragen will
auch abgefragt werden wollen also dass die das eben exportieren das sind so die klassischen
unterschiede aber wie gesagt das wächst beides immer mehr zusammen und topics kann mittlerweile
auch prometheus daten für arbeiten schon mal prtg gearbeitet nur mal ganz kurz ich
weiß es eine winnows only lösung ist also der server winnows only dementsprechend nur
ganz kurz mal irgendwo eine demo angeguckt und ist für mich nicht nutzbar weil ich meine
ganzen systeme auf linux habe also also so viel so viel zur erklärung was unterschied
prometheus und summix oder man ganz hip geht man die sars welt und nutzt ja datadoc ist
aber ziemlich teuer warum ist da so viel monka giga gerade
kannst du auch über telekam benachrichtigen vor topics aussenden ja glaub schon kann
man gleich kommen kennst du borg backup ja beste beste backup software ever huge hast
du mit topics schon angefangen ich habe topics gerade installiert oder ich bin gerade dabei
topics zu installieren so jetzt haben wir timeseries gedürt installiert was muss man jetzt machen
create ach nee moment wir waren auch gar nicht fertig ne getunt haben wir jetzt muss man
jetzt auch was machen danach postklasse neu starten ja das machen wir noch mal schnell
datenbank neu starten ist nicht verkehrt am besten live mittags um 14.30 immer sehr
beliebt datenbank neu zu starten so jetzt müssen wir das machen oh es funktioniert
oder welcome warning was auch immer scheint funktioniert zu haben ket timescale db sql
ok also es wäre nicht schlecht wenn in dieser anleitung stehen würde wo timescale db punkt
sql zu finden ist wo soll ich das wissen also so den ort reinschreiben wo das default
mäßig liegt wer vielleicht nicht verkehrt feind feind slash name da ist es das hätte
man auch dabei schreiben können das hätte man auch dabei schreiben können dann hätte
ich nicht suchen müssen so ket das in die datenbank ok guck mal ob das so funktioniert
anscheinend gut jetzt können wir da zappix anleitung weiter machen jetzt müssen wir
auch das haben wir schon gemacht ok konfigure zappix server alles klar db passport db passport
db passport ist absolute big brain passport 123456 nicht weiter sagen chat nicht verraten
konfigure zappix frontend nicht password leaking so listen auf port 80 ist ok server name example
nee server name machen wir mal ganz primitiv einfach die ip adresse ach nee die ip können
wir nicht nehmen doch die ip können wir nehmen wir können uns ja lokal drauf liegt ip liegt
schon wieder so und jetzt die zeitzone in php ups php php ist immer noch so extrem kryptisch
auch von konfig dateien das ist das liegt glaube ich daran weil php einfach traditionell
diese sachen verwendet hat hier berlin wenn ich da an andere web frameworks denke ist
überhaupt kein ding also dotnet core beispiels also asp dotnet core hat standardmäßig sinnvolle
default settings an denen man zu 95 prozent nichts drehen muss sogar sogar ruby on rails
hat sinnvolle default settings an denen man sich nichts drehen muss aber php erstmal hier
50 konfig dateien für alles mögliche ok restart zappix alles klar bäm jetzt enable zappix
das machen wir ok und angeblich sollte das jetzt funktionieren ja probieren wir mal aus
ip von meinem zappix server das hier ok man muss ihn zugute halten die installationsanleitung
haben sie vereinfacht die installationsanleitung für die letzte version war wirklich abenteuerlich
und die letzte version die ich ausprobiert habe die war abenteuerlich das ist viel schöner
allerdings fürchte ich das wird es nicht rausreißen so welcome next just php sachen was auch
immer next database postgres database ist lokal lokal zappix password 123456 was ich
jetzt nicht ganz verstehe ist ich musste hier irgendwie schon mal die ich musste hier schon
mal das password für die datenmark eingeben warum muss ich das hier nochmal machen verstehe
ich nicht zappix server details nope der da name name keck wie lul wie größer oder
ich glaube den mache ich kaputt wenn ich sonderzeichen namen rein machen das probiere
ich mal nicht aus cute zappix next pony torz ne cute zappix dann dann reiße ich mich vielleicht
zusammen dass ich das nicht so sehr flame wenn es gleich zur config kommt weil eins
kann ich euch schon mal sagen wenn die jetzt nicht grundlegend mal das web interface aufgeräumt
haben werdet ihr gleich zeuge einer der am eklig zu konfigurierenden anwendungen mit
web interface aller zeiten ok next step congratulations you have successful installed zappix zappix
frontend ist am start zappix so ok ja zappix default pass password ich glaube admin admin
mal gucken ob ich so richtige erinnerungen habe admin admin nein habe ich nicht richtige
erinnerungen admin zappix muss man das groß schreiben ja admin zappix excellent besser
als nagios konfig übers web frontend ja das stimmt zumal nagios konfig ja auch gar nicht
also der klassische nagios gar nicht übers web frontend konfiguriert werden kann trotzdem
ist mir die nagios text konfig fast lieber aber ich habe ja auch so eine persönliche
history was zappix angeht was was nagios angeht so das haben sie neu gemacht also das dashboard
gab es früher nicht es ist eine der hässlichsten html css uren die ich je gesehen habe komplett
useless kann man die wenigstens auf auf digital umstellen anscheinend nicht ok das heißt
das erste was ich schon mal machen werde ist die uhr löschen maps favorite crafts favorite
maps ok meinetwegen sind wir mal sind wir mal nicht so lassen wir das mal ok das fühlt
sich schon mal eine ganze ecke hake hello eine ganze ecke hakeliche an als grafana ich
will es ja nicht zu früh flamen die konfig kommt ja jetzt erst by the way warum hat der
refresh intervall eigentlich bei einer uhr warum musste man refresh intervall einstellen
so und wenn euch diese übersicht verwirrt und ihr eigentlich gar keine ahnung habt
was die euch sagen soll dann sei euch gesagt das ist normal bei zappix also bei zappix
was zu finden und was zu konfigurieren sind eine wissenschaft für sich aber zum glück
habe ich das ja schon mal irgendwann gemacht das heißt ich blicke hoffentlich noch ein
bisschen durch also wer so die klassischen die klassischen begriffe im kopf hat host
service notification alert kann es alles vergessen das heißt bei zappix alles anders bei zappix
gibt es dann sowas wie hosts ok das kennt man noch ja host actions triggers items templates
und und und man hat keinen platzen schimmer was was ist also es ist voll für ein arsch
muss man also wer das zum ersten mal macht der blick nicht durch sowas auch schon mal
mega verwirrend ist er sagt hier host availability eins und jetzt passt mal auf big brain jetzt
gehe ich auf inventory hosts gibt keine hosts das ist so eine typische zappix logik die
werde ich nie verstehen so monitoring host geht monitoring host steht drinne inventory
host steht nicht drinne weil für den zappix host das inventory noch nicht aktiviert wurde
was auch immer es ist es ist wir so ich überlege gerade mit was man mit was man am besten anfangen
wir lassen mal wir machen wir lassen mal mein netzwerk discoveren wir lassen mal also wir
können uns mal zum beispiel angucken also wo fange ich am besten also eine sache die
ich ja von einem monitoring tool erwarten würde ist sowas hier eine übersicht übrigens
dass die filter standardmäßig ausgeklappt sind triggert mich bei zappix auch immer ich
würde ja eine übersicht erwarten einfach eine lange liste untereinander host ist da
ist da gibt es so ohne weiteres in zappix nicht es gibt diese hosts übersicht die zeigt
aber nur an ob der zappix agent snmp oder irgendwelche anderen sachen erreichbar sind
so ein klassisches so eine klassische übersicht server pingt und ist oben gibt es nicht man
kann die sich selbst bauen ja das das funktioniert man kann sich das im dashboard auch einrichten
aber das funktioniert dann wiederum nicht mit diesem host availability also ist ihr seht
es schon bisschen pence champ die zappix konfig so wir probieren jetzt mal was aus was für
ein schwund ja richtig so wir probieren jetzt mal was aus genau wir machen jetzt wir machen
jetzt autodiscovery oder was heißt auch wir machen wir machen discovery also man kann
man kann dort einträge auf zwei arten machen machen wir vielleicht erst mal die manuelle
variante also erst mal das ganze zu finden ist schon mal ist schon mal sehr sehr merkwürdig
ja also zum zum beispiel mal angenommen wir gehen jetzt hier auf monitoring host und dann
sehen wir den zappix surfer damit er überwacht sich selbst da kann man jetzt hier drauf klicken
und riesen sachen zur auswahl lustigerweise auch ein inventory eintrag den es ja wenn
man auf inventory geht gar nicht gibt ich hoffe ihr könnt zappix noch folgen zumindest kann
man jetzt hier auf konfig gehen und jetzt wird es eklig und jetzt wird es eklig das
sieht aus wie von 1900 ok nicht 95 das ist zappix 1998 ich weiß gar nicht wie alt zappix
ist das ist auch schon bis sie älter 2010 oder so oh fuck 1998 alter ist das alt moment
zappix ist älter als nagios echt jetzt hätte ich gar nicht gedacht zappix ist mir erst
so 2010 11 12 zum ersten mal aufgefallen echt krass also das das das das das hätte ich
nicht nicht gedacht novell.com da sieht man schon weiß man schon die seite gibt es gar
nicht mehr perfekt wikipedia das hätte ich echt nicht gedacht na gut gehen wir auf das
web interface was hältst du von nagios checkmk ich finde die funktion gut aber das ue einfach
mies checkmk habe ich nie wirklich verwendet außer mal eine demo mir angeguckt das liegt
daran dass halt die nagios konfig nicht für web interface editieren gedacht ist die nagios
konfig lässt sich ganz gut editor mit dem text editor editieren aber das ist die die
nagios konfig ist halt in keinem format was sich gut für einen web interface eignen würde
deswegen ist es wahrscheinlich mit checkmk auch so eklig so jetzt sind wir jetzt sind
wir in den konfig vom zappix server also von dem der defaultmäßig eingerichtet ist wer
jetzt denkt ok wir könnten jetzt hier einfach mal checks anlegen so einfach ist es nicht
also als erstes muss man erstmal finden wo man hin muss xeroxino 11 monate big brain
subscription huge um nicht zu sagen moment
dankeschön für den sub man guckt sich das an und denkt mal wo zum teufel ist denn hier
einfach ein stinknormaler check mal angenommen ich will einfach nur einen ping machen einfach
einen stinknormalen ping wo ist das ja das ist nicht so einfach bei zappix das verbirgt
sich nämlich unter items so und unter items dann sowas hier ist wahnsinnig übersichtlich
das ist das was er standardmäßig schon eingerichtet hat und hier kann man dann sagen new item
oder create item und ein item bei zappix ist quasi nennen die zuordnung von einem check
zu einem host zappix logik ja und jetzt könnte ich jetzt sagen create item dann könnte ich
sowas sagen wie ping dann sage ich simple check wähle hier irgendwie den icmp ping aus den
ganzen kram kann man hinten übrigens löschen muss man auch erstmal wissen
und dann kann man zeugs auswählen wie beispielsweise wieviel pakete verloren gehen können es ist
echt abartig 5 ist der lts version ja es ist wirklich eklig so und jetzt probieren wir
das ganze mit autodiscovery aus dass das ein bisschen einfacher macht wenn ich es finden
würde ja wie gesagt 5 ist der lts version ich schaue und höre den normalerweise echt
gern zu aber heute ist schwer der muss sich über zappix beschwerden ich habe das nicht
ausgedacht also wir machen jetzt mal autodiscovery ah ne da ist es wir machen mal autodiscovery
damit kann man zappix sagen er soll einen kompletten netzwerkbereich scannen und gucken
was er dort für hosts findet und wir lassen ihn jetzt einfach mal mein internes netz scannen
create discovery rule so mein internes netz ist nicht das sondern 121682.1 ip leak oh
mein gott anzeige ist dedos ist raus so keine local network so und zappix geht jetzt hin
und scannt die ip adressen von 121682.1 bis zu 121682.1254 das macht er einmal pro stunde
wir stellen das mal runter auf fünf minuten dass es ein bisschen schneller geht weil sonst
müssen wir hier eine stunde rum warten man kann ihm auch sagen dass er zusätzlich noch
einen check durchführen soll bevor er das ganze aufnimmt bevor er das ganze quasi erkennt
lassen wir jetzt mal der soll einfach die ip range scannen und sobald er was erkannt
hat soll er das anlegen und gut ist hier muss ich noch sagen mit was die geräte unterschieden
werden sollen in dem fall bleibt mir auch nur die ip adresse übrig wenn er das netz
scannt was soll er sonst nehmen und zum anzeigen nehmen wir den dns name und den hostname so
ad achso muss man doch einen check hinzufügen nimm mal noch icmp ping also sprich der pingt
und wenn der server antwortet dann fügt er ihn hinzu ihr müsst ja hier it specialist
muss ihn jetzt nicht flamen oder so kann jeder machen was er will so ad gut so und jetzt
müssen wir fünf minuten warten und schauen was der discover also der sollte in meinem
netzwerk mindestens zwei desktop rechner finden sich selbst den mikrotik router die
das wiki die next cloud müssen wir mal gucken mal schauen mal schauen was der alles findet
müssen wir fünf minuten warten bis er bis er das netzwerk gescannt hat und wir sehen
das dann dort also wenn er sachen discovered hat dann ist das hier drin ich muss jetzt
nur mal schauen ob er das auch eingeschaltet hat enabled ja welches wiki doku wiki ganz
klassisch oldschool doku wiki also wenn ich die auswahl habe zwischen irgendwie bookstack
oder oder confluence oder sowas für mich daheim ist doku wiki immer noch das einfachste
das schöne an doku wiki ist dass die seiten komplett plaintext sind also keine datenbank
und keine api request die man senden muss um seiten zu editieren also wer schon mal
versucht hat automatisch sachen zu updaten im confluence deck da drehste ab ja ich habe
auf der arbeit ein paar sachen für programmiert das ist mit doku wiki richtig schön einfach
weil die seiten plaintext auf dem fallsystem liegen doku wiki mag jetzt nicht super advanced
2020 ausschauen und eine ordentliche markdown unterstützung wäre auch nicht verkehrt aber
für einfach seite aufmachen paar seiten verknüpfen was reinschreiben ist doku wiki immer noch
am besten braucht man für doku wiki nicht apache und mysql es kann sein dass man für
die da bin ich mir jetzt ehrlich gesagt nicht ganz sicher es kann sein dass man immer dass
man mysql braucht für userverwaltung oder so keine ahnung aber für die seiten braucht
man das nicht die seiten liegen in plaintext auf dem fallsystem bei doku wiki liegen nicht
in der datenbank ganz im gegensatz zu confluence welche system nutzt ihr bei der arbeit für
interne dokumentation confluence deswegen sage ich ja ich kenne mich damit aus automatische
sachen im confluence zu machen einmal in process in java selbst und auch über die api und
das ist bei weitem nicht so schön wie einfach ein paar zeilen bash script was doku wiki
seiten aktualisiert so schauen wir mal ob der jetzt autodiscovered hat nope ach nee
moment wo sieht man sowas überhaupt das müsste man hier sehen oder vielleicht sind noch keine
fünf minuten um muss man fünf minuten warten wo sieht man eigentlich ob der gerade discovery
macht wie hast du zappig installiert als docker container oder direkt auf dem system ich habe
mir den ubuntu 20 04 habe ich mir angelegt und darin zappig installiert da kann ich danach
die sachen wieder wegschmeißen gut ist mit 9908 ich habe auch mal eine weile wiki verwendet
so drei vier monate und was mich da dran genervt ist dass es halt so doof es jetzt klingt nur
in wim richtig funktioniert viele sachen sind im browser einfach angenehmer zumal man die
sich auch mobil angucken kann und also ich finde es praktischer wenn sowas wie ein wiki
einfach auch im browser komplett benutzt bei ist er hat er hat das erste netzwerkgerät erkannt
den mikrotik router der router 192 168 2.5 null abteilen eine minute dann sollten die anderen
sachen jetzt auch demnächst hier auftauchen so jetzt kommt wieder ein bisschen zappig
zappig magic der hat jetzt zwar die host discovered dass es die gibt aber wenn ihr hier guckt
werdet ihr feststellen es gibt nirgendswo hosts matze 20 null 20 2 null 9 null zappig gibt
es nicht unter pf sens zappig der zappig agent gibt es unter pf sens ich glaube nicht dass
ein zappig server unter pf sens gibt ok der discovered hier jetzt vor sich hin also wahrscheinlich
ich hoffe der hat bald auch die anderen sachen bei mir im netzwerk discovered aber wir haben
ja schon eine sache so und die zappig logik ist jetzt folgende eine discovery regel reicht
nicht man muss ihm noch sagen was er machen soll nachdem er die host discovered hat also
man braucht irgendwie doppelte schritte also man lässt das netzwerk scannen und dann muss
man ihm sagen wenn du das netzwerk gescannt hast macht damit was so und dann muss man
unter configuration actions discovery actions genau und da kann man jetzt sagen was er machen
soll nämlich dass er aus dem automatisch erkannten host ein zappig host macht wie gesagt ich
finde es echt durch die brust ins auge wie das wie das funktioniert jetzt muss er nämlich
sagen ok action wenn discovery check discovery rule local network ist dann macht da draus
einen add host und zusätzlich noch inventory mode auf automatisch dass das auch im inventory
angelegt wird ok so ne habe ich jetzt falsch gemacht ach hier ja keine ahnung discovery
ja es ist mega umständlich so und jetzt sollte er wenn er das wieder discovered sollte er
host anlegen discovery gucken wir ihm hier mal zu jetzt sollte er host anlegen so dass
ich dann danach für diese host unterschiedliche checks definieren kann die in zappig übrigens
nicht checks heißen sondern es sind items bei einem host die wiederum sich aus templates
mit eins in checks zusammensetzen wenn ich das jetzt richtig wieder wenn es jetzt stimmt
was ich da erzählt habe und wie gesagt es ist es ist echt extrem umständlich zappig
oder grafana ist die frage was man machen will ich tendiere für kleine sachen wie daheim
man kann beides verwenden weil zappig muss man sich ein bisschen an die an die konfiguration
gewöhnen die ist wirklich wie man hier auch hier gerade sieht echt nicht schön grafana
vor allem in kombination mit prometheus ist halt relativ simpel aufgesetzt prometheus
ist ein binary einfach starten grafana ist auch überall dabei einfach installieren verbinden
und ist ziemlich einfach mit zappig kann man mehr machen oder umfangreicher umfangreicher
in mehreren gebieten du kannst mit zappig zum beispiel sagen ok wenn denn host down geht
dann führe den script aus was beispielsweise deine wlan steckdose ein und ausschalten servaryset
hat und sowas die docker images sind die predicate glaube ich an bar 94 zumindest haben sie
das mal erzählt vor zwei jahren dass sie das die predaten wollen so sind jetzt ein paar
host aufgetaucht guck mal er hat erkannt mein home assistant mein router irgendwie jede
menge desktop rechner und ich habe keine ahnung was das alles ist aber er hat es erkannt
jetzt schauen wir mal ob es im inventory drinne ist ja erster host taucht auch im inventory
auf also bei uns auf der arbeit ist es so wir haben ein komplettes team was sich um
nichts anderes als zappig monitorien kümmert das ist schon ein bisschen big brain software
so mein zappig meckert rum dass er zu sehr beschäftigt ist mit discover so sieht das
übrigens aus wenn einer der servanen fehler meldet oder besser gesagt wenn zappig sagt
der eine der servanen fehler dann sieht das hier so in der übersicht aus also sprich man
erkennt das schon das heißt man sieht 15 oder 42 hier ist das und das aufgetreten und wenn
man jetzt im support arbeitet und beispielsweise jetzt sich das angeguckt hat und gesagt hat
ich mache jetzt ein ticket auf um das weiter zu verfolgen dann kann mir hinten auf acknowledge
drücken und sagen ja ja piss dich alde das update dann steht dann drinne ups ich hätte
das acknowledgen sollen dann sieht man hier drinnen auch ok die fehler meldung hat schon
jemand gesehen nein die alerts mache ich nicht an man sieht dann auch die historie wer wie
was geguckt hat also zappig kann halt wirklich viel das ist so ein bisschen bisschen ticket
system lite mit ein bisschen inventory management lite dann sehr viel monitorien viel automatisierungsgeschichten
also zappig kann alles irgendwie also es gibt fast nichts was man nicht in zappig machen
kann aber es ist dementsprechend von der bedienung halt sehr wir erst mal ich glaube man kann
sogar einstellen guck ich glaube jetzt also der blinkt wenn es neu ist und wenn es acknowledge
ist oder älter als eine gewisse zeit dann hört es dann dann läuft es glaube ich durchgängig
ja und hier bei der host übersicht sieht man das auch ok dieser host ist verfügbar hat
aber ein problem ja ein bisschen ekeliger wird es dann zum beispiel schon wenn man sich
die die letzten werte von dem server mal angucken will wenn man nämlich auf latest data klickt
wird man erst mal zugeschmissen mit allen möglichen sachen die vom zappig server abgefragt
werden gerade und zu jedem dieser werte existiert einen graph in dem man auch rein zoomen kann
und alles also ist schon cool gemacht also man kann sehr viel zeug machen wenn man halt
sich ein bisschen mit beschäftigt hat so was man jetzt hier auch sieht ein system ist available
und eins ist unknown jetzt fragt man sich ok warum warum ist das unknown warum ist der
server unknown der ist doch da und ein paar ping erreichbar das liegt daran weil available
in zappig nur systeme sind mit dem zappig proxy drauf oder die man auf andere offizielle
anweise erreichen kann den ping zählt nicht als available in zappig das finde ich jetzt
ein bisschen fail warum es nicht einfach ein stink normales available ping check gibt
was ist besser zappig oder graphama habe ich doch gerade schon was zu gesagt je gesagt
je nachdem je nachdem was man was man braucht jetzt sollte der langsam aber sicher auch
mal die anderen die anderen host discovered haben oder oder auch nicht aber ich warte
noch drauf weil aktuell hat er nur hat er nur eine sache discovered das ist mir bisschen
wenig also discovered hat er alles möglich aber angelegt hat er noch nicht so viel vielleicht
muss man erst noch mal fünf minuten warten gleich gleich sollte der router auf jeden
fall reinkommen so und als nächstes richten wir jetzt mal ein paar checks ein für das
ganze um noch mal eine sache zu zeigen zappig hat halt 30.000 sachen die man machen kann
zum beispiel kann man auch eine netzwerk also eine karte anlegen vom netzwerk wie die sachen
zusammenhängen sieht halt alles ein bisschen altbacken aus und ist auch nicht so schön
von der bedienung her aber zappig kann halt wirklich viel das kann ich ja rock das kann
ich nicht so genau sagen was sie genau machen keine ahnung weiß ich nicht weiß nur dass
die zappig monitor machen das schnellste system ist das aber auch nicht du brauchst schon
zeit auf naja ach es geht eigentlich also die das web interface mag jetzt nicht das
allerschnellste sein das stimmt aber performance mäßig kann ich mich da über zappig nicht
beschweren ich meine wir haben da irgendwie 6000 systeme drin über norm gepailt mit was
weiß ich wie viel zehntausenden checks und sowas also dafür läuft es echt gut wo bei
uns auf der arbeit zappig immer ein bisschen probleme macht ist bei der langzeit archivierung
von history weil bei uns ist jemand mal auf die klor reiche idee gekommen ja wir wollen
quasi fünf jahre lang daten aufheben und das kannst du halt vergessen du kannst keine
fünf jahre history oder drei jahre wanns glaube ich drei jahre drei jahre history aufheben
für hunderttausende checks das ist komplett also detaillierte history läuft das gerade
lokal oder in der vm das läuft hier meiner denox vm aber das ist cpu mäßig nicht so
der unterschied die die die vm ist auch schon ordentlich bestückt hier mit vier cpu kern
also dieses das ist schon vergleichbar mit wenn es auf dem haus laufen wird dann ist
es auf einer ssd drauf vor allem ist kaum was drinne oh guck mal hat er hat mehr sachen
discovered haus jetzt hat er auch noch was ist denn das ich mache ungern ich mache ungern
sachen bei mir im netzwerk auf wo ich nicht weiß was es ist management interface ok management
interface vom surfer alles klar srock cac w welche cpu hast du auf maus ein 8700k der
rechord naja das ist das hat sich der chat natürlich gemerkt sowas sowas das merkt
sich jeder hier das ist immer immer so so zeug merken sich die leute der rechord das
kennen die leute so ok jetzt hat er ein bisschen was discovered ich warte noch drauf bis der
mein router discovered weil da können wir ein bisschen was ausprobieren drauf gut wie
dem auch sei machen wir weiter der wird ja früher oder später jetzt die anderen sachen
auch noch discoveren wenn man jetzt für jeden dieser haus zähler discovered mal den basic
check anlegen will also zum beispiel in ping es wäre ja relativ sinnvoll dass man jeden
haus den man hier den man hier hat auch ab und zu mal pinkt und guckt ob der noch da
ist kennst du check mk nicht gut nicht gut ich habe das schon mal ausprobiert ich weiß
nicht ob ich installiert habe oder nur die demo ausprobiert habe ich glaube ich habe
nur die demo ausprobiert man merkt halt dass es eine nagios ist mit web frontend davor
ist bin ich nicht so der fan von ich wie gesagt ich mag nagios aber wenn ich nagios verwenden
würde dann würde ich wahrscheinlich text konfig machen so er lasse wir immer weiter
discoveren so und eine sache die jetzt ja ganz praktisch ist der scannt jetzt quasi
mein netz im hintergrund weiter und wenn er neue server auftaucht legt er den an was jetzt
natürlich praktisch wäre dass man für jeden neu erkannten server so nen default check
macht zum beispiel in den ping weil nur weil er den server einmal erkannt hat heißt es
ja noch lange nicht dass er jetzt permanent verfügbar ist und das dafür ist ja gerade
im monitoring system da unter anderem zu gucken ob server ab oder down sind so da gibt es
jetzt gibt es jetzt paar varianten eine davon ist dass man jetzt in den discoverten host
geht also zum beispiel dahin haben wir gerade geguckt was das ist das ist hier das web interface
von meiner 4 hee kiste die da hinten steht im rack die aus ist aber das management interface
ist an moment ich bin übrigens falsch da hin da muss man auf configuration und jetzt
kann man ihm sagen was man zusätzlich noch für checks einfügen will zum beispiel den
ping check und wenn man also mit normalen sachen dran geht so quasi ich suche jetzt
einen check oder ich suche jetzt irgendwie einen script was ich ausführen kann hat man
bei topics ein bisschen gelitten das ganze läuft unter items bei items denkt glaube
ich keiner an checks für den server aber bei topics heißt das halt eben items so und
dann kann ich sagen create item und jetzt kommt so eine maske die auch wieder aussieht wie
straight 1995 und jetzt kann man ihm sagen ok was möchte ich denn für den check durchführen
wir wollen einen simple check das sind eingebaute so eingebaute basic checks und hier sieht
man auch schon man kann mit topics mehr oder weniger alles machen was man will man hat
ziemlich viel eingebaute basic checks man hat man kann über den topics agent auf dem
server jede menge sachen standardmäßig schon abfragen man kann über den topics agent
auf dem server sachen abfragen man kann na gut interne sachen aus dem topics man kann von
irgendeinem management controller sachen abfragen per snlp abfragen man kann irgendwelche database
geschichten direkt machen und aber was auch geht ist wenn alles nichts hilft kann man
über ssh sich einloggen und sachen abfragen man kann einen externen script ausführen
was das was die abfrage für einen macht man kann htp requests machen und da dann scannen
ob was in der antwort drin ist und sowas also sprich man kann eigentlich so gut wie alles
was man sich irgendwie vorstellen kann mit subjects abfragen wir machen jetzt mal einen
simple check und zwar einen icmp check ist auch ein bisschen merkwürdig von von dem
wie man es hier auswählen kann wir wollen an icmp ping machen und wenn man alle optionen
bei icmp ping weglässt dann pingt da das host interface ja also die host ip nennen
wir das ding jetzt mal irgendwie ping so ich zeige euch gleich wie man es richtig macht
weil das ist nur eine variante davon und dann kann man ihm hier noch ich glaube die rest
können wir können wir gleich lassen man kann zum beispiel auch sagen ok in welchem intervall
wird das ganze ausgeführt und auch von wann bis wann ist es aktiv weil es könnte ja
sein dass ich manche server nur checken will von 8 bis 18 uhr man kann das ganze noch applications
zuordnen dass man das dann ein bisschen besser filtern kann so jetzt enden wir das ganze
mal und das braucht jetzt eine minute dann hat er ping check gemacht aber wie gesagt
es ist nicht es ist nicht schön das so zu machen weil da muss man zu jedem host hin
und an jedem host das ganze hinzufügen wir warten jetzt ja mal eine minute dass wir uns
das angucken können latest data das habe ich selber mal weg haus groups discovered haus
es ist doch nichts drinne was max für zwischendurch zwischendurch was ist das denn was ist das
denn oh nee nein das muss jetzt nicht sein da asitoni guck und unser ping ist durchgelaufen
also sprich tabx hat jetzt den server angepinkt und ping liefert eins ist auch nicht so schön
genau an der stelle wenn man hier sich das anguckt und es an alle server haben so ein
extra ping eintrag da wird schon ein bisschen unterschiedlich da kommt jetzt halt zum tragen
dass man mit zappings ziemlich easy einzelne äh äh eigene dashboards und und grafen und
sowas zusammen bauen kann dass es wieder ein bisschen übersichtlicher wird und jeder check
hat im zappings auch eine history craft kann man sich das ganze angucken und man sieht
ok ja der server war halt bisher immer da wenn ihr wollt ich kann ihn mal abziehen
dann sehen wir dass das auch auf kritisch wechselt es probieren aus ich gehe mal kurz
ins rz das hört sich jetzt wahnsinnig wichtig an ich gehe mal ins rechenzentrum aber mein
rechenzentrum ich meine das ist ja ich gehe jetzt in mein rechenzentrum also ich gehe
mal ins rechenzentrum ich bin gleich wieder da und ziehe mal das kabel raus
ne das sieht nicht mal gleich aus es liegt viel mehr zeugs rum auf der erde was ich mal
einbauen wollte so und jetzt sollte der zappings innerhalb der nächsten minute checken dass
das ganze down ist wir probieren das mal von hand aus also 1.2.1.6.8.2.1.5.3 ist nicht mehr
da mal gucken wie lange der zappings braucht bis er es mitkriegt er sollte maximal ne minute
brauchen für den check noch ist nichts da zappings wir haben dich im blick wir haben
dich im blick wie heißt noch mal das tool mit dem du zum beispiel die ips um anzeigen
lässt das ist i3 status minus rs so ne custom i3 status leiste na zappings langsam wird
es aber eng mit der zeit hier langsam wird es aber eng kann es sein dass ich kein trigger
ich glaube ich habe kein trigger ich habe kein trigger hinterlegt nach deswegen zeigt
es das nicht an das ist nur eine weitere zappingsgeschichte ein check allein reicht nicht wir
gehen mal kurz auf den host da ist er latest data guckt ping ist null aber es kommt kein
fehler man muss erst noch einen trigger hinterlegen der da draußen einen fehler macht bis jetzt
ist es reine abfrage von einem check der sich noch nicht in einem fehler äußert ist auch
zappings logik aber wenn man sich den graph jetzt anguckt sieht man ok verfügbarkeit
vom server ist von da auf null runtergegangen so und deswegen machen wir das jetzt mal richtig
da kann ich euch zeigen dass es auch einfacher geht es ist eine der sachen die tatsächlich
recht recht gut gehen im zappings wenn man die logik mal durchschaut hat wir machen den
ganzen kram mal wieder weg den mal hier eingerichtet haben also hier für den für den server gehen
wir mal auf items und löschen den ping wieder dafür gibt es nämlich schon vorlagen es gibt
ein paar eingebaute sachen und da gehen wir mal auf moment wo war das denn jetzt noch mal
das create item templates templates templates broma moment wie ging das noch mal host oh
jetzt hört auf ja ich kommt mal der sach jetzt noch mal templates zuweisen templates
templates genau link new template select cloud modules und dann icmp check so update das
ist quasi ein vorgefertigtes ein vorgefertigtes template für ping wie gesagt es ist halt alles
ein bisschen um die ecke update und jetzt wenn man hier drauf guckt wird man auch sehen
aha wir haben jetzt automatisch aus diesem template drei items nämlich ping loss ping
package loss ping und response time und auch trigger warning warning ok hi also sprich
wenn ich mir das jetzt angucke im dashboard und die minute rum ist oh guck mal der zappings
ist wieder am discover also dass er standardmäßig nix drinne hat finde ich auch ok ich finde
halt diesen prozess dahinter nicht so schön ja also du hast einmal items du hast templates
du musst das ganze zuordnen und nach dem zuordnen passiert auch gleich nix das hat alles seinen
sinn innerhalb dieses zappings universums ja aber man könnte das schon ein bisschen besser
benutzbar machen achso es ist auf down standardmäßig deswegen sollte es doch eigentlich mal problems
drin stehen genau hier jetzt zeigt er jetzt jetzt zeigt er an ok dieser host ist nicht
erreichbar und jetzt taucht das ganze auch im dashboard auf wir haben gerade zu viel
rumgeklickt da haben wir es nicht live gesehen jetzt sagt er achtung hier seit 16 uhr 12
ist die kiste nicht mehr da so und jetzt mache ich das kabel mal wieder rein und dann sollte
sich das von alleine beheben
genau jetzt sollte sich das gleich wieder beheben wir gucken mal ob das funktioniert
wieder er antwortet wieder jetzt warten wir eine minute und dann soll sich das wieder
von alleine beruhigen und dann gibt es noch eine richtig coole funktion für zappings
dass man das eben nicht von hand machen muss also man kann beispielsweise sagen wenn man
so default checks hat wie ein ping dass jeder server der erkannt wird der kriegt automatisch
so ein ping template zugewiesen das machen wir jetzt gleich noch und das ist das ist
eine sache wo ich sagen muss da finde ich das ganz ganz gut gemacht in zappings aber
muss ich erstmal an den zappings way gewöhnen wie man dinger tut gut jetzt sollte der gleich
wieder gecheckt haben dass der ping wieder geht
zappings hat ich bin mir nicht sicher wie standardmäßig eingestellt ist zappings hat auch die möglichkeit
dass man definieren muss der check geht erst jetzt ist er weg aber zappings ist was checks
angeht relativ clever man kann den zum beispiel sagen ok der check muss mindestens dreimal
fehl geschlagen bis er als fehl geschlagen registriert er muss dreimal erfolgreich sein
oder oder irgendwie x beliebige anzahl dass er wieder auf ok geht das hat den vorteil
wenn man irgendwelche services hat die gerade rumspacken und mal gehen mal nicht gehen dass
du nicht zugespammt wirst von monitoring fehlermeldung was hältst du von sowas das kenne ich nicht
guckst du mir mal kurz an wie findest du e zinger naja nagios mit frontend halt wenn nagios dann
hardcore nagios textfeil wann kommt wieder starcraft kam heute morgen schon hast verpasst
sieht hübsch aus das sieht hübsch aus allerdings muss das ja wohl auf dem server selbst laufen
so und ich finde dass da habe ich jetzt wenig anwendungszweck für weil ich mein warum brauche
ich auf meinem server selbst den web dashboard wenn ich sowas wo ich sowas haben will ist
ein dashboard von allen meinen servoren hast du erfahrung mit e zinger nee nicht wirklich
großartige aber mit nagios nagios habe ich eine ganze weile gemacht auf der arbeit so
der ping ist jetzt wieder weg und hat festgestellt ok der server geht wieder und jetzt machen
wir es mal richtig wir löschen das mal wieder wir gehen auf hosts dann auf hier das interface
configuration ich weiß gar nicht wie man kann man kann man templates auch komplett wieder
löschen an link an link and clear session update kennst du dich gut mit beid aus ornee
ne ne gut gut ne kenne ich mich nicht so wir können den host name übrigens noch anpassen
sagen wir mal das ist was ist das für eine kiste server mgmt interface irgendwie so kann
wir das nennen frag mich nicht ich mache immer gerne underscores anstatt der zeichen das
ist so eine olle angewohnheit von mir update gut auch eine sache die mich bei topics ein
bisschen nervt im handling ist dass man nicht dass man nicht updaten kann ohne zu schließen
also ich würde beispielsweise gerne hier was tippen und sagen update übrigens das ist
total bescheuert was ich hier gemacht habe visible name machen also ich will das da
das da so will ich das machen dass man nicht ein dass man sich update sagen kann er bleibt
offen jetzt muss ich immer wieder neu aufmachen so alles klar gut also das dass das cover
und funktioniert noch der guckt alle fünf minuten in meinem netzwerk nach wenn man jetzt
will dass der die sachen dass der die surfer aufnimmt und automatisch einen ping check
verknüpft dann kann man das folgendermaßen machen wir gehen in die in die in diese action
action regeln rein und man kann jetzt also was er ja schon macht ist sobald er den surfer
erkannt hat er legt einen host an stellt ein dass sie im inventory auftauchen und man kann
jetzt hier noch sagen link template und in diesem link template kann man jetzt den icmp
ping linken so und jetzt kriegt jeder server der automatisch discovered wird kriegt ping
zugewiesen den eiters den eit den icmp ping check das heißt wenn wir jetzt mal fünf minuten
warten wenn die discovery wieder neu durchläuft dann werden wir sehen dass auf einen schlag
alle diese server hier also eins zwei drei vier fünf sechs sieben acht neun neun systeme
sind direkt erfasst als host und haben direkt den ping check drinnen so und wenn man das
so eingerichtet hat dann ist das ein bisschen weniger schmerzhaft man muss sich ein bisschen
weniger mit subjects rumgeklick im web interface beschäftigen
ob man jetzt natürlich alles was man auto discovered auch hinzufügen will das sei mal
dahingestellt wo ich mir nicht sicher bin ist wenn er schon mal was auto discovered hat
und ich lösche das ob er es dann beim nächsten mal auto discover wieder hinzufügt ich würde
mal drauf tippen ja dass er das das macht er man kann die discovery regel noch ein bisschen
einschränkt also man könnte jetzt zum beispiel sagen ok ich will jetzt hier das ganze nur
machen wenn irgendein spezieller check erfolgreich ist will ich ihn auto discover oder man könnte
im bei den actions sagen ok dass dieses ganze hinzugefüge machst du nur wenn irgendwas
anderes zutrifft wenn in service auf port x y office kann man alles machen kannst du
monitoren systeme die dir information auch in einer app anzeigen warum wie jetzt wozu
brauchst du eine eigene app du kannst einfach die webseite aufmachen oder versteht das verstehe
jetzt nicht app ist schöner warum also was ist einfacher als einfach eine webseite aufzumachen
ich meine du kannst natürlich eine pwr ich gehe mal davon aus vielleicht lässt sich
topics mittlerweile sogar als pwr installieren da kannst du kannst du zum homescreen hinzufügen
und anscheinend gibt es für topics eine app aber wie gesagt webseite webseite wunderbar
was was du machen kannst ist du kannst dich natürlich aufs handy und so informieren lassen
wenn irgendwas da unten geht das geht mal gucken ob die discovery jetzt durchgelaufen
ist latest
jetzt mal gucken ob ich das auch richtig eingestellt habe discovery also das auch macht
actions link to templates template module doch er sollte er sollte das jetzt eigentlich
eigentlich machen
oder muss ich die server vorher löschen dass der das wieder dass er das jetzt noch
mal neu discovered wäre ziemlich blöd
aus group discovered haus
guck da ist der erste schon drin also sprich jeder haus den er jetzt im netzwerk findet
kriegt standardmäßig jetzt den ping check ab daun status und die response time die response
time ist so schnell dass sie bei null steht in wirklichkeit ist wahrscheinlich 0,01 millisekunden
was auch immer gut das ist so das ist so topics basics wie gesagt ich bin wirklich kein fan
von diesem web interface das wirkt alles ein bisschen altbacken ich weiß nicht wie jeder
sehen ist ich weiß dass ja rock finde das wahrscheinlich ganz toll aber mir gefällt
das web interface nicht es hat seine vorteile und es ist cool was man damit machen kann
ich finde es an viel stellen echt hakelig macht er das bei jedem klein ja das macht
er bei jedem wenn wir jetzt gleich sehen hier kommen immer mehr server rein der autodiscover
das netzwerk und gibt legt für jeden den haus an und jeder haus kriegt jetzt standardmäßig
den icmp check also wenn wir jetzt hier noch zwei drei minuten warten dann stehen da immer
mehr haus drinnen so man kann auch ein paar andere coole sachen machen aber ich will jetzt
erstmal gucken was ist neu in subx 5 weil das kennt das kannte ich jetzt ja alle schon
nutzt ihr das auf der arbeit ja aber ich kümmere mich nicht wirklich darum so was was kann
er denn neu in subx 5 out of the box integration mit cloud gedöns mit docker ok da bin ich
jetzt mal gespannt achso die meinen mit out of box integrations dass sie direkt auf dieser
platform lauffähig sind dachte der ist integriert dass der irgendwelche docker geschichten abfragen
kann naja ne ok wie autodiscover der irgendein broadcasting ich glaube da gibt es verschiedene
möglichkeiten habe ich kann mich dunkel dran erinnere habe ich mal in der subx doko gelesen
dass das das normale ist auf jeden fall einfach n map scan quasi n map einmal netzwerk durchgescannt
ping oder port check machen man kann das ja hier auch auswählen also sprich man kann
er hier auswählen was der irgendwie mag der grad nicht mehr aber das kommt bestimmt gleich
noch man kann er hier beim discoveren auswählen auf grundlage was der discovert also sprich
man kann sagen ok er soll autodiscover in dem er jede ip anpingt man kann auch zusätzlich
sagen er soll ein fdp check machen oder warum man auch immer in pop 3 check machen soll
oder tcp check gucken ob irgendwelche telnet verbindungen gehen ob ein subx agent läuft
also man kann da verschiedene sachen einstellen was der ausprobiert auf den system aber ganz
billig gesagt ist es so wie du sagst da geht so jeder ip in diesem netz und und guckt nach
wie soll das auch sonst machen es gibt ja in äußerzeit ein bisschen advancedere varianten
was so service discovery und so was angeht also sprich dass man das über dns macht oder
irgendwie konsul ist ja grad auch voll angesagt oder anderweitig ich bin mir relativ sicher
dass kann man in subx integrieren man kann auch quasi sachen beim subx registrieren lassen
dass er die nicht selbst erkennt das habe ich aber noch nicht gemacht also wie gesagt
man kann nahezu alles nur erdenkliche mit subx machen wenn man weiß wie ja und das hier
ist die big brain manager ansicht man kann verschiedene host und verschiedene applikationen
zu services zusammenfassen und sich dann anzeigen lassen wie hoch war die verfügbarkeit das
ist für für die stonks leute immer ganz toll oder man macht big brain und nennt den service
einfach big brain service sag wir wir haben slas 99,999 und dann und dann und dann hinterlegen
wir einfach keine checks dann ist nämlich der service immer bei 100 prozent also sprich
wenn dann irgendwie einer ankommt sagt und was macht unser big brain service 100 prozent
wenn man da jetzt natürlich was hinterlegt dann sieht das anders aus habe ich beide
noch nie noch nie probiert ja weiß gar nicht wie das funktioniert no data font ok ich
habe keine ahnung wie es funktioniert also typische zappig sache ist es nicht sonderlich
intuitiv keine ahnung wie big brain service vielleicht muss man es umgedreht machen triggert
zu einem service zuweisen das sind dependencies ach hier triggert ah guck mal da select ah
hier genau jetzt kann man jetzt kann man also triggert sind ja im zappig die sachen die
ergebnisse von checks beziehungsweise quasi logik die die ergebnisse von checks überprüfen
und anhand dessen dann den status anzeigen es wäre auch zu einfach wenn es einfach sonst
ein check wäre der was macht und hier kann ich jetzt zum beispiel sagen dieser ping icmp
service gehört dazu zu meinem zu meinem service und wenn ich jetzt bei service gucke ach so
gut der war halt immer ab oder so gut wie immer ab dann würde ich dann würde ich halt
hier sehen der macht dann so ein bisschen auswertung darüber das ist aber eher für
die big brain stonks manager leute die gerne sowas sehen das brauche ich daheim nicht
kann man da auch einstellen dass zappig irgendeine nachricht ein anderes program sendet wenn
zum beispiel ein service ausfällt ja da kommen jetzt dazu das nehme ich auch noch eine sache
die ich ausprobieren wollte da gibt es jetzt seit ein paar zappig version glaub auch microsoft
teams und sowas als notification variante also was man machen kann ist da muss ich jetzt
aber selbst mal gucken wie das wie das funktioniert man kann sagen als action trigger action glaube
ich da kann man sagen ok condition wenn wenn dieser server jetzt kaputt geht also sprich
wenn der server unavailable ist das kann man übrigens auch wieder über templates zuweisen
glaub und so das muss man das muss man nicht für jeden check einzeln machen also könnte
man das mienbord damit verbinden theoretisch schon ja du kannst externe scripts hinterlegen
du kannst alles damit machen also sprich wenn mein router nicht verfügbar wir machen das
mal nicht mit dem router wir machen das mal mit dem dem server hier mit dem management
interface vom server ben what what the fuck hat er das noch nicht auto discovered oder
was aber er hat es noch nicht auto discover natürlich den mit dem ich jetzt ausprobieren
will den hat er noch nicht auto discovered by the way angeblich läuft das alles alle
fünf minuten ja dann machen wir das bei exemplarisch mit mit meinem mit meinem router also actions
trigger actions also sprich wenn wenn mein router nicht mehr verfügbar ist dann sagen
wir dann schicken wir eine nachricht und zwar über also das sind die sachen die standardmäßig
da integriert sind aber man kann auch weitere sachen hinzufügen also erstens das ding kann
glaube ich webhooks irgendwo konnte das glaube ich auch webhooks kann sogar discord mittlerweile
also es kann schon ziemlich viel kann über microsoft teams und ich glaube man kann dem
ding auch sagen es soll soll ein custom script ausführen oder sowas weil ich jetzt aber
grad grad nicht wie es funktioniert dann kann man mehr oder weniger alles machen also man
kann auch sagen hier send über discord ach genau ich weiß wo das ging irgendwo hier scripts
mediatypes media mediatypes auch wieder so eine bezeichnung wo kein mensch dran denkt
dass unter mediatypes allen ernstes notification varianten stehen so create mediatype email
script script genau also sprich wenn ich irgendeinen custom service habe den subx nicht standardmäßig
kann da kann ich entweder über einen x beliebigen webhook oder wenn es ganz hart kommt ein externer
script sagen wohin er das schicken soll also subx das muss man subx echt so gut halten
ist ziemlich erweiterbar was das angeht und du kannst mit subx wirklich nahezu alles machen
was was so lustig beste so jetzt gucken wir mal ob das auto discover jetzt soweit schon
funktioniert hat dass ich jetzt auswählen darf nicht mein router sondern jetzt jetzt
als auto discover genau unavailable also sprich wenn mein management interface schon selber
ausgefallen ist dann schickt eine nachricht an an per mail so ach nee ach message muss
ich reinschreiben an den user stimmt der bross ja ok atmen ich glaube man hat gar keine
email adresse hinterlegt aber wurscht so jetzt krieg ich eine mail geschickt wenn ich die
email adresse hinterlegt hätte kennst du prtg ja das ist windows only deswegen habe ich
mich damit nie großartig beschäftigt und übrigens dass das also das nice an subx an
der stelle ist auch man könnte auch sagen ok wenn das ganze wieder ok ist schickt er
diese nachricht wenn es sich wenn sich der status ändert schickt er diese nachricht
und diese nachricht wird halt geschickt wenn er fehler auftritt also fehler tritt zuerst
auf gibt diese message fehler geht wieder weg gibt es diese message es gibt einen anderen
fehler beim gleichen service dann gibt es diesen fehler ist eigentlich ziemlich cool
gelöst was was die da jetzt habe ich nicht geerdet ist auch egal prtg benutzen wir auf
der arbeit bin kein fern von sagt der ghostwriter ja ich bin allein schon kein fern von weil
es windows only ist so was man jetzt auch machen kann ist wie gesagt subx kann ziemlich viel
manche sachen wirken bisschen altbacken zum beispiel man kann sich eine map anlegen vom
wir müssen erstmal die map ein bisschen größer machen keine ahnung wie 800 mal 600 man kann
zum beispiel dann alle haus die jetzt automatisch das kaffert hat was auch immer das jetzt ist
alle haus die automatisch das kaffert hat kann er zu so einer karte hinzufügen es ist
aber eklig so edit map schweißen wir den subx server raus remove fühlt sich auch an
wie 1995 ein bisschen da kann man sagen add map element so es sieht natürlich ganz toll
aus so haus group und dann kann man ihm sagen er soll die haus group discovered haus anzeigen
apply close update und wenn man da jetzt rein guckt damit man sehen ok ah lull ah yes jetzt
haben wir alle haus drin die heißen jetzt natürlich falsch weil die sollen nicht alle
new element heißen sondern die sollen gefälligsten ordentlichen namen bekommen das kann man natürlich
auch machen man kann in subx an ganz vielen stellen macros einsetzen so subx macro host name
muss ich nachgucken weiß ich nicht ok hier host name host punkt name alles klar exzellent label
host punkt name close update safe und jetzt guck haben die dinge ip beziehungsweise richtige
namen allerdings ganz ehrlich ich wir haben wir haben auf der arbeit auch eine subx map
ich habe glaube ich in 13 jahren nicht einmal reingeguckt ich weiß ja braucht man nicht
wirklich so und eine weitere sache die subx richtig gut kann es habe ich wie gesagt habe
ich kann ja alles irgendwie ist sowas hier screens also wenn man jetzt hier mal bei latest
data schaut so wir gucken uns jetzt mal hier unseren ping an zwar ping ping vom server
den da wenn wir uns hier den graph angucken der war zwischenzeitlich mal daun ich weiß
nicht warum der jetzt wieder angeblich immer ab ist da war doch zwischenzeitlich mal daun
ich habe doch persönlich den stecker gezogen nun gut angeblich war da immer ab ich glaube
das ist weil er weil ich den neu discoveren hab lassen mit einem neuen check mehr zumindest
unabhängig davon man kann jetzt bei subx auch relativ schöne grafen anlegen so da muss
jetzt mal selbst gucken wie das ganze funktioniert da muss man wieder in die host config configuration
dann geht man auf graphs ne configuration hosts graphs ah create graph big brain sondern
sagen wir jetzt keine ahnung ping warum ich einen extra graph anlegen muss obwohl es dafür
schon einen graph gibt leuchtet mir nicht ein vielleicht kann man das auch automatisieren
so blablabla items dann nehmen wir jetzt hier ping select und schon kriegen wir einen graph
mit dem ping drinne und wenn wir den hinzugefügt haben dann kann man sich da raus so ein bisschen
wie in grafana so ein bisschen wie in grafana kann man sich daraus extra screens zusammen
bauen also übersichten für eine bestimmte servergruppe zum beispiel also poggers es
sieht auch ein bisschen aus wie grafana lite gleich so wie grafana in version 0.1 ausgeschaut
hat change und da nehmen wir jetzt den graph ping vom management server add dann ist er
da drin und man sieht schon es ist altertümlich weil man muss ich weiß nicht ob es anders
geht man muss hier noch von hand irgendwelche breiten eingeben und so das ist halt schon
ein bisschen ein bisschen low brain weiß ich nicht ob man das nicht automatisch machen
kann so und wenn man jetzt hier auf screens geht hat man den ganzen kram hier halt schön
zusammengefasst aber ganz ehrlich was übrigens eine sache man kann ja auch sagen dark seam
ganz ganz furchtbar wichtig muss man machen aber jetzt mal ernsthaft leute was sieht was
sieht besser aus oder was ist jetzt sieht es relativ ähnlich aus jetzt kann man es ganz
gut vergleichen also welche grafen sind schöner die da oder die da okay auf dem graph ist
jetzt nicht viel zu sehen das ist ein doofes beispiel jetzt machen wir noch was anderes
rein immer noch einen zweiten graph subx server internal process cache usage server performance
okay excellent change 1200 left auch nicht direkt untereinander also es sieht jetzt relativ
ähnlich aus wenn man sich hier was interface anguckt also welche grafen sind schöner die
oder die oder die oder die also ich finde der gewinner ist relativ klar was übersichtlicher
und besser aussieht und moderner also das kann er mit graf hana nicht wirklich mithalten
von den daten her macht es keinen großen unterschied wobei man sagen muss die logik
die man in graf hana machen kann die ist schöner als die grafen die man im subx machen kann
im graf hana kannst du noch ein bisschen besser feintunen also aber was man halt auch daran
schön sieht ist man kann im subx halt wirklich alles irgendwie machen von grafen bis screens
für monitoring wende bis service discovery bis maps vom netzwerk alles irgendwo dafür
ist subx nicht schlecht so eine sache die ich jetzt unbedingt mal ausprobieren will
ist die prometheus integration weil das habe ich noch nicht gemacht und das ist eines der
großen neuen features gewesen von 42 mal gucken wie das funktioniert okay bla bla note exporter
ja meine note exporter läuft mein note exporter ist hier zu finden den wir jetzt mal verwenden
also was müssen wir machen um das im subx irgendwie anzulegen configuration host prometheus
items und viele haus prometheus ah der hat vorhin ein haus prometheus angelegt na gut
ich brauche gar kein extra haus für das benutze ich irgendjemanden der schon da ist
nämlich den subx server oder so ich configuration und was muss man da jetzt machen
creating an http master item ok also items create item hat ttp h ne doch
http agent also ich habe keine ahnung was ich hier mache ich tippe das einfach nur
ab kein schürmer was da passiert so request get raw ne was request type get timeout drei
sekunden raw ok achso dass der request passt schon so so update intervall auf was auf fünf
sekunden alles klar wir wollen ja auch was davon haben
history storage period zu null
type information text was wo ist type information type text ab den intervall fünf was auch immer
hier abgeht grad storage storage hat er ausgeschaltet ok prometheus add
ob das jetzt funktioniert wo ist er wo ist man check ob das jetzt klappt ich habe ja
so meine zweifel habe ich überhaupt richtig gemacht ja matrix prometheus und jetzt sollen
wir once go to monitoring latest data ok monitoring latest data und jetzt ist der haus der subx
server selbst und da gibt es irgendwo prometheus nö gibt es nicht ah zweite seite exzellent
nö gibt es nicht alles klar geht schon gut los krass ist toll application wo steht denn
das dann drunter wo finde ich das überhaupt müsste es jetzt was eigenes sein oder ich
habe legit keine ahnung wo ich danach suchen muss tja
also seite 2 vielleicht hätte ich es doch nicht auf dem subx server machen sollen
5 sekunden ok das müsste auf jeden fall da sein jetzt execute test get value ok was
habe ich habe ich irgendwas verkehrt gemacht read ja es ist es ist von der bedienung schon
echt eklig wo ist das problem jetzt ich habe doch alles gemacht wie die gesagt haben test
a house address
test query very vieles raus machen ja hatte da auch drinnen
keine ahnung latest ok keine ahnung ich habe wirklich keine chance was der für schmerzen
hat irgendwie prom habe ich es genannt ja gut da wird das mit prometheus monitoring
ich meine ich kann es noch mal zu einem anderen host machen ich mache es noch mal bei einem
anderen host wir machen mal den subx server wir machen das mal vom subx server weg configuration
items ok löschen was hier delete ok wir machen das mal bei einem anderen host rein bei
irgendem irgendwie war einer da ein bisschen sinnvoller ist der noch nix macht wir machen
das jetzt machen das jetzt hier dabei beim management interface vom server ok items create
also http agent key master url das damals stimmt die url überhaupt ja stimmt name prometheus
das lassen wir alles das lassen wir alles man musste typ update intervall fünf sekunden
so man musste doch irgendwo noch typ einstellen typ text test
was gebe ich da überhaupt what the fuck was soll ich da überhaupt eingeben value ne das
ist das doch was ich gerade ausprobiert habe ich habe keine ahnung was willst du von mir
add so wir warten jetzt fünf sekunden und gucken ob es funktioniert 1 2 3 4 5 wir machen
es jetzt mal wieder auf eine stunde hoch dass es nicht so rumspackt das ist eigentlich
eine sache was ich bisher gemacht habe eigentlich nur euch gezeigt dass ich keine ahnung von
subx habe und ein bisschen rumgekleckt das ist eines der sachen die wollte ich jetzt
echt mal ausprobieren items master enabled ok prom latest latest data latest data für
den server select da ist es doch history so ok das funktioniert jetzt jetzt kommt die
nächste big brain aktion wie kriege ich davon jetzt den wert abgefragt ich ahne schlimmes
ok items ok wie geht es weiter übrigens ich stelle mal den intervall intervall wirklich
hoch nicht den intervall die history mache ich mal weg weil ich brauche keine history
von einem check mit so viel textausgabe so ist besser ok als dass man das immer doppelt
und dreifach anklicken muss items so wie geht es jetzt weiter also create item you have
to specify type dependent item type die dependent item master du scheiße ultra intuitive bedienung
ok key ist keine temperature von der heizung key der key ist von meiner heizung die temperatur
current current temp unit grad zellius numeric unsigned float unsigned es ist float oder
float unsigned float unsigned ok float float so das kann er storen add so oh nu oh nu
preprocessing promet ach du grob soll ich jetzt soll ich jetzt jeden einzelnen scheiß
von hand mappen oder was ist das euer ernst das ist ja der witz ich ich map doch nicht
jeden value von hand warum gibt es da nicht irgendwie nen click ui an der stelle wo sinn
machen würde also dass man hier sagt key select die will ich auswählen ich pass doch
da jetzt nicht jedes ding von hand raus wollte ich mich das ist ja mal absolut lächerlich
ok funktionieren tut es auch nicht value of string is not suitable for numeric float ok
wahrscheinlich wahrscheinlich muss ich irgendwie preprocessing machen ok preprocessing step
regular expression what da prometoids pattern ok prometoids pattern und dann das da ich
hab keine ahnung ob es funktioniert update wir warten jetzt einfach fünf sekunden und
gucken ob es wieder funktioniert dann das ist echt eine beschissene integration sagt
schuss bei dem ja finde ich auch mal gucken ob es wenigstens funktioniert jetzt aber ich
ich mach doch nicht ich map doch nicht jedes ding von hand was kennst du igl ums nein was
ist das also ich kenne igl und ich kenne ums aber in kombination kenne ich das nicht ums
klingt nach einem unify irgendwie security zeug und igl klingt halt nach einem igl darf
man das einschrieb die seite darf man nicht refreshen ist auch wieder geil excellent ok
guck mal es hat funktioniert temperature monitoring latest latest data aber aber an dem moment
temp 51,9 grad ok es funktioniert aber ich map das doch nicht alles von hand das ist
ja ne das kenne ich nicht ist nur nackt keine ahnung was ist aber ich map das doch wirklich
nicht da wirst ja da ist ja doch durch im kopf wenn du das alles von hand mapen willst
was haben die sowas was was haben sonst noch hier für dinger geschrieben low level discovery
ist noch was in key like was
ist happening prometheus to jason what
ich habe keine ahnung was die hier gerade von mir wollen man muss das man muss das wirklich
alles von hand mapen sehe ich das richtig ohne jegliches gui was einem hilft dabei ok die
integration sagt die integration sagt mal richtig hardcore da bleibe ich doch was das
angeht bei grafana und prometheus direkt anstatt das damit zu machen ist mir zu dumm die lld
was die lld kann die items einzeln aus dem jason erstellen das heißt ich könnte dann
schon alles importieren von allen host oder wie und ich muss es nicht direkt mappen das
wäre das wäre schon mal ein start weil das von hand zu mappen alles da wisst ihr verrückt
das musst du was web interface machen ich glaube das steht dann alles in der datenbank
und da ist nix mit text datei also was ist das ich habe keine ahnung die igel ums die
igel ums klingt etwas wie igel zucht so igel ums die universal management suite wurde
zur also allein schon weil das weil das ein produkt auf deutsch ist bin ich da schon mal
skeptisch sieht ein bisschen aus wie die jetzt wie die alte esx oberfläche ich glaube
das will ich nicht benutzen sowas ist das eine windows anwendung ach du scheiße das
ist doch nicht mal eine web anwendung monkaS das ist ne windows anwendung ne ne ne ne ne
schnell weg schnell weg alles weg hier aber krate william das funktioniert dann nur für
wenn ich das richtig sehe ich muss ja hier eintragen was er erwarten kann im json output
so und dann kann ich das auf allen host die den gleichen json output haben oder den gleichen
prometos output verwenden was ich jetzt nicht machen kann ist einfach alles was es gibt
mit dem key automatischen topics importieren also dass ich dem einfach nur sage hier frag
metric ab und die metric steht dann einfach unter dem key name im topics zur verfügung
ich muss ihm einmal sagen was für keys möglich sind weil er mappt ja hier ne moment wo macht
er das gar nicht weil hier mappen die ja sachen labels device help help also sprich ich muss
schon einmal sagen was ich alles aus dem jeweiligen prometos output haben will levantin sagt da
wie igel im geschäft nutzen kann ich sagen don't use es sieht für mich auch auf den
ersten blick so aus wie was was man nicht benutzen will also also falls das eine monitoring
lösung sein sollte die nur mit windows only funktioniert das schlimmste ticket system
leute was ich je gesehen habe war das hier das war das schlimmste ticket system was ich
je gesehen habe und das ist naja ist klar das ist auch windows only client kein web client
windows only client wp dann windows only wpf client die haben auch nicht mal screenshots
da drinnen weil es so hässlich ist mittlerweile gibt es angeblich ein web client habe ich
aber nie nie ausprobiert das ist das hässlichste ekligste ticket system was ich je gesehen habe
guckt euch an hier winstiget oje schlimm ganz ganz schlimm
also bei mir haben alle anwendungen die einen windows only client erfordern schon mal verloren
für sowas hier wenn es natürlich was ist was nur für windows ausgelegt ist und hat
auch nur unter windows funktioniert da sage ich nichts dagegen das ist ein bisschen wie
früher vmware esx management nur über den windows client ging es gab wenn du esx also
ist schon einige jahre her wenn du wenn du den esx managen musstest dann hast du glaube
ich vmware wie ist das vmware den v4 client hieß das ding genau da hast du den v4 client
gebraucht den gab es nur für windows das war irgendeine uralt.net 1.1 anwendung und
das ging nur mit windows mittlerweile gibt es das zum glück ganz normal übers webinterface
wie gescheit läuft denn krafana auf einem raspberry pi 3 ohne probleme prometoys und
sowohl krafana sind recht ressourcensparend ich habe es aber nicht auf raspberry pi laufen
ich habe es auf lanyardkiste laufen kannst du aber ohne probleme machen du hast kein
ding ich würde nur schauen dass du es nicht auf eine micro sd karte machst weil gerade
prometoys wenn das permanent metriken einsammelt dann ist die micro sd karte wahrscheinlich
auch schnell mal im arsch gachi bass 5 minuten gut also die prometoys integration gefällt
mir ehrlich gesagt gar nicht ich mache jetzt mal eine sache noch nehme ich mal den vergleich
zu meinem krafana hab ähm leg noch mal nen kraf an temperature craft oder so temp craft
type normal und zwar für temperatur von meiner heizung aber dass ich das so einzeln mappen
muss ach ich weiß nicht add screens fügen wir den mal hinzu machen wir den kram hier
mal weg da steht eh nur eins dran temp update so das ist die temperatur von meiner heizung
also quasi der kraft dort entspricht ähm dem hier na dann weiß dann weiß ich aber
echt was ich bevorzuge wenn ich die auswahl zwischen dem und dem hier hab
ne ne ne gefällt mir nicht das gefällt mir nicht das coole an subbing ist weshalb ich
immer noch immer noch dran denke dass vielleicht doch bei mir daheim einzusetzen deshalb das
gesamtpaket ist halt echt cool gerade auch die möglichkeit was ich jetzt hier ganz cool
finde zum beispiel ich könnte sagen ok ich mache eine action wenn jetzt sagen wir mal
der trigger von meinem nehmen wir jetzt mal sagen wir jetzt mein raspberry pi ist unavailable
so da könnte ich nämlich sagen als action da drauf führe ich einen script aus wenn
ich jetzt finden würde wie das funktioniert ich finde den knopf dafür gar nicht dass
ich einen script ausführen kann was dann über meine wlan steckdose den raspberry pi neu
startet das ist schon cool dass das hat schon was irgendwie also quasi dass ein monitoring
system hast was für dich auch sachen fixen kann zum beispiel mein das frontend für die
cameras was ich da programmiert habe wo es per web rtc die camera streams anzeigt das
spackt manchmal ein bisschen rum wenn eine camera sich neu startet halt bisschen noch
nicht so ganz back frei und wenn ich das erkennen könnte und es lockt sich ein und startet es
neu das wäre schon cool aber was mir halt nicht gefällt ist das hier ich meine das
die dinger das ist auch kein ersatz für schön für ein schönes grafana dashboard und auch
die übersicht mit host ab daun ist nicht so schön vielleicht vielleicht wäre das sinnvollste
wirklich beides zu verwenden aber ich will keine zwei monitoring systeme für meine kisten
daheim verwenden du kannst den grafana auch zappings als data source angeben ja ich weiß
in dem fall ist es aber umgedreht ich habe die daten ja schon über prometheus im grafana
und gerade und im zappings müsste ich die daten erstmal aus prometheus abfragen und
pasen dass sie funktionieren also ich habe ja sogar schon die bessere lösung ohne zappings
was das zumindest für die heizung angeht ich würde aber halt gerne mal alle ich würde
halt gerne mal alle meine hosts so basing monitoring erfassen und die nachschauen regelmäßig
nachschauen lassen beispielsweise läuft der raspberry pi im keller noch oder ist mein
esp 32 für die klingel noch erreichbar einfach dass ich schneller mitkriege wenn was nicht
geht und nicht erst bei dem zeitpunkt wenn es halt nicht mehr funktioniert die grafen
sehen aus wie beim alten psd oder pf sens ja ich vermute mal dass es rad hieß das doch
glaube ich oder erd kraft ja das sind so die die klassischen dies die sehen die sahen
früher die sehen beim nagios auch so aus die sahen alles die sind sahen früher alle
so aus grafana hat mehr big brain gemacht die sehen halt einfach besser aus stehe auf
und guck vor ort nach ja mache ich ja jetzt gerade wenn was ist aber so wäre es schon
deutlich besser ich meine wie cool wäre das wenn das ding feststellt ok server ist down
und moment die war die ip von dem den ich muss mal kurz in mein router nach der ip gucken
router wo ist der router wo wird hier geraudet das hier vielleicht
was ist die ip von dem ding
wo ist es hin
wo ist denn die ip 100 130
ah hier ich habe es gefunden genau ich weiß es wäre doch richtig cool wenn der zappix
feststellt raspberry pie im keller ist down und geht dann über die api auf die wlan steckdose
hier und macht an und aus also jetzt nicht im web interface klicken sondern sondern
wie auch immer der api aufruf dazu aussieht kein schimmer toggle button
also wenn der zappix dann einfach einen aufruf an die wlan steckdose macht und an und ausschaltet
das wäre doch echt nice wobei man das mit grafana auch machen kann also nicht direkt
mit grafana sondern mit prometheus in der kombination mit prometheus ich glaube wie
heißt das andere alert manager da kann ich auch custom scripts ausführen wenn was ist
also ja der vorteil vom zappix ist halt dass alles schön integriert ist aber die bedienung
gefällt mir nicht ich bin da echt hin und her gerissen schlauer geworden bin ich jetzt
auch nicht schlauer geworden bin ich jetzt auch nicht was ich mache was sind die was
sind die tollen neukiller features von zappix 5 autentifiziertes autentifiktion juckt mich
nicht support http proxy webhooks juckt mich auch nicht black white list matrix juckt mich
auch nicht das ist also enterprise zeug was ist das ein secret store ok das ist tatsächlich
ganz nützlich wenn man es denn verwendet next generation zappix support zappix agent
jetzt in go programmiert ja meinetwegen
aber ich weiß nicht ich bin immer noch unschlüssig was ich da jetzt verwenden soll ich glaube
ich probiers ich glaube ich lasse es mit zappix wie gesagt ich bin eh kein großer zappix
fan ich baue einfach mein grafana beziehungsweise mein prometheus aus ich brauche ja bei mir
nicht viel ich will wissen sind meine hosts up und down und vielleicht noch die ein oder
andere services und alerts weiß gar nicht ob ich überhaupt alerts brauche hauptsache
ich hab ein dashboard ja alerts per pushover oder so auf aufs handy ist auch ok kann auch
fast alles und discovery kann ich über dns machen oder über
irgendeinen feil oder sonst wie vielleicht mache ich einfach eine host liste mit dem
ich mein daheim muss ich eigentlich ist es doch mit autodiscovery für daheim auch komplett
auf a kill oder jetzt mal ehrlich so cool die autodiscovery ist dass man quasi alles
automatisch erkennt für daheim ist es eigentlich total überflüssig ich meine ich habe die
ich habe sind wir mal über sagen wir mal übertriebener weise ich hätte 20 20 kisten
die wichtig sind ich meine ich habe zwar mehr endgeräte letztendlich als 20 im im im netzwerk
aber server und und sachen die mich interessieren lass es mal 20 sein wenn es hochkommt lass
es mal 20 sein ja die zwei tablets im flur als dashboard der raspberry pi im keller der
esp für die klingel wiki nextcloud filesync und sowas habe ich 20 kisten diese 20 kisten
kann ich doch ohne probleme von hand in der host liste erfassen was welcher server ist
die ändern sich nicht und wenn ich die mal lösche dann dann geht der check halt auf
daun und ich lösche ihn da raus also eigentlich ist die autodiscovery für daheim fast schon
auf a kill da hast du mit der autodiscovery daheim wahrscheinlich mehr zu kämpfen weil
die meisten host die du discover gar nicht haben willst zum beispiel von allem was ich
hier was ich hier discovert habe was will ich haben ich will vielleicht das management interface
vom server haben ich will vielleicht mein router interface haben und irgendwie den wiki
container oder so das war es glaube ich glaube das ist einfach komplett auf a kill ich bleibe
mal bei meiner graf hana prometheus lösung und bau die ein bisschen aus und erst wenn
dort irgendwas nicht funktioniert wie ich mir das vorstelle dann überlege ich mir ob
ich vielleicht damit zappichs oder irgendwas anderem anfangen weil ich habe jetzt auch
nicht vor großartig zappichs zappichs master hier zu werten dass ich damit dafür bin ich
jetzt nicht zu groß bin ich jetzt nicht groß genug zappichs fern naja gut aber haben wir
noch schön ausprobiert wie lang bin ich denn on 2 stunden 44 so lange schon gar nicht gedacht
sagen mal leute war das jetzt wirklich heute mal ein stream wo wir von anfang bis ende
was gemacht haben sehe ich das richtig ich habe von anfang bis ende was gemacht sachen
gibt es das kommt selten vor na gut easy fast dahin ja dazu kann man nicht nur sagen ganz
wichtig ganz wichtig
falle bis nächstes kaputt gegangen ja gut es ist in der das ist ja in einem in einem
eigenen container gewesen wo wir das gemacht haben da kann nichts kaputt gehen power off
bam ups weg ist er rip container also wir könnten ihn wieder starten es ist nicht weg
ja chat gibts noch ich gucke mal ob ich was übersehen habe
jemals übersehen questions
wie zeigt grafana daten über einen längeren zeitraum an je nachdem wie lang man die sachen
vorräte hält also ich habe glaube ich einen grafana ich habe glaube ich ein halbes jahr
eingestellt gucken wir mal also nehmen wir hier die wassertemperatur excellent die wollte
ich schon immer so genau wissen also wassertemperatur und jetzt gehen wir mal hier zurück letztes
letztes jahr okay wir haben daten nur vom 27.6. okay doch nicht drei monate sondern
wie lange ist das 14 tage ne doch ungefähr ne ja so so so 14 tage ungefähr habe ich
wahrscheinlich da eingestellt wie lange das ganze vorräte hält reicht ja auch länger
muss ja wirklich nicht sein man kann da einstellen was man will man kann das auch fünf jahre
aufheben wenn man das wenn man das braucht ja ich habe mit prtg eben das problem dass
er auf 100 tage den median anzeit nicht die peak so richtig dumm das ist das coole an
grafana das mag ich man kann ziemlich im detail einstellen was man will und in kombination
mit prometheuse hat man hat man noch mehr möglichkeiten also du kannst in prometheuse mit dieser
abfragesprache schon ganz gut vorfiltern und aufbereiten was du haben willst und dann
in grafana die details machen das ist ganz cool die kombination chronograph tele ne telecraft
chronograph und und und influx db ist auch ganz gut was das angeht also influx db finde
ich sogar noch einen ticken schöner als prometheuse von vom abfragen her was machst du heute
noch also ich werde jetzt die kamera einbauen führen für den hof wieder die ist ja kaputt
gegangen und da werde ich noch ein bisschen pass auf exile kreiten und fertig geworden
ja läuft alles wie gesagt läuft wunderbar ok chat dann würde ich sagen beim bis wir
sehen uns bis zum nächsten mal herz 390 warum war das zu zu anstrengend die webconfig von
dem ding kann ich verstehen schön war es nicht easy clap so irgendwas was man hausen kann
du folgst zu viel hackermann live kanäle ein bisschen kleineres hausen
bin ich wirklich keiner da na gut machen wir schluss wir sehen uns zu bis denn
